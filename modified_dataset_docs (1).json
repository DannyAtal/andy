{
  "messages": [
    [
      {
        "role": "user",
        "content": "What is cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io is a comprehensive ML/AI platform that provides tools and services to simplify the machine learning and artificial intelligence development process."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can you tell me about the core features of cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Certainly! Cnvrg.io offers features such as data versioning, experiment tracking, collaboration tools, automation, and model deployment."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io assist with data management?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io allows users to organize, version, and manage their training data efficiently, ensuring data integrity throughout the ML lifecycle."
      }
    ],
    [
      {
        "role": "user",
        "content": "Tell me more about experiment tracking in Cnvrg.io."
      },
      {
        "role": "assistant",
        "content": "Experiment tracking in Cnvrg.io helps data scientists monitor and manage multiple ML experiments, recording parameters, metrics, and results."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can multiple team members collaborate on Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io supports collaboration among data scientists and ML teams, enabling seamless teamwork on projects."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io automate the ML process?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io may offer automation features to streamline model training, hyperparameter tuning, and other repetitive tasks."
      }
    ],
    [
      {
        "role": "user",
        "content": "What role does Cnvrg.io play in model deployment?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io facilitates the deployment of ML models in production environments and provides tools for model monitoring."
      }
    ],
    [
      {
        "role": "user",
        "content": "In which industries is Cnvrg.io commonly used?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io finds applications in various industries, including healthcare, finance, retail, and more."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can you provide examples of use cases for Cnvrg.io in healthcare?"
      },
      {
        "role": "assistant",
        "content": "In healthcare, Cnvrg.io has been used for tasks like medical image analysis, patient outcome prediction, and drug discovery."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io address data privacy and compliance concerns?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io implements security measures and features to help users adhere to data privacy and compliance regulations."
      }
    ],
    [
      {
        "role": "user",
        "content": "What are the advantages of using Cnvrg.io for fine-tuning language models like llama-7b?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io streamlines the fine-tuning process for language models by providing data management, collaboration, and experiment tracking features. It helps optimize hyperparameters and accelerates model development."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can Cnvrg.io integrate with popular deep learning frameworks?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io supports integration with popular frameworks like TensorFlow and PyTorch, making it versatile for various ML tasks."
      }
    ],
    [
      {
        "role": "user",
        "content": "What are some alternatives to Cnvrg.io for ML/AI development?"
      },
      {
        "role": "assistant",
        "content": "Alternatives to Cnvrg.io include platforms like Databricks, Google AI Platform, and Azure Machine Learning."
      }
    ],
    [
      {
        "role": "user",
        "content": "Why is Cnvrg better than its competitors?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io stands out due to its robust data versioning, collaborative capabilities, and streamlined ML workflow management. Its competitive pricing and comprehensive features make it an attractive choice for many organizations."
      }
    ],
    [
      {
        "role": "user",
        "content": "How is Cnvrg.io improving the world with MLOps?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io contributes to the advancement of MLOps by providing tools that enhance collaboration, automation, and monitoring throughout the ML lifecycle. It has helped numerous organizations streamline their ML operations, resulting in faster model development and improved decision-making."
      }
    ],
    [
      {
        "role": "user",
        "content": "What happened after Intel bought Cnvrg.io, and how is it improving Intel?"
      },
      {
        "role": "assistant",
        "content": "Intel's acquisition of Cnvrg.io aimed to enhance its AI and ML capabilities. Cnvrg.io's technology and expertise have played a significant role in improving Intel's AI product portfolio and services. The collaboration has led to various projects, including improved AI hardware and software integration and innovative AI solutions."
      }
    ],
    [
      {
        "role": "user",
        "content": "Who founded cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io was founded by Yochay Ettun and Leah Forkosh Kolben."
      }
    ],
    [
      {
        "role": "user",
        "content": "How was Cnvrg.io acquired by Intel, and why?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io was acquired by Intel to strengthen Intel's AI and ML capabilities. The acquisition allowed Intel to enhance its AI product portfolio and provide more comprehensive AI solutions to its customers."
      }
    ],
    [
      {
        "role": "user",
        "content": "What was the founder's vision for Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "The founders of Cnvrg.io envisioned creating a platform that simplifies and accelerates the development and deployment of machine learning and artificial intelligence models. They aimed to empower data scientists and ML teams with the tools needed to efficiently manage and scale their ML projects."
      }
    ],
    [
      {
        "role": "user",
        "content": "How will the success of Cnvrg.io benefit the market?"
      },
      {
        "role": "assistant",
        "content": "The success of Cnvrg.io benefits the market by advancing the field of machine learning operations (MLOps). It sets a high standard for ML platform capabilities, encouraging innovation and competition. Additionally, Cnvrg.io's success means that more organizations can leverage AI and ML to solve complex problems and drive efficiency across various industries."
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "cnvrg is designed to make running and using remote computes easier than ever.  Part of that mission is affording you the flexibility to set your environment exactly the way you need it. - cnvrg lets you manage and utilize a versatile set of computes that meet a range of needs. [Read more here](../core_concepts/compute.md). - cnvrg provides support for using custom Docker images for running experiments, launching workspaces, building flows and configuring endpoints and apps.  Every team and user has full control to build or use custom Docker images. In some cases, you would want to use a custom library without building a Docker image. To do so, you can use `requirements.txt` and `prerun.sh` files.  The topics in this page: [[TOC]]   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is cnvrg Environment Variables Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " The environment for every job in cnvrg, contains a selection of useful environment variables that you can access as part of your scripts and experiments.  The full list is as follows: sh CNVRG_COMPUTE_CPU CNVRG_COMPUTE_MEMORY CNVRG_COMPUTE_GPU  CNVRG_COMPUTE_TEMPLATE CNVRG_COMPUTE_CLUSTER  CNVRG_JOB_ID CNVRG_JOB_URL CNVRG_JOB_NAME CNVRG_JOB_TYPE   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is requirements.txt (Python) Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "There are some cases when you would like to use a different version of a library or a package that isn't installed on the machine or included in the Docker image.  To support this use case, cnvrg offers an easy solution - if a `requirements.txt` file exists in the project root directory, cnvrg will install the packages listed in the file before the workspace or experiment starts.  To use a `requirements.txt` file:  1. Create a file named `requirements.txt` and save it in the project head tree (in the main project directory). 2. Specify which Python libraries you would like to use.  ::: warning If you are creating the file in your local environment, make sure you sync the file to cnvrg or your git repo. :::  Here is an example `requirements.txt` file:   docutils==0.11 Jinja2==2.7.2 MarkupSafe==0.19 Pygments==1.6 Sphinx==1.2.2 numpy tensorflow   To generate this kind of format for your own project, run:  pip freeze > requirements.txt  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is prerun.sh Script Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "When using cnvrg to run experiments or to start a notebook, there are some cases where you would like to run a bash script before starting the experiment or notebook.  To support this use case, cnvrg offers an easy solution. When the job starts, it will search for a `prerun.sh` file and automatically run it before the experiment/notebook starts.  To use a `prerun.sh` script:  1. Create a file name `prerun.sh` and save it in the project head tree (in the main project directory). Include all the commands you wish to execute before the experiment starts. 2. Make sure to sync or push the file before starting an experiment or a notebook.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " A Docker image is one of the main building blocks that cnvrg requires to execute a job. A job can be a workspace, experiment, web app, endpoint, or flow.  While cnvrg supplies capable, ready-to-use Docker images by default, if you prefer, you can use your own images.  ::: tip NOTE The working directory of any images to be used in cnvrg will be `/cnvrg`, regardless of what is set in the Dockerfile. To find out all the requirements for your custom images, read the [requirements for custom images section](../core_concepts/environments.md#requirements-for-custom-images). :::  cnvrg lets you:    * **Build your own Docker image**: You upload a custom Dockerfile. cnvrg builds the Docker image and pushes it to the private registry that you choose.  - While the image is being built, the build log is streamed live. - Once the image is ready, it is added to the table of images. - You receive an email notification about the success or failure of the image build.  ::: tip NOTE You can only build and push an image once you have [connected cnvrg to a custom registry](../core_concepts/environments.md#connecting-to-a-private-docker-registry). :::    * **Pull a Docker image**: You specify the information of an existing Docker image.  After successfully adding a docker image, [you can select the newly created Docker image](environments.md#using-the-new-image-when-running-jobs) when you run a workspace or an experiment. When selected, the image will be pulled Kubernetes node and be used to run that specific job. If the image is already available locally, it will not be pulled but just loaded. For AWS, cnvrg creates a new AMI. For on-premise machines, the Docker image must be available locally on the machine.  ::: tip NOTE You can pull images from public registries without connecting to them.  [Some registries come pre-configured in cnvrg](../core_concepts/environments.md#default-registries). :::  ::: tip You can also access the build image and pull image screens from within the page of the relevant registry. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Build a custom Docker image Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  1. Go to the **Containers** tab of your organization. 2. Click **Add Image**. 3. In the pane that appears, click **Build Image**. 4. In the drop-down list, select the **Registry** that the image will be pushed to. 5. Type in the **Repository** name and **Tag** of the image that will be created. 6. In the **Compute** drop-down list, click one or more compute engines. cnvrg will attempt to run the job on the first available compute engine that you selected. 7. Paste in your custom Dockerfile. Each time you edit the Dockerfile and click **Add,** cnvrg pushes it again to the relevant repository. 8. (Optional) Type in a Readme. 9. (Optional) Click **Change Logo** and select an image from the list provided. 10. Click **Add**.  cnvrg builds the image and pushes it to the relevant repository and adds the image to the list of your available Docker images.     "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Pull a custom Docker image Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  1. Go to the **Containers** tab of your organization. 2. Click **Add Image**. 3. In the pane that appears, click **Pull Image**. 4. Either: - Type in the full Docker URL; or - Select the registry in the drop-down list, type in the repository and type in the tag. 5. (Optional) Type in a Readme. 6. (Optional) Click **Change Logo** and select an image from the list provided. 7. Click **Add**.  cnvrg adds the image to the list of your available Docker images.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Custom images with on-premise compute Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " If you are using on-premise hardware with cnvrg, there are a few differences in the Docker image process.  **Building a Docker image**  If you build an image on on-premise compute, you have the option to not push the image to a registry. In this case, the image will be built and available for use on on-premise hardware locally.  ::: tip NOTE You can still push the image if you so choose. :::  **Pulling a Docker image**  You cannot pull a Docker image to on-premise hardware. To use a specific Docker image on on-premise hardware you must first ensure it is available locally on the machine.  Then, [add the details of the Docker image to cnvrg](../core_concepts/environments.md#add-your-own-custom-docker-image) and choose the **Pull from existing repository option**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Requirements for custom images Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " cnvrg is designed to make using custom Docker images as easy as possible, however there are a few important notes.  - You must install the code language of your choice (Python, R and others). - To use R Studio or R Shiny you must install them yourself. - You must have `pip` installed (version > 10.0). - To use your custom image with a Visual Studio Code workspace, you must install `tar`. - While cnvrg will clone your git repository for you when stating a job (when your project is linked wit git), if you want to use git commands (for example, `git push`), you must install `git` and `ssh` yourself. - When using the container in cnvrg, the project will be downloaded or cloned into `/cnvrg`. You do not need to set this as the `WORKDIR` in your Dockerfile.  If you have the **Install Job Dependencies Automatically** organization setting enabled, your custom Docker image will automatically work with all of the cnvrg features (workspaces, serving, experiments and so on). This includes the cnvrg SDK. The toggle for this feature can be found in your organization **Settings**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Recommendations when Install Job Dependencies Automatically is enabled Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " While not required, we suggest you [install the cnvrg CLI](../cli/install.md) in your Docker image so that you can use all of the CLI commands. Otherwise, the CLI will only be usable in the folders `/cnvrg` (the workdir) and `/data` (where datasets are mounted).  To use git easily inside a JupyterLab workspace we recommend you install the [JupyterLab git extension](../core_concepts/environments.md#jupyerlab-git).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Required packages when Install Job Dependencies Automatically is disabled Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " If you have the  **Install Job Dependencies Automatically** organization setting disabled, you will need to install the required packages yourself. You will also be unable to use the cnvrg [CLI](../cli/install.md) and [SDK](../core_concepts/python_sdk#download-and-install-cnvrg-python-sdk) unless you install them yourself.  Here is a table outlining the required packages to install for each feature you want to use your custom Docker image with.  *You may need to scroll horizontally to see the full table.*  | Package | Experiments | JupyterLab Workspace | R Studio Workspace | Shiny App | Dash App | Voila App | Tensorboard Compare | Serving | | --: |:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:| |tensorboard|:white_check_mark:|:white_check_mark:| | | | |:white_check_mark:| |butterfly|:white_check_mark:| |jupyterlab| |:white_check_mark:| |jupyterlab-git| |:white_check_mark:| |RStudio| | |:white_check_mark:| |dash| | | | |:white_check_mark:| |dash-daq| | | | |:white_check_mark:| |voila| | | | | |:white_check_mark:| |pygments| | | | | |:white_check_mark:| |gunicorn| | | | | |:white_check_mark:| |:white_check_mark: |flask| | | | | | | |:white_check_mark:|   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io handle model versioning?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io provides model versioning capabilities to track and manage different versions of machine learning models. This helps in maintaining a history of model changes and allows for easy comparison and rollback to previous versions."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can you explain the benefits of using Cnvrg.io for model deployment?"
      },
      {
        "role": "assistant",
        "content": "Certainly! Cnvrg.io streamlines the model deployment process by offering tools for containerization, orchestration, and monitoring. It ensures that ML models can be deployed into production environments quickly and efficiently, reducing time-to-market."
      }
    ],
    [
      {
        "role": "user",
        "content": "What is the typical workflow when using Cnvrg.io for machine learning projects?"
      },
      {
        "role": "assistant",
        "content": "The typical workflow in Cnvrg.io involves data preparation, model development, experimentation, training, deployment, and monitoring. Cnvrg.io provides tools and features for each stage of the ML project lifecycle, making it a comprehensive platform."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io assist in data management?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io allows users to organize, version, and manage their training data efficiently. It offers data cataloging and tracking features to ensure data integrity and accessibility throughout the ML pipeline."
      }
    ],
    [
      {
        "role": "user",
        "content": "Are there any tools or features in Cnvrg.io for natural language processing tasks?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io provides tools and libraries for natural language processing (NLP) tasks. It supports NLP model development, training, and deployment, making it suitable for NLP projects."
      }
    ],
    [
      {
        "role": "user",
        "content": "What is the user interface like in Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io offers a user-friendly web-based interface that allows users to interact with the platform, manage projects, track experiments, and collaborate with team members."
      }
    ],
    [
      {
        "role": "user",
        "content": "What types of data sources can be connected to Cnvrg.io for training datasets?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io supports various data sources, including cloud storage, databases, and on-premises data sources. Users can connect to data repositories to access and use training datasets."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io handle large-scale data preprocessing for ML projects?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io offers data preprocessing capabilities, including data transformation and cleaning tools. It can scale to handle large datasets and automate data preprocessing tasks."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can Cnvrg.io assist in automating the process of data labeling and annotation?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io provides tools for data labeling and annotation automation. It helps in accelerating the data preparation process for machine learning projects."
      }
    ],
    [
      {
        "role": "user",
        "content": "What security measures are in place to protect sensitive data within Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io implements security features such as encryption, access controls, and audit trails to protect sensitive data. It complies with industry standards and regulations to ensure data security."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io support multi-cloud deployment for ML models?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io can deploy ML models to multi-cloud environments. It offers flexibility in choosing cloud providers and managing deployments across different cloud platforms."
      }
    ],
    [
      {
        "role": "user",
        "content": "What are the options for model deployment in Cnvrg.io? Is it compatible with Kubernetes?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io provides options for deploying models in containers or through Kubernetes. It offers flexibility in choosing deployment methods based on your requirements."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can you provide examples of successful case studies using Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Certainly! There have been numerous successful case studies where organizations have used Cnvrg.io to accelerate ML development, improve model accuracy, and optimize operations. These case studies showcase the platform's impact across various industries."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io handle model explainability and interpretability?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io offers model explainability and interpretability features to help users understand and interpret model predictions. It provides tools and visualizations to gain insights into model behavior."
      }
    ],
    [
      {
        "role": "user",
        "content": "What types of customizations can be made to Cnvrg.io for specific use cases?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io allows for customizations through plugins, APIs, and integrations. Users can tailor the platform to meet specific use case requirements and extend its functionality."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io address challenges related to bias and fairness in machine learning?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io includes features for bias detection and mitigation in ML models. It helps users identify and address bias and fairness issues in their models, promoting ethical AI practices."
      }
    ],
    [
      {
        "role": "user",
        "content": "What industries have seen the most significant benefits from using Cnvrg.io?"
      },
      {
        "role": "assistant",
        "content": "Various industries have benefited from using Cnvrg.io, including healthcare, finance, retail, and manufacturing. The platform's versatility makes it applicable to a wide range of use cases."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io support transfer learning and pre-trained models?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io supports transfer learning by allowing users to leverage pre-trained models and fine-tune them for specific tasks. It provides the tools and infrastructure needed for transfer learning projects."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can Cnvrg.io be used for reinforcement learning projects?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io can be used for reinforcement learning projects. It provides the necessary resources and capabilities for developing and deploying reinforcement learning models."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io facilitate the collaboration between data scientists and data engineers?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io offers collaborative features that allow data scientists and data engineers to work together seamlessly. It provides tools for sharing code, data, and insights, promoting collaboration across teams."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io assist in optimizing hyperparameters for deep learning models?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io includes hyperparameter optimization tools that help users find the best hyperparameters for their deep learning models. It automates the tuning process to improve model performance."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can Cnvrg.io handle multi-modal data for AI projects?"
      },
      {
        "role": "assistant",
        "content": "Yes, Cnvrg.io is capable of handling multi-modal data, which includes different types of data such as text, images, and audio. It provides the flexibility to work with diverse data sources."
      }
    ],
    [
      {
        "role": "user",
        "content": "What is the pricing structure for Cnvrg.io, and are there different tiers or plans?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io typically offers a pricing structure based on usage and requirements. It may have different tiers or plans to cater to the needs of various organizations."
      }
    ],
    [
      {
        "role": "user",
        "content": "How does Cnvrg.io handle data version conflicts and merge requests in collaborative projects?"
      },
      {
        "role": "assistant",
        "content": "Cnvrg.io provides features for handling data version conflicts and merge requests in collaborative projects. It ensures that changes to data and code are tracked, documented, and reviewed before merging."
      }
    ],
    [
      {
        "role": "user",
        "content": "Can you provide insights into Cnvrg.io's approach to data versioning and lineage tracking?"
      },
      {
        "role": "assistant",
        "content": " ::: warning Creating a Dockerfile and building a working custom image can be a very technical process. Each situation can be different and will require you to do your own research while building your Dockerfile.  The following code snippets are examples and may not work in your own Dockerfile. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use cnvrg CLI Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN apt-get install -y ruby ruby-dev RUN gem install cnvrg --no-ri --no-rdoc  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use pip (version > 10) Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip install --upgrade pip   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use tar Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " RUN apt-get install tar   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use cnvrg SDK Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip install cnvrg   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use TensorBoard Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install tensorboard   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Butterfly Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install butterfly   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use JupyterLab Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install jupyterlab   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use JupyterLab-git Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN jupyter labextension install @jupyterlab/git RUN pip3 install jupyterlab-git && jupyter serverextension enable --py jupyterlab_git   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dash Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install dash   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dash DAQ Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install dash-daq   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Voila Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install voila   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Pygments Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install Pygments   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Gunicorn Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install gunicorn   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Flask Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  RUN pip3 install flask   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use R Studio Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " The simplest method is to build your image based on a Rocker image.  FROM rocker/rstudio:latest   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use R Shiny Installation guides for packages Add a Custom Docker Image Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "The simplest method is to build your image based on the official R Shiny Rocker image.  docker pull rocker/shiny   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Docker Images in Jobs Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " There are three ways to choose a Docker image for a job:  - Using the image selector in the web UI - Using the CLI - Using the SDK  ::: tip NOTE cnvrg will always pull the latest version of the Docker image and tag as chosen for the job. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the image selector in the web UI Using Docker Images in Jobs Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "   You can use the image selector to choose a Docker image when starting a workspace, preparing a flow task, creating a new experiment, or deploying an endpoint from the web UI.  1. Click **Start Workspace**, **New Experiment**, choose your **Task** or **Publish**. Fill in the other relevant details in the pane that appears. 2. To choose your image, click the **Image** drop-down list. 3. First, click the image repository toggle list you want to use. 4. Then click the tag of your choice from the list. The repository and tag will now be selected in the **Image** drop-down list. 5. Click **Start Workspace**, **Run**, **Save Changes** or **Deploy Endpoint**.  The selected image will be used as the virtual environment.  ::: tip The image selector is found in the **Environment** subsection for experiments and in the **Advanced** tab for flow tasks. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the cnvrg CLI Using Docker Images in Jobs Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " To use your new image [through the CLI](../cli/install.md#run-a-new-experiment), add the `--image` flag in the `run` command. For example:   cnvrg run --image=\"tensorflow:19.07\" python3 mnist.py  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the Python SDK Using Docker Images in Jobs Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " In the [`run()` SDK call](../core_concepts/python_sdk.md#create-an-experiment), pass in the name of the image. For example:  python from cnvrg import Experiment() e=Experiment() e.run(python3 train.py, image=\"tensorflow:19.07\")    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  In cnvrg, you can connect to other Docker registries, beyond the registries provided by default.  This allows you to pull from these registries and easily add new images to cnvrg from them. In the case of a private registry, you can also build and push new images to them.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Default registries Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use cnvrg Default registries Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " Your system is automatically connected to cnvrg's Docker registries. These contain the default images that are built and maintained by the cnvrg team.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use NVIDIA NGC Default registries Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " cnvrg has seamless integration with NVIDIA's NGC platform. Without any further setup, you can pull all of NVIDIA's Docker images.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Docker Hub Default registries Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " cnvrg is connected with the official Docker Hub registry. You can pull from any public repositories within Docker Hub by simply adding the details to cnvrg. Follow the instructions [here](../core_concepts/environments.md#add-your-own-custom-docker-image).  ::: tip To pull an image from a public registry, you do not need to connect to it beforehand. However, it is however best practice to connect to it. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a registry to cnvrg Connect to a Docker Registry Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  To add a private or public registry to cnvrg:  1. Go to the **Containers** tab of your organization. 2. Click **Add registry**. 3. From the list of registries, select the registry you wish to connect to. 4. In the **Registry URL** field, type in the full registry URL. 5. Type in a title for the new registry.  :::tip NOTE If you require authentication for the new registry, click **Authentication**, then provide a username and password.  Authentication is optional, because most cloud providers can be connected directly to the Kubernetes cluster and additional authentication is unnecessary. It may also be a public registry. ::: 6. Click **Save**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Explore your Docker Images Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " cnvrg provides a set of images that meet most of the needs of data scientists working in machine learning settings. Using a ready-made image saves you the often complex task of building Docker images that cnvrg supports.  You can also [add your own custom Docker images to use within cnvrg](../core_concepts/environments.md#custom-docker-images).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Viewing your available Docker images Explore your Docker Images Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": "  To view the images and registries that are known to cnvrg, navigate to the **Containers** tab of your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Registries Viewing your available Docker images Explore your Docker Images Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " Along the top of the pane are the registries that cnvrg has been configured to connect to.  A registry is a storage and content delivery system, holding repositories, within which are the Docker images, available in different tagged versions.  There are two types of registries in cnvrg: - **Public**: cnvrg, Docker Hub, NVIDIA, and others. These registries are marked with a globe. Images can only be *pulled* from the public registries provided with cnvrg. You will not be able to push new images to them from within cnvrg. - **Private**: ACR, ECR, GCR, NVIDIA private, Docker Hub private and others. Images can be *both pulled from and pushed to* a private registry.  You can [connect cnvrg to any additional registry](../core_concepts/environments.md#add-a-registry-to-cnvrg) to which you have access.  Clicking an entry will display the registry's page. From there, you can edit and delete the registry as well as add images (build and pull).    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Images Viewing your available Docker images Explore your Docker Images Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " In the lower area is a table showing the Docker images that are known to cnvrg: both the images that are provided by default with the product (they reside in the cnvrg registry), as well as images that you have added.   For each image, the following information is provided:  - Status - Repository name - Tag - Registry name - Creation date - Author name   You can sort and filter the data in the table.  Clicking an entry in the table displays a summary of the image and its Readme. From there, you can edit and delete the image.  ![General](../images/image-page.png \"General\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Custom Python Modules Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " You can use your own custom Python modules within cnvrg. To avoid any issues, you should follow best practices when setting up your custom modules:  1. Create and add a file named `__init__.py` to the modules folder in your file structure. 2. Add the following code snippet to the beginning of the code you are executing:  python import os, sys from os.path import dirname, join, abspath sys.path.insert(0, abspath(join(dirname(__file__), '..')))   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Git Submodules Cnvrg Environments"
      },
      {
        "role": "assistant",
        "content": " If your project is connected to a git repository that contains submodules, you must add the following to the `prerun.sh` file in your repo or **Files**. You must also have an [OAuth git token set for your user account](../core_concepts/projects.md#oauth-token).  If you do not already have a `prerun.sh` file, create one, and then add the following code.  Add to your `prerun.sh` file: bash git config --global url.\"https://x-access-token:${GIT_REPO_CLONE_TOKEN}@github\".insteadOf https://github git submodule init git submodule update   ::: tip A `prerun.sh` script allows you to run commands to further customize your environment at the start of every job. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " Flows in cnvrg are production-ready machine learning pipelines that allow you to build complex DAG (directed acyclic graph) pipelines and run your ML components (tasks) with just drag-n-drop.  Each task in a flow is an ML component that is fully customizable and can run on different computes with different docker images. For example, you can have feature engineering running on a Spark cluster, followed by a training task running on a GPU instance on AWS.  Each run of the DAG will produce an experiment for fully tracked and reproducible machine learning.  ![Flows](../images/flows.png \"Flows\")  The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "A Flow can have an unlimited number of components. A component can be a data task, custom task or deploy task. Each task is flexible and able to leverage different types of computes, environments, and frameworks.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Data Tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "A data task represents your datasets that are hosted and accessible via the cnvrg platform. You may select any dataset, with a specific version or query. Additionally, you can add multiple data tasks as well.  Adding a data task to your Flow, will automatically mount the chosen dataset to the connected task. For example, if you add the `hotdogs` dataset and connect it to VGG/ResNet/InceptionV3 (as in the image above), then the dataset `hotdogs` will be accessible in each of the tasks.  ::: tip A mounted dataset will be accessible at `/data/dataset_name`. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Custom tasks and AI Library tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "A task in cnvrg represents a machine learning component. A task could be any component that you'd want and there is full flexibility to design and code it however you need.  A task holds the following information:  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Parameters tab Custom tasks and AI Library tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "- **Command:** Every task starts with a command. It could be your Python script or any other executable (R/Bash/Java/etc). For example: python3 train.py - **Parameters:** Hyperparameters, data paramaters, or any kind of argument you would like to pass to your command. All parameters are automatically captured for reproducible data science.  ::: tip For parameters, you can also use comma separated values and cnvrg will automatically run an experiment for each permutation as in a grid search. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Conditions tab Custom tasks and AI Library tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "* Add a [condition](#conditions) that will dictate wether or not the task is executed. * Choose users who will [approve](#human-validation) the execution of the task.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Advanced tab Custom tasks and AI Library tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "- (If project connected to git) **Git Branch** and **Git Commit**: Which git branch and commit to clone when executing the task. - **Compute**: The compute template/s that the task will try to run on. - (If project connected to git) **Output Folder**: Which folder you will save artifacts to. The contents of only this folder will be available in the following tasks. - **Container**: The Docker image to use for the viryal environment of the task.  ![Task popup](../images/task-popup.png \"Task popup\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use YAML Custom tasks and AI Library tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "The YAML config representation of the task.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Deploy tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Setup tab Deploy tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "Fill in the information for the web service you will be creating or updating:  To update an existing web service, choose the name of the endpoint from the **Select Endpoint** menu.  To create a new web service, click **+ Add New** from the **Select Endpoint** menu. Then fill in the required details for the service: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute tha the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **File**: The file containing your predict function. * **Function**: The function name of your predict function. Click **Advanced Settings** to reveal advanced options: * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * **Language**: Which language your service is in. * **Flask Config**: Change any flask config variables for any specific configuration you desire. * **Function accepts file as input**: Enable or disable the ability for the model to accept files as an input.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Conditions tab Deploy tasks Flows Components Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "* Add a [condition](#conditions) that will dictate wether or not the task is executed. * Choose users who will [approve](#human-in-the-loop) the execution of the task.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is The Files in a Task Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " Similar to the execution of any other machine learning workload in cnvrg, when a task is executed, it constructs its environment as follows:  1. Pull and execute the chosen container. 2. Clone the chosen git branch and commit (if project connected to git) into `/cnvrg`. 3. Clone the latest version of the files from your projects **Files** tab and artifacts from preceding tasks into their respective `/input` folders. 4. Install packages from the `requirements.txt` file (if it exists). 5. Execute the `prerun.sh` script (if it exists).  Only after all these steps have been completed will the task execute the given **Command**. That means you can call or use any of the files made available by the prepeartion of the environment as the **Command** or from within you code.  For more information see [Environment](../core_concepts/environments.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Artifacts Flow Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " Each task in the flow has access to all of the artifacts of each of the previous connected tasks. The files can be found and accessed from the `/input/task_name/` folder for each preceding connected task. The folder contains the entire end commit of the corresponding task.  The folder name for the task, is the name of the preceding task in lowercase with spaces substituted as underscores and extra symbols removed. For example, artifacts of the task named `Processing the Data` are loaded in `/input/processing_the_data/` in the following task.  Each input path is exported as an environment variable in the task and the naming is in uppercase and with `INPUT_` pre-pended but otherwise follows the above rules. The corresponding example environment variable is `INPUT_PROCESSING_THE_DATA`  For example, if `Task A` creates a file named `output.txt`, that file will be cloned to `/input/task_a/` in the following task and could be accessed from the full path `/input/task_a/output.txt`.  When a task is run in [Single mode](#single-mode), artifacts from preceding tasks are not cloned into the task.  ::: tip If your project is connected to git, only the files that are saved to the chosen **Output Folder** (`/output` by default) will be available in the following tasks. They will be available in `/input/task_name/PATH-OF-OUTPUT-FOLDER/`. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Tags & Parameters Flow Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "Each task can produce [tags like hyperparameters, metrics, and more](../core_concepts/experiments.md#tracking-and-visualizing). The parameters and tags of preceeding tasks are available as environment variables within the following tasks.  The key (name) of the environment variable will be in the following format:  For tags in current task:  `CNVRG_TAG_<TAGNAME>`  For tags from previous tasks:  `CNVRG_<TASKNAME>_<TAGNAME>`  The variable will always be in all uppercase (even if the original parameter was not). Spaces in task and tag names will be substituted for underscores. For example, if you had a parameter in `Task A` named `model accuracy`, the corresponding environment variable in following tasks is `CNVRG_TASK_A_MODEL_ACCUARCY`.  You can use a tag from a previous experiment as a parameter by using the following format:  `{ { task name.tag name } }`  The tag will retain the same casing (uppercase and lower case letters) as was recorded in the task where it was created. Spaces in task and tag names are preserved. For example, if you had a parameter in `Task A` named `model accuracy`, the corresponding format is `{ { Task A.model accuracy } }`.  ![Task params flow](../images/tags-params-flow.png \"Task popup\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "Running the Flow by clicking the **Play** button in the flow bar <img src=\"../images/flow-play-icon.png\" width=\"30\"> will execute the Flow's DAG in an optimized way using your cloud/on-premise compute resources.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Experiments Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " Each run will generate an experiment page so you can track in real-time the progress of your flow. Using the experiment page, you'll be able to track metrics, hyperparameters, algorithms, and more. Additionally, you also have the option to stop and terminate runs.  A flow route on the experiments page has a tab for each task. Tasks in the flow that have yet to be run will be grey-ed out before they begin executing.  ![Flow route experiments](../images/flow-routes-experiments.png \"Flow route experiments\")  ::: tip You can use [the experiment comparison feature](../core_concepts/experiments.md#comparing-and-organizing) to visualize different models and routes to understand your Flow performance better. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Flow Routes Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " cnvrg will dynamically create the flow routes for your executions. When you start running a flow, it will begin by running the first tasks (and their grid searches). Once those are complete, cnvrg will calculate the next steps of the flow and calculate the how many new experiments need to be run (and accordingly how many flow routes there will be).  This means that when you start running a flow, you may not see the full extant of the flow routes immediately, however, as the flow runs, more routes will appear on the experiments page.  Each task will wait for any preceding connected tasks to complete before starting to run. This way, multiple tasks can be inputs to a single task that runs on the output of several tasks.  ![Flow route](../images/flow-route.png \"Flow route\")  In the above image, `Task C` will only run once `Task A` and `Task B` have concluded. `Task C` will have access to the outputs of both `Task A` and `Task B`. There is only 1 route.  This amount of times `Task C` will need to be run however, is only calculated when `Task A` and `Task B` complete.  ![1 route](../images/the-route.png \"A Flow route\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Grid Searches Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " Each task can conduct a grid search over the parameters you enter. A single task will run once for each combination of parameters. Any following tasks will then run once for each of the preceding task's combinations and once for each experiment in its grid search.  Specifically, each task in the graph will run `N` times where `N` is the number of permutations in its internal grid search `X` times its parents number of permutations `Y`. `N=X*Y`  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example: 2 grid searches Grid Searches Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   In the above example, the first task `Grid Search A` consists of 3 experiments which is followed by a second task `Grid Search B` of 3 experiments. This will result in 9 (`3*3`) different flow routes, accommodating all the permutations.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example: 3 grid searches Grid Searches Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   In the above example, both `Grid Search A` and `Grid Search B` are connected to `Grid Search C`. `Grid Search A` consists of 2 experiments, `Grid Search B` consists of 3 experiments and `Grid Search C` consists of 5 experiments. When the flow is run, cnvrg will execute 30 (`2*3*5`) flow routes.     "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dynamic Routes Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " You can dynamically create flow routes based on the tags of a preceding task. When using this mode, the task will run once for each value in the chosen tag.  To use this feature, use the following format as a parameter in a task: `{ { task name.tag name | hyper } }`: - `task name` is the preceding task with the desired tags - `tag name` is the tag you are using to generate the routes    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example: Dynamic Route Dynamic Routes Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   In the above example, `Params` creates a parameter called `route` with the value `1,2,3` and, `Dynamic [?]` has a parameter set as `{ { Params.route | hyper } }`.  When executed, the `Params` task will run. Afterwards, cnvrg will check the `route` tag in the previous experiment and find 3 values. cnvrg then dynamically creates 3 experiments for the `Dynamic [?]` task, each with a different value for `route` (`1`, `2` and `3`)   ::: tip The tag can be made with the SDK:  py from cnvrg import Experiment e = Experiment() e.log_param(\"route\", \"1,2,3\")   Or by printing to STDOUT:  `print(\"cnvrg_tag_route: 1,2,3\")` :::    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Single mode (beta) Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   Single mode allows you to run a task without considering the permutations of the preceding tasks. When Single mode is enabled, the task will run once, or as many times as its own grid search requires.  When you use Single mode the artifacts from preceding tasks are not cloned into the task's environment.  You can enable Single mode from the **Advanced** tab of a task and enabling the **Single mode** toggle.  ::: warning Please note, this feature is currently in beta. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example: 2 grid searches followed by task in single mode Single mode (beta) Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   In the above example, both `Grid Search A` and `Grid Search B` are connected to `Single mode C`. `Grid Search A` consists of 2 experiments, `Grid Search B` consists of 3 experiments and `Single mode C` is 1 experiment with Single mode enabled. When the flow is run, cnvrg will execute 6 (`2+3+1`) flow routes.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example: 2 grid searches followed by grid search in single mode Single mode (beta) Execution and Reproducibility Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   In the above example, both `Grid Search A` and `Grid Search B` are connected to `Single mode C`. `Grid Search A` consists of 2 experiments, `Grid Search B` consists of 3 experiments and `Single mode C` is a grid search that consists of 5 experiments with Single mode enabled. When the flow is run, cnvrg will execute 10 (`2+3+5`) flow routes.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Conditions Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "   You are able to add conditions on custom tasks, deploy tasks and AI Library tasks within your flow which will control which of the previous experiments will continue to the new task (which you are adding the conditions to). A condition can be set for any of the [cnvrg Research Assistant Tags](experiments.md) within your experiments.  To set a new condition, click the chosen task and then click the **Conditions** tab in on the card that appears.  1. Choose which previous tasks in the flow will have the conditioning tested against them. 2. Write the name of the cnvrg Research Assistant tag you will be testing. 3. Choose the type of test (see the list below). 4. And choose the value (if applicable) that will need to be passed in the condition.  A condition can be any of the following: - Greater than (>): any experiments with the matching tags value greater than the value will continue. - Less than (<): any experiments with the matching tags value less than the value will continue. - Equal (=): any experiments with the matching tags value equalling the value will continue. - The Maximum: the experiment with the highest value for the matching tag will continue. - The Minimum: the experiment with the highest value.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Human Validation Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " You are able to set mandatory approvals on exec tasks, deploy tasks and AI Library tasks within your flow. If human validation is enabled for a task, the task will not begin executing until the approval is received from one of the chosen users.  When the flow reaches a task with human validation enabled, the chosen users will receive an email notification alerting them that the task is awaiting their confirmation. The email will contain a link to the flow and the pending task. They can then access the flows page, read information about the previous tasks, and decide wether or not to approve the next task to run. If they approve the task, the flow will continue, otherwise the flow will be aborted.  A flow that contains a task that is pending approval, will have the status **Pending Approval** as per the experiments table and within the page for the flow run. The individual task awaiting approval will also have status **Pending Approval**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Enable Human Validation on a task Human Validation Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " To enable approvals for a task, click on the desired task and then click on the **Conditions** tab: 1. Enable approvals by clicking the toggle under **Human Validation**. 2. In the user selector, choose the users that will be given the authority to approve the task.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Approve or reject a task Human Validation Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " If a task is awaiting approval, the relevant users will receive an email notification. To approve or reject the task: 1. Open the page for the task awaiting approval. 2. The approval pop up will appear automatically, either select **Approve** or **Cancel** as desired.  If you would like to view more information about the previous tasks, click away from the pop up and it will disappear. Once you are ready to approve or reject the task: 1. Click **View** next to the status **Pending Approval**. 2. In the pop up, either select **Continue Flow** or **Stop Flow** as desired.  The flow will continue to run or be aborted according to the decision made.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Edit flow title Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "--- You can easily edit your Flow title by clicking the title on the top left of the Flow canvas. <img src=\"../images/flow-title.png\" width=\"400\">    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Versioning Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "--- cnvrg allows you to manage and create versions of your Flows. You can save a Flow and revert back to previous versions with just a click. To do so, click the dropdown next to your Flow title. <img src=\"../images/flow-versioning.png\" width=\"400\">  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Continual Learning Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "--- Continual learning is a method of machine learning, in which input data is continuously used to extend the existing models knowledge that is, to further train the model.  cnvrg made it easy for you to set Continual Learning to your flow. Click the magic-wand icon &nbsp;<img src=\"../images/continual-learning-icon.png\" width=\"20\" height=\"20\">&nbsp; in the Flow bar to open the Continual Learning popup.  <img src=\"../images/continual-learning-popup.png\" width=\"500\">  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Continual Learning Triggers Continual Learning Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " * **Dataset updates** - The flow will be triggered whenever there's a new version of the chosen dataset. * **Webhook** - The flow will be triggered when the webhook URL will be triggered  ::: tip Your latest version of the flow will run when triggered. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Scheduling Settings Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "--- You may schedule your Flow to run periodically by clicking the Clock icon in your Flow bar &nbsp;<img src=\"../images/scheduling-icon.png\" width=\"20\" height=\"20\" >&nbsp; and select the schedule in the popup:  <img src=\"../images/scheduling-popup.png\" width=\"500\">  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "A YAML file may be used to create or edit a flow. Flow YAML files store the flow title, all task parameters and relationships between tasks. To create (or edit) a flow using a YAML file click the &nbsp;<img src=\"../images/flow-yaml.png\" width=\"20\" height=\"20\">&nbsp; icon, and an editor will open in a popup. Any changes made in the popup will be saved to the file only after clicking **Save**. Alternatively you can import a flow to the project using the CLI:  cnvrg flow import --file=MY_FILE.yaml  Or run a flow directly from a YAML file:  cnvrg flow run --file=MY_FILE.yaml  A flow YAML file consists of the following sections: | Key | Value | Required | Description | | :---: | :---: |:---: | :--- | | flow: | TITLE | Yes | The title of the flow | | tasks: | LIST_OF_TASKS | Yes | The tasks that exist in the flow | | relations: | -RELATION | Yes | List of the relationships between tasks. A relationship consists of `from:` (input) and `to:` (output). | | schedule: | DATE TIME | No<sup>*</sup> | When to run the flow. You can specify the time using either a 24- or 12-hour clock format. For example: To specify 4:25 PM on the 31st of January 2012, you can specify any of these: `31.01.2021 16:25`, `31.01.2021 4:25PM`, `2021.01.31 16:25`, `2021.01.31 4:25PM`. | | recurring: |  CRON | No<sup>*</sup> | Set a schedule for executing a recurring flow. Specify the schedule using [Cron format](https://en.wikipedia.org/wiki/Cron). For example, to execute the flow at 30 minutes past every hour, specify: `\"30 * * * *\"`|  ::: tip NOTE `schedule:` and `recurring:` cannot be used together. if neither are used, the flow will run immediately when triggered. :::  For example: :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Immediate Flow\" yaml flow: FLOW_NAME tasks: - task 1 . . . - task n relations: - from: to: . . . - from: to:  ::: ::: tab \"Scheduled Flow\" yaml flow: FLOW_NAME tasks: - task 1 . . . - task n relations: - from: task1_title to: task2_title . . . - from: taskn-1_title to: taskn_title schedule: 31.01.2021 16:25  ::: ::: tab \"Recurring Flow\" yaml flow: FLOW_NAME tasks: - task 1 . . . - task n relations: - from: task1_title to: task2_title . . . - from: taskn-1_title to: taskn_title recurring: \"30 * * * *\"  ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "For each task there are both required and optional fields. Some are unique per task type and other are general for all tasks.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Fields for all tasks Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " The following table includes fields that are relevant for each of the types of flow tasks:  | Key | Value | Required | Description | | :---: | :---: |:---: | :--- | | title: | TASK_TITLE | Yes | This field is the name for the task. | | type: | data OR exec OR deploy| Yes| Set the type of task you are defining. Either `data`, `exec` or `deploy`. | | description: | \"task description\" | No | The description of the task to appear in the documentation. | | top: | int | No | The position of task card in the UI, relative to the top.  | | left: | int| No | The position of task card in the UI, relative to the left. |  ::: tip NOTE If `top` and `left` keys aren't specified corresponding task blobs will appear at the top left corner. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Condition fields for custom and deploy tasks Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " The condition field for an custom or deploy task can contain a condition that must be reached in order for the flow to advance. Each condition consists of a `target:`, `task:`, `objective:`, `tag_key:` and `value:`. This format is used both for regular conditions (where a metric is checked automatically) and approval conditions (where a user's approval is required).  For regular conditions, only `target:`, `task:`, `objective:` and `tag_key:` are used. For approval conditions, only `objective:` and `value:` are used.  | Key | Value  | Description | | :---: | :---:| :--- | | target: | float | The value that your metric is checked against. Leave this field blank for Human-in-the-loop conditions. | | task: | name_of_previous_task | Which previous task this condition will be run on. If blank, all tasks will be subjected to the condition. Leave this field blank for Human-in-the-loop conditions.| | objective: | min/max/gt/lt/eq/human_validation | The form of comparison. Either `min` (minimum), `max` (maximum), `gt` (greater than), `lt` (less than), `eq` (equals) or `human_validation` (Human-in-the-loop) | | tag_key: | KEY | The metric that is being checked in the condition. Should be a metric being tracked in the experiment. Leave this field blank for Human-in-the-loop conditions.| | value: | USERNAME1,USERNAME2,... | The comma-separated usernames of users who will be asked to approve the running of this task. Leave this field blank for normal conditions. |   See the below examples for clarification:  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Human Validation\" yaml conditions: - objective: human_validation # this task will ony run when approval is received value: Leah,Yochay          # the task can be approved by these users  ::: ::: tab Maximum yaml conditions: - target: 0.0       # ignored when objective is max task: objective: max    # only the task with the maximum for the chosen metric will continue tag_key: accuracy  ::: ::: tab Minimum yaml conditions: - target: 0.0       # ignored when objective is min task: objective: min    # only the task with the minimum for the chosen metric will continue tag_key: loss  ::: ::: tab \"Greater than\" yaml conditions: - target: 0.9 task: objective: gt     # only tasks with the where the chosen metric is greater than the target will continue tag_key: accuracy  ::: ::: tab \"Less than\" yaml conditions: - target: 0.1 task: objective: lt     # only tasks with the where the chosen metric is less than the target will continue tag_key: loss  ::: ::: tab Equals yaml conditions: - target: 0.95 task: objective: eq      # only tasks with the where the chosen metric is equal to the target will continue tag_key: accuracy  ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Data task fields Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " The following table includes the fields that can be specified for a data task. Make sure to include the required tasks from the [general table](#fields-for-all-tasks) as well:  | Key | Value | Required | Description | | :---: | :---: |:---: | :--- | | dataset: | DATASET_NAME | Yes| The name of the dataset to be used. | |data_commit: | COMMIT_SHA1 | No | Which commit to use of the dataset. If blank, the latest version will be used. Leave blank if using `data_query`. |data_query: | QUERY_NAME | No | Which query to use of the dataset. Leave blank if using `data_commit`. | | use_cached: | boolean | No | Wether to use the cache of the chosen commit. |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Custom task fields Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": " The following table includes the fields that can be specified for a custom task. Make sure to include the required tasks from the [general table](#fields-for-all-tasks) as well:  | Key | Value | Required | Description | | :---: | :---: |:---: | :--- | | input: | COMMAND | Yes | The command to be run for this task. For example, `python3 train.py`. | | computes: | -TEMPLATE |Yes | The list of compute templates to try and use. The compute templates should be under the `computes:` heading and each on their own line, preceded by a `-`. See the examples for clarification. You must include at least one entry.| | image: | REPO:TAG | No | The container to use for the task. If left empty, the project's default container will be used. | conditions: | CONDITION | No | The condition for wether the task should be executed. [See here for information](#condition-fields-for-custom-and-deploy-tasks). | params: | PARAMETERS  | No|  The parameters that the task will use. [See here for information](#parameter-fields)  | | git_branch: | BRANCH | No| Which git branch to clone. If empty, will use master. Only relevant when project is [connected to git](..core_concepts/projects.md#git-integration).| | git_commit: | COMMIT | No | Which git commit to clone. If empty, will use latest. Only relevant when project is [connected to git](..core_concepts/projects.md#git-integration).| | mount_folders: | MOUNT_STRINGS | No| Used to mount [network drives](../core_concepts/datasets.md#local-folders-network-storage-support) in the pod. Each should be in the format: `<ip_of_network_drive>:/<name_of_folder>`. | | periodic_sync: | BOOLEAN | No | Wether or not to enable periodic sync for the task.| | restart_if_stuck: | BOOLEAN | No| wether or not to restart if the experiment has an error.| | prerun: | BOOLEAN | No | Wether or not to run the `prerun.sh` script if it exists.| | requirements: | BOOLEAN | No | Wether or not to use the `requirements.txt` list if it exists.| | notify_on_error: | BOOLEAN | No | Wether or not to send an email notification if the experiment reaches an error. | | notify_on_success: | BOOLEAN | No | Wether or not to send an email notification if the experiment finishes successfully. | | emails: | EMAILS | No | Additional recipients of email notifications for this experiment.|  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use # Parameter fields Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "The parameter field for a custom task can contain multiple parameters. Each parameter consists of two fields: `key:` and `value:`. There can be one key for each parameter, but each parameter can have multiple values.  cnvrg will automatically calculate the different permutations of parameters and run a grid search. Each possible combination of parameters is it's own experiment and run of the flow.  See the below examples for clarification:  yaml params: - key: data value: \"data.csv\" # single value example - key: epochs value: [3,5,12]   # array example - key: batch_size value:            # list example - '128' - '256'    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Deploy Task Keys Tasks YAML Files Cnvrg Flows"
      },
      {
        "role": "assistant",
        "content": "| Key | Value | Required | Description | | :---: | :---: |:---: | :--- | | endpoint_title: | ENDPOINT_NAME | Yes<sup>*</sup> | For new endpoint: The name of the desired endpoint. Used to create a new endpoint. A new endpoint will be created with this name.| | endpoint_id: | ENDPOINT_SLUG | Yes<sup>*</sup> | For existing endpoint: Supply the ID of the existing endpoint to update the service. | | computes: | -TEMPLATE |Yes | The list of compute templates to try and use. The compute templates should be under the `computes:` heading and each on their own line, preceded by a `-`. See the examples for clarification. You must include at least one entry.| | image: | REPO:TAG | No | The container to use for the task. If left empty, the project's default container will be used. | conditions: | CONDITION | No| The condition for wether the task should be executed. [See here for information](#condition-fields-for-custom-and-deploy-tasks). | file_name: | FILE_NAME | Yes | The file which contains the function to be used for the service. | | function_name: | FUNCTION_NAME | Yes | The function used to manage the input and output of the service. | | env_setup: | python_3 OR r_endpoint | No | Wether the endpoint is Python or R based. The default is `python_3`. | | min_replica: | int | Yes | Minimum number of pods to use for auto-scaling.| | max_replica: | int | Yes | Maximum number of pods to use for auto-scaling.  | | config_vars: | [key1=val1,...,key=val] | No  | Used to and different key value pairs for the Flask config of the endpoint. | | accept_files: | boolean | No | Wether or not to accept files as an input. Default is False. | | git_branch: | BRANCH | No| Which git branch to clone. If empty, will use master. Only relevant when project is [connected to git](..core_concepts/projects.md#git-integration).| | git_commit: | COMMIT | No| Which git commit to clone. If empty, will use latest. Only relevant when project is [connected to git](..core_concepts/projects.md#git-integration).|   :::tip Note Use either `endpoint_title` *or* `endpoint_id`, not both! :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": " cnvrg is an AI OS designed to help you effectively manage and utilize your compute resources. This is enabled through the **Dashboard** tab of your organization.  Inside the **Dashboard** tab, you get a complete overview of how your resources are allocated and utilized.    The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Summary Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": "    Along the top of the page, there is an overview of the current status of all your jobs and compute allocations over your entire organization and all of your compute resources.  The summary displays: - Current active jobs - Current pending jobs (queued or initializing) - Amount of Compute Resources - Assigned and total available GPU cores - Assigned and total available CPU cores - Assigned and total memory - Number of nodes among your compute resources  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Live Resources Chart Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": "   The Live Resources graph provides live insights into the allocation and utilization for each of your compute resources. Each resource has a line representing allocation (% of full cluster) and a line representing utilization (% of full cluster) for CPU, GPU and memory.  Highlight a line on the graph by hovering over its name. Click its name to toggle the line's visibility on and off.  The **Metric** menu toggles on and off visibility of CPU, GPU and memory metrics.  The **Compute** menu allows to toggle on and off visibility for each resource individually or enable **All**.  When you hover over a data point on the graph, a tooltip appears showing the allocation and utilization for that metric (CPU,GPU or memory) and the relevant jobs.    The tooltip can be docked to appear on the right side of the graph by clicking **<<**. When undocked, the tooltip displays a couple relevant jobs, when docked, more jobs appear. You can undock the tooltip by clicking **>>**.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Job Table Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": "   Below the Live Resources chart is the Job Table. This contains a full list of all current and historical jobs run in the organization, along with accompanying utilization metadata. All metadata is on a per job basis, for instance, Utilized CPU refers to the portion of the allocated CPU for the specific job was utilized by the job.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Customize the table Job Table Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": " You can control the columns that appear in the table by clicking the **Customize** button. The following fields can be chosen: - **Type**: The type of job (experiment, workspace, endpoint or app). - **Title**: The name of the job. - **Project**: The project the job belongs to. - **User**: The user who started the job. - **Status**: The resource utilization status (active, inactive or pending). - **Job Status**: The status of the job itself (initializing, ongoing, success, aborted, error or scheduled) - **Duration**: Length of time the job has been running (current or total). - **Created At**: When the job was created. - **Resource**: The compute resource used. - **Compute**: The compute template used. - **Allocated GPU**: Total allocated GPU for the job. - **Allocated CPU**: Total allocated CPU for the job. - **Allocated Memory**: Total allocated memory for the job. - **Utilized GPU**: Percentage of allocated GPU utilized by job. - **Utilized CPU**: Percentage of allocated CPU utilized by job. - **Utilized Memory**: Percentage of allocated memory utilized by job. - **Image**: Container used by job. - **Node Selectors**: Any Kubernetes selector used for choosing node/node pool. - **Datasets Attached**: Datasets used by job. - **Datasets Size**: Size of dataset used by job.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Filter the table Job Table Cnvrg Dashboard"
      },
      {
        "role": "assistant",
        "content": "   Filter the table by clicking the **Filter** icon. Then add one or more key, comparison and value combinations to filter the table. Added filters appear along the top of the table.  For each added filter, you can remove it by clicking the **X** corresponding to the filter.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg cnvrg SDK V2"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Getting Started"
      },
      {
        "role": "assistant",
        "content": "The cnvrg SDK was developed in Python and is designed to help data scientists to interact with cnvrg from their code, experiments and models. Through the SDK, you can create experiments, manage models, automate your machine learning pipeline and more.  The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Prerequisites Cnvrg Getting Started"
      },
      {
        "role": "assistant",
        "content": "In order to run the pip commands, Python **(version 3.6 or later)** should be installed on the system.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Download and Install the cnvrg SDK Cnvrg Getting Started"
      },
      {
        "role": "assistant",
        "content": "To install, open up your terminal/command prompt and run the following command:  py pip3 install cnvrgv2   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Authenticating the cnvrg SDK Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Inside a cnvrg job scope Authenticating the cnvrg SDK Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "The cnvrg SDK will already be initialized and authenticated with cnvrg using the account that is logged in. You can start using cnvrg SDK functions immediately by running: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg()    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Authenticate using a local configuration file Authenticating the cnvrg SDK Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "You can authenticate to the cnvrg SDK by creating a configuration file in your working directory - In your working directory create a directory called `.cnvrg` You can create it using the following command:  mkdir .cnvrg  - Inside the directory .cnvrg create a configuration file named `cnvrg.config` - Edit the file and insert the following:  check_certificate: <false/true> domain: <cnvrg_full_domain> keep_duration_days: null organization: <organiztion_name> token: <user_access_token> user: <user_email> version: null  - Once you finish editing, save the file Now you can simply run the following in your code and it will log you in automatically: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Authenticate using environment variables Authenticating the cnvrg SDK Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "You can authenticate to the cnvrg SDK by setting the following environment variable: - `CNVRG_JWT_TOKEN`: Your API token ( You can find it in your user settings page) - `CNVRG_URL`: Your cnvrg url that you use to view cnvrg through the browser,  for example: https://app.prod.cnvrg.io - `CNVRG_USER`: Your email that you use to log in to cnvrg - `CNVRG_ORGANIZATION`: The organization name you use Once you set those environment variables, you can simply run the following and it will log you in automatically: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg()   You can also pass the credentials as parameters: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg(domain=\"https://app.cnvrg.io\", email=\"Johndoe@acme.com\", password=\"123123\", )  If you are on cnvrg metacloud environment you need to use your API KEY that can be found in your `Account` page py from cnvrgv2 import Cnvrg cnvrg = Cnvrg(domain=\"https://app.domain.metacloud.cnvrg.io\", email=\"Johndoe@acme.com\", token=\"YOUR API KEY\")   ::: tip NOTE As a security measure, please do not put your credentials into your code. :::  ::: tip NOTE The following documentation assume you have successfully logged in to the SDK and loaded the cnvrg object :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is User Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get the logged in user object User Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " To get the logged in user object you can simply run: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() user = cnvrg.me()  Once you have the user object you can get the user fields like: email, username, organizations, git_access_token, name, time_zone For example: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() user = cnvrg.me() email = user.email   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Set the default organization User Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() cnvrg.set_organization(\"my-org\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a new project Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.create(\"myproject\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get the project's object: Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\")   Once you have the project object you can get the project fields like:  title, slug,  git_url, git_branch, last_commit For example: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") title = myproj.title   ::: tip NOTE You can also reference the current project from within a job scope: py from cnvrgv2 import Project ws = Project()  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List all the projects in the organization: Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " * List all projects that the current user is allowed to view py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.list()  To order the projects list by created_at run the following: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.list(sort=\"-created_at\")  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a project: Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") myproj.delete()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Upload files to a project Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py myproj.put_files(paths=['/files_dir/file1.txt', '/files_dir/file2.txt'], pattern='*')  available Parameters: | Parameter     |     type    |   description     | required | default | | -------- |  |  | - | - | | paths       | List            |  The list of file paths that will be uploaded to the project  | Yes | | | pattern       | string            |  String defining the filename pattern  | No | `\"*\"` | | message       | string            | The commit message  | No | `\"\"` | | override       | bool            |  Whether or not to re-upload even if the file already exists| No | `False` | | force       | bool            |  Should the new commit copy files from its parent  | No | `False` |  ::: tip NOTE If a folder is given all the relevant files in that folder (that answers to the regex pattern) will be uploaded. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remove files from a project Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "You can remove files from the project: py myproj.remove_files(paths='*', message='This will delete everything!')  ::: tip NOTE When deleting files from a project `paths` parameter can be both a list of file paths or a string pattern like `'*'` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List the project's content Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " You can list all of the files and folders that are in the project: py myproj.list_files() myproj.list_folders(commit_sha1='xxxxxxxxx')  Available Parameters | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | commit_sha1       | string            |  Sha1 string of the commit to list the files from | No | `None` | | query       | string            |  Query slug to list files from | No | `None` | | query_raw       | string            | Raw query to list files according to [Query language syntax](../core_concepts/datasets.md#querying-data)| No | `None` | | sort       | string            |  Key to sort the list by (-key -> DESC / key -> ASC) | No | `\"-id\"` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Clone the project to the current working directory Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py myproj.clone()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Download the project files Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py myproj.download(commit_sha1='xxxxxxxxx')  ::: warning The Project must be cloned first :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Sync the local project with the remote one Project File Operations Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py myproj.sync_local()    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Update the project's settings Project Operations Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "you can change any of the project's settings by passing them as keyword arguments py myproj.settings.update(title='NewProjectTitle', privacy='private')  Available Settings: | Parameter   |    type    |  description   | | -------- |  |  | | title                  | string | The name of the project | | default_image | string | The name of the image to set to be the project's default image | | default_computes | List | The list of the project's default compute template names  | | privacy | string | The project's privacy set to either `'private'` or `'public'` | | mount_folders | List | Paths to be mounted to the docker container | | env_variables | List | KEY=VALUE pairs to be exported as environment variables to each job | | check_stuckiness | bool | Whether to stop or restart experiments that have not printed new logs and have resource utilization below 20% | | max_restarts | int | When \"check_stuckiness\" is `True` this sets how many times to repeatedly restart a single experiment each time it idles | | stuck_time | int | The duration (in minutes) that an experiment must be idle for before it is stopped or restarted  | | autosync | bool | Whether or not to preform periodic automatic sync | | sync_time | int | The interval (in minutes) between each automatic sync of jobs | | collaborators | List | The list of users that are collaborators on the project | | command_to_execute | string | The project's default command to execute when starting a new job | | run_tensorboard_by_default | bool | Whether or not to run Tensorboard by default with each launched experiment | | run_jupyter_by_default | bool | Whether or not to run Jupyter by default with each launched experiment | | requirements_path | string | The default path to the requirements.txt file that will run with every job | | is_git | bool | Whether if the project is linked to a git repo or not | | git_repo | string | The address of the git repo | | git_branch | string | The default branch | | private_repo | bool | Whether the repo is private or not | | output_dir | string | The default path for jobs output directory | | email_on_success | bool | If email should be sent when the experiment finishes successfully | | email_on_error | bool | If email should be sent when the experiment finishes with an error |    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a new workspace and run it: Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg from cnvrgv2.modules.workflows.workspace.workspace import NotebookType cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.create(title=\"My Workspace\", templates=[\"small\",\"medium\"], notebook_type=NotebookType.JUPYTER_LAB)  If no parameters are provided, then the default values are used to further customize the created workspace you pass use the following parameters  | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | title                  | string | The name of the workspace | No | `None` | | templates | list | A list containing the names of the desired compute templates | No | `None` | | notebook_type | string | The notebook type (currently available: \"jupyterlab\", \"r_studio\", \"vscode\") | No | `NotebookType.JUPYTER_LAB` | | volume | Volume | The volume that will be attached to the workspace | No | `None` | | datasets | list | A list of datasets to be connected and used in the workspace | No | `None` | | Image | Image | The image to be used for the workspace environment | No | default organization image |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Fetch the workspace object Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "Once the workspace is created you can fetch it by its slug: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.get(\"workspace-slug\")   ::: tip NOTE You can also reference the current running workspace from within its job scope: py from cnvrgv2 import Workspace ws = Workspace()  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Access workspace attributes Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "You can access the workspace attributes by using regular dot notation: py ws_slug = ws.slug ws_title = ws.title ws_datasets = ws.datasets ws_notebook = ws.notebook_type   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Sync the workspace Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.get(\"workspace-slug\") ws.sync()   sync multiple by providing a list containing their slug ids py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") myproj.workspaces.sync([\"workspace-slug\"])    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Stop a running workspace Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "Stop a running workspace and sync it (the default is `sync=False`): py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ws = myproj.workspaces.get(\"workspace-slug\") ws.stop(sync=True)   Stop multiple workspaces at once: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") myproj.workspaces.stop([\"workspace-slug\"],sync=True)   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Start a stopped workspace Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "Start a stopped workspace: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.get(\"workspace-slug\") ws.start()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List all of the workspaces Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "You can list all the workspaces in the current project, as well as sort them by a key in ASC or DESC order: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") exps = myproj.workspaces.list(sort=\"-created_at\")  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete workspaces Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.get(\"workspace-slug\") ws.delete()   Delete multiple workspaces by listing their slugs: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") myproj.workspaces.delete(['workspace-slug1','workspace-slug2'])   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Operate a Tensorboard Workspaces operations: Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": "Start a Tensorboard session for an ongoing workspace py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ws = myproj.workspaces.get(\"workspace-slug\") ws.start_tensorboard()  Get the Tensorboard url: py ws.tensorboard_url   To stop the Tensorboard session: py ws.stop_tensorboard()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg "
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a new remote Experiment Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.create(title=\"my new exp\", template_names=[\"medium\", \"small\"], command=\"python3 test.py\")  List of optional parameters: | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | title | string| The name of the experiment| No | `None` | | templates | List| list of the compute templates to be used in the experiment (if the cluster will not be able to allocate the first template, then it will try the one after and so on..)| No | `None` | | local | bool | whether or not to run the experiment locally (default: `local=False`) | | command | string| the starting command for the experiment (example: `command='python3 train.py'`)| No | `False` | | datasets | List[Dataset] | A list of dataset objects to use in the experiment| No | `None` | | volume | Volume | Volume to be attached to this experiment | No | `None` | | sync_before | bool | Wheter or not to sync the environment before running the experiment | No | `True` | | sync_after | bool | Wheter or not to sync the environment after the experiment has finished | No | `True` | | image | Image | The image to create the environment from | No | organization default image | | git_branch | string | The branch to pull files from for the experiment, in case project is git project  |  No | `None` | | git_commit | string | The specific commit to pull files from for the experiment, in case project is git project | No | `None` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Initalize an empty experiment Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You may create an empty experiment that will not be run automatically (by default: `local=True, sync_after=False, sync_before=False`): py e = myproj.experiments.init(title=\"my new exp\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a local experiment Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.create(title=\"my new exp\", local=True command=\"python3 test.py\", local_arguments={epochs:20,batch_size:12}))  | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | local_arguments | dict | If local experiment and command is a function, `local_arguments` is a dictionary of the arguments to pass to the experiment's function| No | `None` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Experiment slug Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " In many commands, you will need to use an experiment slug. The experiment slug can be found in the URL for the experiment.  For example, if you have an experiment that lives at: `https://app.cnvrg.io/my_org/projects/my_project/experiments/kxdjsuvfdcpqkjma5ppq`, the experiment slug is `kxdjsuvfdcpqkjma5ppq`.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get an existing experiment Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can get the experiment object by using the experiment's `slug`:  py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.get(\"exp-slug\")  You can also get all of the experiments in the project: py experiments = [e for e in myproj.experiments.list()]   ::: tip NOTE You can also reference the current running experiment from within its job scope: py from cnvrgv2 import Experiment ws = Experiment()  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete Experiment Experiment Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can delete a Experiment from a project by its `slug` value py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.get(\"experiment-slug\") e.delete()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk delete on multiple experiments"
      },
      {
        "role": "assistant",
        "content": "myproj.experiments.delete(['experiment-slug1','experiment-slug2'])   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Stop a running Experiment Cnvrg Do bulk delete on multiple experiments"
      },
      {
        "role": "assistant",
        "content": "Stop a running Experiment by passing its `slug` value (also All Experiment must be running) py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.get(\"experiment-slug\") e.stop()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk stop on multiple experiments"
      },
      {
        "role": "assistant",
        "content": "myproj.experiments.stop(['experiment-slug1','experiment-slug2'])   | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | sync | bool | sync the experiment's data or not| No | `True` |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get Experiment's system utilization Cnvrg Do bulk stop on multiple experiments"
      },
      {
        "role": "assistant",
        "content": "You can access the experiment's system resources usage data. For example, let's get the 5 last records for memomry utilization percentage: py >>> utilization = e.get_utilization() >>> utilization.attributes['memory']['series'][0]['data'][-5:] [[1626601529000, 7.7], [1626601559000, 19.85], [1626601589000, 48.05], [1626601620000, 49.26]]  ::: tip NOTE The data syntax is `[unix_timestamp, metric]` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Track an Experiment manually Cnvrg Do bulk stop on multiple experiments"
      },
      {
        "role": "assistant",
        "content": "You can initialize an empty Experiment in Cnvrg: py cnvrg = Cnvrg() proj = cnvrg.projects.get('my-project') e = proj.experiments.init(title='my-exp')  Now that the Experiment is initialized, its status is `ONGOING` and you can preform operations from within your code like with regular Cnvrg Experiments in order to track  If you have initialized an Experiment object, you should conclude the experiment with the `e.finish()` command.  To conclude an experiment object: py exit_status = 0 e.finish(exit_status=exit_status)  ::: tip NOTE `0` is success, `-1` is aborted, `1` and higher is error :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Examples Cnvrg Do bulk stop on multiple experiments"
      },
      {
        "role": "assistant",
        "content": " :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Successful Experiment\"  To end an experiment with the status as `Success`: py e = myproj.experiments.init() #initialize experiment "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg run code, track logs and metrics"
      },
      {
        "role": "assistant",
        "content": "e.finish(exit_status=0)    ::: ::: tab \"End with Error\"  To end an experiment with the status as `Error`: py e = myproj.experiments.init() #initialize experiment "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg run code, track logs and metrics"
      },
      {
        "role": "assistant",
        "content": "e.finish(exit_status=1)     ::: ::: tab \"End as Aborted\"  To end an experiment with the status as `Aborted`: py e = myproj.experiments.init() #initialize experiment "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg run code, track logs and metrics"
      },
      {
        "role": "assistant",
        "content": "e.finish(exit_status=-1)    ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Metadata operations on experiments Cnvrg run code, track logs and metrics"
      },
      {
        "role": "assistant",
        "content": "You can create your own logs in an experiment (timestamp default is `utcnow()`): py from datetime import datetime e.log(\"my first log\", timestamp=datetime.now()) e.log([\"my first log\",\"my second log\"])  Get the experiment's last 40 logs: py logs = e.logs()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Charts Cnvrg run code, track logs and metrics"
      },
      {
        "role": "assistant",
        "content": "You can create various charts by using the sdk, for example create a linechart showing the experiments loss: py from cnvrgv2 import Cnvrg, LineChart cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") e = myproj.experiments.get(\"exp-slug\")  loss_vals = [] "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg experiment loop:"
      },
      {
        "role": "assistant",
        "content": "for epoch in range(8): loss_vals.append(loss_func())  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "loss_chart = LineChart('loss') loss_chart.add_series(loss_vals, 's1') e.create_chart(loss_chart)   ::: warning chart_name can't include \"/\" :::  You will immediately see the chart on the experiment's page:   You can create all different types of charts:  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Heatmap: Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "In case of Heatmap, list of tuples that form a matrix. e.g, 2x2 matrix: `[(0.5,1),(1,1)]`  py from cnvrgv2 import Heatmap heatmap_chart = Heatmap('heatmap_example', x_ticks=['x', 'y'], y_ticks=['a', 'b'], colors=[[0,'#000000'],[1, '#7EB4EB']], min=0, max=10) heatmap_chart.add_series('s1', [(0.5,1),(1,1)]) e.create_chart(heatmap_chart)     Typing information: `x_ticks` and `y_ticks` must be a `List` and `matrix` is a list of tuples in struct `(x,y,z)`. `color_stops` is optional and is a `List` of `Lists` with size 2, where the nested first value is a float 0 <= X <= 1, and the second value is the hex value for the color to represent matrix values at that point of the scale. `min` and `max` are optional and should be numbers corresponding to the minimum and a maximum values for the key (scaling will be done automatically when these values are not submitted).  Each struct corresponds to a row in the matrix and to a label from the `y_ticks` list. The matrix is built from the bottom up, with the first struct and y_tick at the bottom edge. Each value inside the struct corresponds to each x_tick. Using steps and groups allow you to submit the same heatmap across different steps and visualize it in a single chart with a slider to easily switch between the charts. `steps` should be an integer and `group` should be a string.  **Steps and groups**:  Using steps and groups allow you to submit heatmaps across different steps and visualize it in a single chart with a slider to easily move between the steps. `steps` should be an integer and `group`. Multiple `steps` should be grouped with a single `group`.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Bar chart: Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "* Single bar: python from cnvrgv2 import BarChart bar_chart = BarChart('bar_example', x_ticks=['bar1', 'bar2']) bar_chart.add_series('s1', [1, 2]) e.create_chart(bar_chart)   * Multiple bars: python from cnvrgv2 import BarChart bar_chart = BarChart('bar_example', x_ticks=['bar1', 'bar2']) bar_chart.add_series('s1', [1, 2, 3]) bar_chart.add_series('s2', [3, 4]) e.create_chart(bar_chart)    The `x_ticks` list will populate the labels for the bars, and the corresponding series values will dictate the value of the bar for that category. `min` and `max` are optional and are numbers that correspond the lower and upper bounds for the y values. Optionally, you can set each bar to be a specific color using the `colors` list of hex values, with each hex value corresponding to each x value.  **Steps and groups**:  Using steps and groups allow you to submit bar charts across different steps and visualize it in a single chart with a slider to easily move between the steps. `steps` should be an integer and `group`. Multiple `steps` should be grouped with a single `group`.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Scatter Plot: Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "You can pass a list of tuple pairs representing points on the axis  * Single set of points: python from cnvrgv2 import ScatterPlot points_list = [(1,1),(2,2), (3,3), (4,4)] scatter_chart = ScatterPlot('scatter_example') scatter_chart.add_series('s1', points_list)  * Multiple sets of points: python from cnvrgv2 import ScatterPlot points_list = [(1,1),(2,2), (3,3), (4,4)] scatter_chart = ScatterPlot('scatter_example') scatter_chart.add_series('s1', points_list) scatter_chart.add_series('s2', points_list[::-1]) # Reversed version of the list     "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Upload artifacts Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "You can add local files to the Experiments artifacts and create a new commit for it: py paths = ['output/model.h5'] e.log_artifacts(paths=paths)  | Parameter | Type| Description| |-|-|-| | paths | list| List of paths of artifacts to save|  ::: tip NOTE Log images with `log_images(file_paths=[<images_paths>])` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Download the Experiment's artifacts Cnvrg attach the chart to the experiment"
      },
      {
        "role": "assistant",
        "content": "You can download the artifacts to your local working directory py e.pull_artifacts(wait_until_success=True, poll_interval=5)  | Parameter | Type| Description| |-|-|-| | wait_until_success | bool| Wait until current experiment is done before pulling artifacts| | poll_interval | int| If wait_until_success is True, `poll_interval` represents the time between status poll loops in seconds |    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " Flows can be created and run from any environment using the SDK. Creating flows requires using a [flow configuration YAML file](../core_concepts/flows.md#yaml-files).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can use a flow YAML to create a flow inside a project. You can use either the absolute path to a YAML file or include the YAML content directly. Use the `Flow.create` command:  py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.create(yaml_path='YAML_PATH')    | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | yaml_path     | path         |  A path to the YAML configuration file. | No | `None`|    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Example YAML: Create a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "  --- flow: Flow Example recurring: tasks: - title: Training Task type: exec input: python3 train.py computes: - medium image: cnvrg:v5.0 relations: []   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Access Flow attributes Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can access the Flow's attributes by using regular dot notation:  Example: py >>> flow.title 'Training Task'  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Flow Attributes: Access Flow attributes Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "| Parameter   |    type    |  description   | | -------- |  |  | | title     | string         |  The name of the Flow | | slug     | string         |  The flow slug value | | created_at     | datetime         |  The time that the Flow was created | | updated_at     | datetime         |  The time that the Flow was last updated | | cron_syntax     | string         |  The schedule Cron expression string (If the Flow was scheduled)| | webhook_url     | string         |   | | trigger_dataset     | string         |  A dataset that with every change will trigger this Flow |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Flow slug Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " In some commands, you will need to use an Flow slug. The Flow slug can be found in the Flow page URL.  For example, if you have an Flow that lives at: `https://app.cnvrg.io/my_org/projects/my_project/flows/iakzsmftgewhpxx9pqfo`, the Flow slug is `iakzsmftgewhpxx9pqfo`.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "Get an existing Flow by passing its `slug` value or title py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List Flows Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can list all existing flows: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flows = proj.flows.list() for flow in flows: print(flow.title)   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Run a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "To run The Flow's latest version: py flow.run()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Update Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can update the existing Flow's attributes:  py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow.update(title=\"My Updated Flow\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can delete an existing Flow: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow.delete()  Or multiple Flows at once by listing all of the Flows `slug` values: py proj.flows.delete([\"FLOW1_SLUG\", \"FLOW2_SLUG\"])   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Schedule a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can make the Flow run on schedule by using Cron expression syntax.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Set a new schedule: Schedule a Flow Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow.set_schedule(\"* * * * *\")  # Run every minute  Disable it with:  py flow.clear_schedule()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Trigger webhook Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can create a webhook that will trigger the Flow run.  Toggle it on/off by setting the `toggle` parameter to `True` or `False`: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow.toggle_webhook(True)   Get the webhook url:  py flow.webhook_url   ::: tip NOTE If you just toggled the webhook use `flow.reload()` before fetching the `webhook_url` :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Toggle dataset update trigger Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " You can toggle the option to trigger on dataset update on/off, by setting the `toggle` parameter to `True` or `False`: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.get(\"myds\") proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\")  flow.toggle_dataset_update(True)   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Flow versions Flow Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "Every Flow have multiple versions and you can access them:  List all the flow versions: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow_versions = flow.flow_versions.list() for fv in flow_versions: print(fv.title)   Get a specific flow version object by slug or title: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") flow = proj.flows.get(\"slug/title\") flow_version = flow.flow_versions.get(\"Version 1\")   Get info of a flow version status: py info = flow_version.info()  Stop a running Flow version: py flow_version.stop()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg "
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create Endpoint Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg from cnvrgv2 import EndpointKind, EndpointEnvSetup  cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") ep = proj.endpoints.create(title=\"myendpoint\", templates=[\"small\",\"medium\"], kind=EndpointKind.WEB_SERVICE, file_name=\"predict.py\", function_name=\"predict\", env_setup=EndpointEnvSetup.PYTHON3, kafka_brokers=None, kafka_input_topics=None, *args, **kwargs)  You can use the following parameters to build your Endpoint: | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | title       | string            |  Name of the Endpoint  | Yes | | | kind       | int            |  The kind of endpoint to deploy (example: `EndpointKind.WEB_SERVICE`, options: `[WEB_SERVICE, STREAM, BATCH]`)  | No | `EndpointKind.WEB_SERVICE` | | templates       | List            | List of template names to be used  | No | `None` | | image       | Image            |  Image object to create endpoint with  | No | organization default image | | file_name       | string            |  The file containing the endpoint's functions  | Yes | | | function_name       | string            |  The name of the function the endpoint will route to  | Yes | | | env_setup       | string            |  The interpreter to use (example: `EndpointEnvSetup.PYTHON3`, options: `[PYTHON2, PYTHON3, PYSPARK, RENDPOINT]`)  | No | `None` | | kafka_brokers       | List            |  List of kafka brokers  | No | `None` | | kafka_input_topics       | List            |  List of topics to register as input  | No | `None` | | queue       | List            |  Name of the queue to run this job on  | No | `None` | | kafka_output_topics       | List            |  List of topics to register as input  | No | `None` |    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Endpoint slug Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " In many commands, you will need to use an endpoint slug. The endpoint slug can be found in the URL for the endpoint.  For example, if you have an endpoint that lives at: `https://app.cnvrg.io/my_org/projects/my_project/endpoints/show/j46mbomoyyqj4xx5f53f`, the endpoint slug is `j46mbomoyyqj4xx5f53f`.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get Endpoint object Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can get Endpoints by passing their `slug` value: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() proj = cnvrg.projects.get(\"myproject\") ep = proj.endpoints.get('slug')   ::: tip NOTE You can also reference the current running endpoint from within its job scope: py from cnvrgv2 import Endpoint ws = Endpoint()  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List Endpoints Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py ep_list = proj.endpoints.list(sort='-created_at')  # Descending order  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Stop running Endpoints Endpoint Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "Stop a running Endpoint by passing its `slug` value (`sync=False` by default, also All Endpoints must be running) py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\") ep.stop(sync=False)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk stop on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "myproj.endpoints.stop(['endpoint-slug1','endpoint-slug2'])   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Start a stopped Endpoint Cnvrg Do bulk stop on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\") ep.start()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete Endpoints Cnvrg Do bulk stop on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can delete a Endpoint from a project by its `slug` value py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\") ep.delete()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "myproj.endpoints.delete(['endpoint-slug1','endpoint-slug2'])    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Endpoint Attributes Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can access the Endpoint attributes by using regular dot notation, for example: py >>> ep.api_key '43iVTWTp55N7p62iSZYZLyuk'   | Attribute                 |           type            |           description            | | -------- |  |  | | title       | string            |  Name of the Endpoint  | | kind       | int            |  The kind of endpoint (`webservice`, `stream`, `batch`) | | updated_at       | string            | when was this Endpoint last updated | | last_deployment       | dict            |  details about the Endpoint's last deployment  | | deployments       | List            |  list of dictionaries containing details about all of the Endpoint's deployments  | | deployments_count       | int            |  The number of deployments that the Endpoint had  | | templates       | List            |  List of compute templates that are assigned to the Endpoint  | | endpoint_url       | string            | The Endpoint's requests URL | | url       | string            |The Endpoint's base URL | | current_deployment       | dict       | The active deployment's data | | compute_name       | string            | The name of the current compute template that is being used for the Endpoint to run | | image_name       | string            | Name of the Endpoint's environment that is currently deployed | | image_slug       | string            | The `slug` value of the Endpoint's deployed image | | api_key       | string            | API key to access the Endpoint securely | | created_at       | string            | The time that this endpoint was created | | max_replica       | int            | Maximum number of pods to run this endpoint on | | min_replica       | int            | Minimum number of pods0 to run this endpoint on | | export_data       | bool            | whether to export data or not | | conditions       | dict            | conditions attached to this Endpoint and trigger a Flow/email every time one of them is met |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Update The Endpoint's version Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can deploy a new version to the Endpoint and change some of its settings, for example: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\") ep.update_version(file_name=\"new_predict.py\", commit=\"q7veenevzd83rewxgncx\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Update the Endpoint's replica set Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can update the minimum and maximum number of pods to run the Endpoint on: py ep.update_replicas(min_replica=2, max_replica=5)   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get sample code Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can fetch the sample code to query the Endpoint (as shown in the Endpoint's main screen):   example: py >>> sample_code = ep.get_sample_code() >>> sample_code['curl'] 'curl -X POST \\\\\\n    http://endpoint_title.cnvrg.io/api/v1/endpoints/q7veenevzd83rewx...'   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Poll charts Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can fetch a dictionary with data about the Endpoint's latency performance, number of requests and user generated metrics from the Endpoint's charts: py >>> ep.poll_charts()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Rollback version Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "If you want to rollback the Endpoint version to a previous one you just need to pass the current version's `slug` value, for example: py >>> ep.current_deployment['title'] 3  # current version is 3 >>> last_version_slug = ep.current_deployment[\"slug\"] >>> ep.rollback(version_slug=last_version_slug) >>> ep.reload() >>> ep.current_deployment['title'] 2  # after the rollback the Endpoint's version is now 2   ::: tip NOTE To fetch the most updated attributes of the Endpoint, use `ep.reload()` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Set feedback loop Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "You can grab all inbound data and feed it into a dataset for various uses, such as continuous learning for your models, for example: py from cnvrgv2 import Cnvrg from cnvrgv2.modules.workflows.endpoint.endpoint import FeedbackLoopKind cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\") ds_slug = \"dataset-name\" ep.configure_feedback_loop(dataset_slug=ds_slug, scheduling_type=FeedbackLoopKind.IMMEDIATE)  Setup the feedback loop behaviour with the following parameters: | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | dataset_slug       | string            | `slug` of the receiving dataset  | No | `None`| | scheduling_type       | int            |  whether if the feedback loop is immediate (for every request) or recurring (for every time interval) (use `FeedbackLoopKind.IMMEDIATE` or `FeedbackLoopKind.RECURRING`)  | No | `FeedbackLoopKind.IMMEDIATE`| | cron_string       | string            |  Cron syntax string if scheduling type is recurring  | No | `None`|  Disable the feedback loop:  ep.stop_feedback_loop()    ::: tip NOTE The data will be automatically saved in predict/predictions.csv  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Control batch Endpoint Cnvrg Do bulk delete on multiple endpoints"
      },
      {
        "role": "assistant",
        "content": "If the Endpoint is of batch type, then you can control it straight from the SDK: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") ep = myproj.endpoints.get(\"endpoint-slug\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Check if it is running"
      },
      {
        "role": "assistant",
        "content": "ep.batch_is_running()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Scale it up or down"
      },
      {
        "role": "assistant",
        "content": "ep.batch_scale_up() ep.batch_scale_down()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg "
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a webapp Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": " py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") wb = myproj.webapps.create(\"mywebapp\", templates=[\"small\",\"medium\"], webapp_type=\"dash\", file_name=\"app.py\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Available parameters: Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "| Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | |webapp_type|string|The type of webapp to create (`\"shiny\"`, `\"dash\"` or `\"voila\"`)| Yes | | |file_name|string| File name of the main app script | Yes | | |title|string|Name of the webapp| No | `None`| |templates|list|List of template names to be used| No | `None`| |datasets|list|List of datasets to connect with the webapp.| No | `None`|  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Available attributes: Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "You can access the WebApp attributes by using regular dot notation, for example: py >>> wb.webapp_type 'dash'   | Attribute                 |           type            |           description            | | -------- |  |  | | webapp_type       | string            |  The type of webapp  (`\"shiny\"`, `\"dash\"` or `\"voila\"`) | | template_ids       | List            |  The size of the Dataset  | | title       | int            | The name of the Dataset  | | members       | List            |  List of collaborators on this Dataset  | | category       | string        |  The data structure category  | | description       | string            |  Description of the Dataset  | | num_files       | int            |  The number of files in the Dataset  | | last_commit       | string            |  The last commit on this Dataset  | | current_commit       | string            |  The current commit on this Dataset object  |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get webapp object Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "Get a specific WebApp by its `slug` value py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") wb = myproj.webapps.get(\"webapp-slug\")   ::: tip NOTE You can also reference the current running webapp from within its job scope: py from cnvrgv2 import Webapp ws = Webapp()  :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List all the webapps in the project Webapps Operations Cnvrg "
      },
      {
        "role": "assistant",
        "content": "py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg sort them by decending order"
      },
      {
        "role": "assistant",
        "content": "wb = myproj.webapps.list(sort=\"-created_at\")  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete webapp Cnvrg sort them by decending order"
      },
      {
        "role": "assistant",
        "content": "You can delete a WebApp from a project by its `slug` value py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") wb = myproj.webapps.get(\"webapp-slug\") wb.delete()  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk delete on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "myproj.webapps.delete(['webapp-slug1','webapp-slug2'])   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Stop running webapp Cnvrg Do bulk delete on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "Stop a running WebApp by passing its `slug` value (`sync=False` by default, also All WebApps must be running) py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() myproj = cnvrg.projects.get(\"myproject\") wb = myproj.webapps.get(\"webapp-slug\") wb.stop(sync=False)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "myproj.webapps.stop(['webapp-slug1','webapp-slug2'])     "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a Dataset Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": " You can create a new Dataset in cnvrg:  py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.create(name=\"MyDataset\",category='general')  You can use the following parameters to customize the Dataset: | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | | name       | string            |  The name of the new Dataset  | Yes| | | category       | string            |  The type of dataset, can be one of the following: [`general`, `images`, `audio`, `video`, `text`, `tabular`]   | No | `\"general\"` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dataset ID Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": " In some methods, you will need to use a dataset ID. The dataset ID is the name used for the dataset in its URL.  For example, if you have a dataset that lives at: `https://app.cnvrg.io/my_org/datasets/MyDataset`, the dataset ID is `MyDataset`.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Access Dataset attributes Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "You can access the workspace attributes by using regular dot notation: py ds.slug ds.members ds.last_commit  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Available attributes: Access Dataset attributes Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "| Attribute                 |           type            |           description            | | -------- |  |  | | slug       | string            |  The unique slug value of the Dataset  | | size       | int            |  The size of the Dataset  | | title       | int            | The name of the Dataset  | | members       | List            |  List of collaborators on this Dataset  | | category       | string        |  The data structure category  | | description       | string            |  Description of the Dataset  | | num_files       | int            |  The number of files in the Dataset  | | last_commit       | string            |  The last commit on this Dataset  | | current_commit       | string            |  The current commit on this Dataset object  |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get a Dataset Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": " To fetch a Dataset from Cnvrg you can use:  python from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.get(\"MyDataset\")   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List all existing Datasets Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": " You can list all the datasets in the current organization: python from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.list(sort=\"-created_at\")  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a Dataset Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": "To delete a Dataset call the `delete()` function on it's instance: py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.get(\"MyDataset\") ds.delete()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dataset Commits Dataset Operations Cnvrg Do bulk stop on multiple webapps"
      },
      {
        "role": "assistant",
        "content": " Every Dataset in Cnvrg may contain multiple data commits that you can interact with in the following manner:  py from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.get(\"MyDataset\")  # Get the Dataset object  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Get A specific commit by its sha1 value"
      },
      {
        "role": "assistant",
        "content": "cm = ds.get_commit('xxxxxxxxx') "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg OR list all available commits"
      },
      {
        "role": "assistant",
        "content": "commits = [cm for cm in ds.list_commits()]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "last_commit = ds.last_commit current_commit = ds.current_commit   Each commit contains the following attributes:  | Attribute                 |           type            |           description            | | -------- |  |  | | sha1       | string            |  The unique sha1 value of this commit   | | source       | int            |  Where this commit were created from  | | message       | string            | The commit message  | | created_at       | List            |  The date the commit was created on  |   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dataset Queries Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": " You can create and use queries directly from Cnvrg SDK to filter and use the Dataset exectly the way you want it by using [Query language syntax](../core_concepts/datasets.md#querying-data)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a new Query: Dataset Queries Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "python from cnvrgv2 import Cnvrg cnvrg = Cnvrg() ds = cnvrg.datasets.get(\"MyDataset\")  # Get the Dataset object ds.queries.create(name='OnlyPngFiles', query='{\"fullpath\":\"*.png\"}', commit_sha1='xxxxxxxxx')  Query parameters: | Parameter   |    type    |  description   |required | default | | -------- |  |  | - | - | |name|string| The name of the query | Yes | | |query|string| The query string according to [Query language syntax](../core_concepts/datasets.md#querying-data)|Yes | | |commit_sha1|string| The sha1 value of the commit that this query will be based on| No | `None` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List all of the Dataset queries: Dataset Queries Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py ds.queries.list(sort=\"-created_at\")  ::: tip sort the list by: `-key` -> `DESC` | `key` -> `ASC` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Get a specific query Dataset Queries Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py q = ds.queries.get('slug')  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a query Dataset Queries Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py q.delete()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Upload files to a dataset Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py ds.put_files(paths=['/files_dir/file1.txt', '/files_dir/file2.txt'], pattern='*')  available Parameters: | Parameter     |     type    |   description     | required | default | | -------- |  |  | - | - | | paths       | List            |  The list of file paths that will be uploaded to the dataset  | Yes | | | pattern       | string            |  String defining the filename pattern  | No | `\"*\"` | | message       | string            | The commit message  | No | `\"\"` | | override       | bool            |  Whether or not to re-upload even if the file already exists| No | `False` | | force       | bool            |  Should the new commit copy files from its parent  | No | `False` |  ::: tip NOTE If a folder is given all the relevant files in that folder (that answers to the regex pattern) will be uploaded. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remove files from a dataset Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "You can remove files from the dataset: py ds.remove_files(paths='*', message='This will delete everything!')  ::: tip NOTE When deleting files from a dataset `paths` parameter can be both a list of file paths or a string pattern like `'*'` :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use List Dataset content Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": " You can list all of the files and folders that are in the dataset: py ds.list_files(query_raw='{\"color\": \"yellow\"}', sort='-id') ds.list_folders(commit_sha1='xxxxxxxxx')  Available Parameters | Parameter     |     type    |   description     | required | default | | -------- |  |  | - | - | | commit_sha1       | string            |  Sha1 string of the commit to list the files from | No | `None` | | query       | string            |  Query slug to list files from| No | `None` | | query_raw       | string            | Raw query to list files according to [Query language syntax](../core_concepts/datasets.md#querying-data) | No | `None` | | sort       | string            |  Key to sort the list by (-key -> DESC / key -> ASC) | No | `\"-id\"` |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Clone the dataset to the current working directory Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py ds.clone()   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Download the dataset files Dataset File operations Cnvrg Last and current commits are available as attributes"
      },
      {
        "role": "assistant",
        "content": "py ds.download(commit_sha1='xxxxxxxxx')  ::: warning The Dataset must be cloned first :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " cnvrg allows you to run experiments.  An experiment can be any executable, written in any language: Python (for example,` python neuralnet.py`), R, Java, Scala and more. It can also be an existing Jupyter notebook.  You can run an experiment on any remote compute (cloud or on-premises) simply and efficiently by using the cnvrg web UI, cnvrg CLI and cnvrg SDK, or through API calls.  When running an experiment, cnvrg automatically takes a snapshot of your code, launches a worker, installs all dependencies (docker-based) and runs your experiment. cnvrg frees up resources for other jobs once the experiment is over.  cnvrg also provides the option to stop, delete and rerun experiments. When running an experiment in the cloud, cnvrg  automatically launches an instance, run the experiment and shutdown the instance when its over.  When an experiment is running, cnvrg provides the ability to track live exactly what occurs during the session. All standard output is visible to you, resource usage (GPU, CPU, RAM, Disk IO) are periodically checked and reported to you.  The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " There are several ways of running experiments:  - Through the web UI - Using the cnvrg CLI - Using the cnvrg SDK  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "To run an experiment with via the web, go to your project, click the **Experiments** tab and click **New Experiment**. ![Run Experiment](../images/exp-working-dir.png \"Run Experiment\")  The run page is divided into sections grouped by category. You can open each section to fill in the details you require. You can also click **Open All** to expand all the sections.  When you have filled in the details, click **Run** and cnvrg starts running the experiment according to the choices you have made.  **Set a Default Template**  You can also save a run template for each project. First fill in the details on the run page that you want to set as default. Afterwards, click **Save as default template** and confirm your decision. The details you have selected will now be loaded automatically whenever you go to run a new experiment.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use General Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![General](../images/general-new.png \"General\")  - **Command to Execute**: Write the command the remote compute will run for the experiment (for example, `python3 train.py`). - **Working Directory**: You can customize the working directory in which the command will be executed by clicking **Change**. For example, if the script you wish to execute is in a sub-folder named `scripts/`, you can set `/cnvrg/scripts/` as the working directory. The default can be set in [project settings](../core_concepts/projects.md#environment). - **Title**: You can provide your experiment with a title. By default, the experiments are named `Experiment #` (# is the number of experiments run before, plus 1).  ::: tip You can dynamically set the title of the experiment using the [cnvrg Research Assistant](../core_concepts/experiments.md#tracking-and-visualizing). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Parameters Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![Parameters](../images/run-param_1.png \"Parameters\")  Here, you can add the parameters you want to use when running a grid search. Add all the parameters you want and cnvrg will dynamically create experiments for all the permutations of parameters.  1. Click **Add** to add a parameter. 2. For each parameter, enter a key and provide values in the fields, as required:  There are four types of parameters:  - **Float**: Scale between float values. Specify a minimum and maximum value and number of steps, in addition to selecting the desired scale (Linear, Log 2, or Log 10). For example, say the key you chose is `learning_rate`, values might be: `Min=0`, `Max=1`, `Scale=Linear` and `Steps=10`. - **Discrete**: Comma-separated integers. This type is useful for designating discrete values. For example, say the key you chose is `epochs`, values might be: `10,20,100`. - **Categorical**: Comma-separated strings. You specify a list of values, for example, `1,5,9,13` and cnvrg adds `\"\"` to either side of the values. For example, say the key you chose is `optimizer`, values might be: `Adam` and `sgd`. - **Integer**: Scale between integer values. Specify a minimum and maximum value and number of steps, in addition to selecting the desired scale (Linear, Log 2, or Log 10). For example, say the key you chose is `folds`, values might be: `Min=1`, `Max=1000`, `Scale=Log10` and `Steps=3`.  cnvrg displays the number of experiments to be run in the top right corner of the panel.  ::: tip Information on how to handle the inputs from this feature can be found [here](#hyperparameter-optimization-and-grid-searches). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Datasets Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![Datasets](../images/run-data.png \"Datasets\")  In this menu, you can select one or more datasets to be mounted on the remote compute for this experiment. You can also select specific commits or queries on any of your datasets.  The dataset will be accessible at the absolute path: `/data/name_of_dataset/`.  ::: tip More info on using datasets can be found [here](../core_concepts/datasets.md). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Git integration Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " ::: tip NOTE The following section is relevant only if you have integrated with Git. :::  ![Git](../images/run-git.png \"Git\")  When your project is integrated with a Git repo, you can choose the git branch and git commit of your choice.  - **Git Branch**: The name of the git branch to clone (default is `master`). - **Git Commit**: The name of the specific commit you want to clone (default is `latest`). - **cnvrg.io Commit**: You can load an output directory of a previous job and your new experiment will start at that point and have access to the files from that cnvrg commit (that is, its artifacts). - **Output Folder**: Even when connected to Git, cnvrg will handle the versioning of experiment artifacts. In order for cnvrg to locate files produced by the experiment, you must set the correct directory or path here.  ::: warning Make sure the Output Folder matches the location where your code saves its changes and files. Otherwise, they will not by synced and versioned by cnvrg. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Environment Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![Environment](../images/run-env.png \"Environment\")  Use this menu to choose the settings that will create the environment for the running of the experiment.  - **Compute** - Choose one or more compute templates you would like your experiment to run on. If the first compute is unavailable, the experiment attempts to run on the next compute you have selected. If you only select one compute template, the experiment waits until it is available to run. - **Image** - Choose the docker image to serve as the basis for your experiment.  ::: tip More info on setting up your environment can be found [here](../core_concepts/environments.md). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Scheduling Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![Scheduling](../images/run-schedule.png \"Scheduling\")  Here you schedule your experiment to run at a specific time or on a recurring basis.  There are three options: - **Now** - **Schedule**: Run once at a specific date and time of your choice. - **Recurring**: Run this experiment repeatedly based on a timing rule.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use More Through the web UI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "  ![More](../images/run-more.png \"More\")  In this final menu, there are a few extra options you can set:  - **AutoSync**: When turned on, cnvrg will commit the experiments artifacts every 60 minutes. (Note: the time can be configured in your project's settings.) - **Restart when idle**: When turned on, your experiment will automatically restart if logs are not printed for more than 60 minutes. - **Email Notifications**: There are two options for email notifications when running experiments: - **On Success**: If you enable this option, you will receive an email when the experiment ends successfully. - **On Error**: If you enable this option, you will receive an email if an error occurs while your experiment is running.  You can also enable email notifications with the SDK and CLI. See the next sections.  ::: tip You can set a default behavior for email notifications in your project settings. Go to **Settings** > **Environment** > **Email notifications** and toggle on notifications for success or error. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the cnvrg CLI Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "Experiments can be run locally on your machine, or on one of the cnvrg remote machines.  To run an experiment with the cnvrg CLI, go to your project directory, create a project and simply add the `cnvrg run` prefix to your command as follows:   cnvrg run python myscript.py  You will immediately receive a link to track the progress of your experiment via the web.  ::: tip If you wish to run the experiment local first, use: `--local` flag (or simply, `-l`) :::  cnvrg uses your default organization or user setting for experiments. You can edit these on an experiment basis by using the different flags.  To enable email notifications with the CLI, use the `--notify_on_success` and `--notify_on_error` flags.  bash cnvrg run --notify_on_success --notify_on_error python3 train.py   There is a large list of commands to control your experiments properties. You can choose any combination of commands for your needs. If you don't use any specific commands, cnvrg will use the default settings.  For example:   cnvrg run  --datasets='[{id:d3-new,commit:dd7c1a3d9d5627da9aea5415e3d07202bfb5925e}, {id:d4,commit:3028f51407d83338f72f994bc283572452a877de}]' --git_branch=master --git_commit=0a787d11e1e2f01b15ac63599ebed3777f21dab8 --output_dir=output --machine=\"gpu\" --sync_before=false python3 train.py   For more information about the flags available with the `run` command, see [Experiments](../cli/install.md#experiments).   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the cnvrg SDK Running Experiments Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " You can run experiments in cnvrg using the cnvrg SDK. To run a new experiment, use the `experiment.run()` method:  python from cnvrg import Experiment e=Experiment.run('python3 train.py', title=\"SDK Experiment\", compute='medium')  The code will start running an experiment on a remote compute and sync the status with cnvrg.  To enable email notifications when running an experiment, use the `notify_on_success` and `notify_on_error` parameters in `experiment.run()`.  python e = Experiment.run('python3 train.py', notify_on_success=True, notify_on_error=True)   There are many different arguments you can use in the command. The [cnvrg SDK documentation](../core_concepts/python_sdk.md#experiment-operations) has information on all of the options.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Use Cases Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " As a cnvrg experiment can be any form of code, there are many different types of experiments that can be run within cnvrg.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Preprocessing datasets Use Cases Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " You can run processing code as an experiment in cnvrg. Ensure that you select the relevant dataset to attach to the experiment and set the command to execute (for example, `Rscript preprocess.R`).  If you want to update the cnvrg dataset with the processed data, ensure that you run the `cnvrg data sync` CLI command as part of your code, in the dataset directory. Information on where your dataset is located in the remote compute is [here](../core_concepts/experiments.md#using-datasets).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Training machine learning models Use Cases Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " You can train a machine learning model using a cnvrg experiment. cnvrg is completely code and package agnostic, so if you want to train an NLP Tensorflow model using Python, train a Recurrent Network based on Keras in R, or train your own custom modeling code, you can!  To train your model set your command to execute exactly as you would on your machine (for example, `python3 train.py`).  cnvrg's default Docker images support most standard use cases and are updated regularly. Learn more about using your own custom Docker image to support your specific use case [here](..core_concepts/environments.md#using-your-own-docker-images).  ::: tip Don't forget to use [grid searches](../core_concepts/experiments.md#hyperparameter-optimization-and-grid-searches) and [experiment visualization](../core_concepts/environments.md#tracking-and-visualizing) to make the most of training models within cnvrg experiments. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Running Jupyter notebooks as experiments Use Cases Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " You can run existing Jupyter notebooks as experiments by using the `jupyter nbconvert` command. The command automatically runs the code inside the notebook.  Use the following syntax:  bash jupyter nbconvert --to notebook --execute \"notebook_path/some_notebook.ipynb\"   ::: tip NOTE The output will be rendered inside an updated Juypter notebook file. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Datasets Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " When starting an experiment you have the option of including one or more datasets. Choose the datasets you want to use when starting the experiment. You can also choose a specific query or commit of the dataset at this point.  When you choose to include a dataset with an experiment, the dataset will be mounted in the remote compute and accessible from the absolute path: `/data/name_of_dataset/`.  For example, if you include your dataset `hotdogs`, when running an experiment, the dataset can be found at `/data/hotdogs/` and all of the dataset files will be found in that directory.  ::: tip It can be useful to parameterize the dataset slug and make use of the hyperparameter parsing features of cnvrg. Doing so can help avoid hard-coding the dataset's slug and is helpful in case you want to run on a different dataset or multiple datasets. More information about parameters is [here](../core_concepts/experiments.md#hyperparameter-optimization-and-grid-searches). ::: "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "   cnvrg is designed to make tracking and visualizing your experiments as intuitive as possible. Using either allows you to sort, search and compare experiments easily, enabling deep comparison between experiments and models.  The cnvrg Research Assistant automatically extracts parameters, metadata and model performance, creating tags and beautiful charts from experiments. This happens automatically with no activation needed and the Research Assistant knows how to work with scikit-learn, Keras, TensorFlow, Caffe, and more!  You can customize the tracking of your experiments in two ways: - You can use print statements to Standard Output to track any other parameters of your choice, or create your own custom charts. - You can completely customize your tracking using the [Python SDK](../core_concepts/python_sdk.md#experiment-operations).   <!-- ### Python SDK tracking overview  You can track and visualize your models using the SDK. Just as with the cnvrg Research Assistant, you can monitor any parameters or create graphs. With the SDK you gain access to creating bar charts (feature importances), heat maps (confusion matrices) and scatter plots.  To use the Python SDK for tracking, you must first run an experiment using the SDK with `Experiment.run()` and then use the different methods to cutomize tags and graphs.  python from cnvrg import Experiment e = Experiment.run('command or function')   The experiment will begin to run and its logs and metrics will be tracked by cnvrg.  ::: tip The Experiment object can be referenced, and its methods can be used from within the code that is called by the run command.  For example, to log a parameter use the following code structure within the code that the run command calls: python from cnvrg import Experiment e = Experiment()  ... e.log_param(\"key\", \"value\") ...  :::  More information on each of the relevant commands can be found in the [cnvrg SDK documentation](../core_concepts/python_sdk.md#experiment-operations). -->  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Log a metric or parameter as a tag Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---    You can take any piece of information and extract that as a metric. This means that it will become a tag for your experiment and can then be used for sorting, searching and comparing.  - **Log Parsing**  Print to Standard Output: `\"cnvrg_tag_key: value\"`  For example, if you printed `cnvrg_tag_precision: 0.9`, the Research Assistant automatically transforms it to a tag named `precision` with a value of 0.9.  - **Python SDK**  Use the `log_param` method to track custom metrics and parameters.  python from cnvrg import Experiment e = Experiment() e.log_param(\"key\", \"value\")   For example, `e.log_param(\"precision\", \"0.9\")` would create a tag named `precision` with  value of 0.9.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a line chart Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---   You can create a single or multi-line line chart to track any variable as it changes throughout the running of your experiment. This can be really useful for tracking metrics like accuracy or loss as it develops in the creation of your model.  - **Log Parsing**  There are 2 formats for creating line charts. Using any of the print statements will either create a new graph or add to an already existing graph with the same name. 1. *Name, Value*:  Print to Standard Output: `\"cnvrg_linechart_Name value: Value\"`  For example, if you printed `\"cnvrg_linechart_computingPie value: 3.14\"`, you would create a graph titled \"computingPie\" (or add to the graph if it already exists), and add a data point with value \"3.14\".  2. *Name, Group, Value*:  Print to Standard Output: `\"cnvrg_linechart_Name group: \"Group_name\" value: Value\"`  For example, if you printed `\"cnvrg_linechart_computingPie group: \"pi_val\" value: 3.14\"`, you would create a graph titled \"computingPie\" (or add to the graph if it already exists), and add a data point with value \"3.14\" and a line labelled \"pi_val\". You can use this format to add multiple lines to one graph.  ::: tip You can use this format to quickly create the correct format in Python using variables:  python cnvrg_linechart_{} value: '{}'\\n\".format(chart_name, value)  :::  - **Python SDK**  Use the `log_metric()` method to create single line and multi-line charts.  python from cnvrg import Experiment e = Experiment() e.log_metric(\"chart_title\", Ys=[val_1,val_2,val_3])   For example, `e.log_metric(\"accuracy\", ys=[0.6,0.64,0.69])` would create a chart named \"accuracy\" with 3 data points: (0,0.6), (1,0.64) and (2,0.69).  For more information on how to create line charts or multi-line charts with the Python SDK, consult the [full SDK documentation](../core_concepts/python_sdk.md#create-a-line-chart).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a confusion matrix/heatmap Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---   You can create confusion matrices and heatmaps easily using the Python SDK.  - **Python SDK**  python from cnvrg import Experiment from cnvrg.charts import MatrixHeatmap e = Experiment() e.log_chart(key=\"chart_key\", title=\"chart_title\", group=None, step=None, x_ticks=['x', 'y', 'z'], y_ticks=['a', 'b', 'c', 'd'], data=MatrixHeatmap(matrix=[(0,0,0), (9,9,9), (1,0,1), (1,1,1)], color_stops=[[0,'#000000'],[1, '#7EB4EB']], min_val=0, max_val=10))   Typing information: `x_ticks` and `y_ticks` must be a list and matrix is a list of tuples in struct `(x,y,z)`. `color_stops` is optional and is a list of lists with size 2, where the nested first value is a float 0 <= X <= 1, and the second value is the hex value for the color to represent matrix values at that point of the scale. `min_val` and `max_val` are optional and should be numbers corresponding to the minimum and a maximum values for the key (scaling will be done automatically when these values are not submitted).  Each struct corresponds to a row in the matrix and to a label from the `y_ticks` list. The matrix is built from the bottom up, with the first struct and y_tick at the bottom edge. Each value inside the struct corresponds to each x_tick.  **Steps and groups**:  Using steps and groups allow you to submit heatmaps across different steps and visualize it in a single chart with a slider to easily move between the steps. `steps` should be an integer and `group`. Multiple `steps` should be grouped with a single `group`.    python for i in range(10): e.log_chart(key=\"MyChart_\" + str(i), group=\"group-1\", step=i, title=\"MyChart_\" + str(i), x_ticks=['x', 'y', 'z'], y_ticks=['a', 'b', 'c', 'd'], data=MatrixHeatmap(matrix=[(0,0,0), (9,9,i), (i,0,1), (1,i,1)], min_val=0, max_val=10))    ::: tip When using the group parameter, make sure the chart's key is unique across the different steps :::   For more information on how to create confusion matrices with the Python SDK, consult the [full SDK documentation](../core_concepts/python_sdk.md#create-a-heat-map-confusion-matrix).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a bar graph Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---   You can create single bar and multi-bar graphs using the Python SDK.  - **Python SDK**  python from cnvrg import Experiment from cnvrg.charts import Bar e = Experiment() x_value=[\"bar1\",\"bar2\",\"bar3\",\"bar4\",\"bar5\"] y_value1=[1,2,3,4,5] y_value2=[5,4,3,2,1] e.log_chart(\"chart_key\", title=\"chart_title\", group=None, step=None, data=[Bar(x=x_value, y=y_value1, name=\"y_value1\", min_val=0, max_val=10)), Bar(x=x_value, y=y_value2, name=\"y_value2\")])   Typing information: `x` must be a `List` and `y` must be an `Array`, `np.ndarry`, `pd.array` or `pd.series`.  The `x` list will populate the labels for the bars, and the corresponding `y` value will dictate the value of the bar for that category. The name of the `y` array will be the name of the set/category in the graph. `min_val` and `max_val` are optional for each Bar and should be numbers corresponding to the minimum and a maximum values for the key (scaling will be done automatically when these values are not submitted).   **Steps and groups**:  Using steps and groups allow you to submit bar charts across different steps and visualize it in a single chart with a slider to easily move between the steps. `steps` should be an integer and `group`. Multiple `steps` should be grouped with a single `group`.    python for i in range(10): e.log_chart(key=\"MyChart\" + str(i), group=\"group-1\", step=i, title=\"MyChart\", data=[Bar(x=[\"cat1\", \"cat2\", \"cat3\"], y=[1**1, 2/(i+1), 3*i], name=\"Bar1\"), Bar(x=[\"cat1\", \"cat2\", \"cat3\"], y=[2**1, 3/(i+1), 4*i], name=\"Bar2\")])    ::: tip When using the group parameter, make sure the chart's key is unique across the different steps :::  For more information on how to create bar graphs with the Python SDK, consult the [full SDK documentation](../core_concepts/python_sdk.md#create-a-bar-chart).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a scatter plot Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---   You can create scatter plots using the Python SDK.  - **Python SDK**  python from cnvrg import Experiment from cnvrg.charts import Scatterplot e=Experiment() x1_values=[1,2,3,4,5] x2_values=[1,2,3,4,5] y1_values=[5,4,3,2,1] y2_values=[1,2,3,4,5] e.log_chart(\"chart_key\", title=\"chart_title\", data=[Scatterplot(x=x1_values, y=y1_values, name=\"name\"), Scatterplot(x=x2_values, y=y2_values, name=\"name2\")])   Typing information: `x` and `y` must be an `Array`, `np.ndarry`, `pd.array` or `pd.series`. `x` is the list of x values and `y` is the list of y values.  For more information on how to create scatter graphs with the Python SDK, consult the [full SDK documentation](../core_concepts/python_sdk.md#create-a-scatter-plot).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Change the title of an experiment Tracking and Visualizing Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "---  You can easily change the name of an experiment from within the experiment. You can include variables or any string in label for your experiment. One good example of how to use this tag is when running a grid search - you can use the parameters to name the experiment. Doing so allows you to easily mark what parameters were tested in the specific experiment.  - **Log Parsing**  Print to Standard Output: `\"cnvrg_experiment_title: experiment_title\"`  For example, if you printed `cnvrg_experiment_title: \"New Name\"`, the experiment will be renamed to \"New Name\"  - **Python SDK**  python from cnvrg import Experiment e = Experiment() e.title = \"experiment_title\"   For example, `e.title = \"New Name\"` would change the name of the experiment to \"New Name\"  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Hyperparameter Optimization and Grid Searches Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": "A grid search is the process of choosing a set of parameters for a learning algorithm, usually with the goal of optimizing a measure of the algorithm's performance on an independent dataset.  With cnvrg you can fire up multiple experiments in parallel with a single command. This feature is very useful for grid searches and hyperparameter optimization.  With cnvrg you can fire up multiple experiments in parallel with a single command. This feature is very useful for running grid searches and hyperparameter optimization.  There are two ways of triggering grid searches in cnvrg: - Using the UI - Using the CLI and a `YAML` file  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the UI Hyperparameter Optimization and Grid Searches Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " To run a grid search using the UI, navigate to the **Experiments** tab of your project and click **New Experiment**.  On the next page you will have access to the **Parameters** menu. Click it to expand the panel. In this box you can add the parameters you would like to tune for.  ![Parameters UI](../images/run-param_new.png \"Set your parameters in the UI\")  Add another parameter by clicking **Add**.  ::: tip More info on using this menu can be found [here](../core_concepts/experiments.md#parameters). :::  When you click **Run**, cnvrg will automatically spin up an experiment for each permutation of the parameters you have included.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the CLI Hyperparameter Optimization and Grid Searches Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " To run a grid search using the CLI you first need to create a yaml file that contains information about the parameters, and their possible values.  In the YAML file, each parameter has a param_name that should match the argument that is fed to the experiment.  **To trigger the grid search, use this command:**  bash cnvrg run --grid=src/hyper.yaml python myscript.py    **Below you can see an example yaml file:** `hyper.yaml`   parameters: - param_name: \"learning_rate\" type: \"discrete\" values: [0.1, 0.01 ,0.001]  - param_name: \"kernel\" type: \"categorical\" values: [\"linear\", \"rbf\"]  - param_name: \"epochs\" type: \"integer\" min: 10 # inclusive max: 200 # not inclusive scale: \"linear\" steps: 10 # The number of linear steps to produce.  - param_name: \"fractions\" type: \"float\" min: 0.1 # inclusive max: 0.2 # not inclusive scale: \"log2\" steps: 10 # The number of linear steps to produce.   ::: tip The scale can be linear, log2 or log10. ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using this feature in your code Hyperparameter Optimization and Grid Searches Cnvrg Experiments"
      },
      {
        "role": "assistant",
        "content": " When you run a grid search, the parameters are included as flags on the command line argument that runs the code in the remote compute.  For example, for when tuning your epochs, the command executed on the remote compute is: `python3 myscript.py --epochs 10`  Then use an open source library to parse this input and use it as a variable in your code. We recomend: - `argparse` for Python scripts. - `optparse` for R code.  Here are example implementations of both:  **Python Implementation Example**   Below you can find a Python snippet that uses argparse library to parse input values from command line:  import argparse  parser = argparse.ArgumentParser(description='set input arguments')  parser.add_argument('--epochs', action=\"store\", dest='epochs', type=int, default=10) parser.add_argument('--learning_rate', action=\"store\", dest='learning_rate', type=float, default=0.0001)  args = parser.parse_args()  epochs        = args.epochs learning_rate = args.learning_rate    **R Implementation Example**  Below you can find an R snippet that uses optparse library to parse input values from command line:  install.packages('optparse', dependencies = TRUE)   library(\"optparse\")  option_list = list( make_option(c(\"--epochs\"), type=\"integer\",     default=10,help=\"number of epochs to perform\",metavar=\"number\"), make_option(c(\"--learning_rate\"), type=\"double\", default=0.001,help=\"learning rate values\",metavar=\"number\"));  opt_parser = OptionParser(option_list=option_list); opt = parse_args(opt_parser);  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " sprintf(\"Number of epochs is: ( %s )\", opt$epochs)    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Experiment Artifacts Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "Many machine learning experiments, jobs or even notebook sessions are producing artifacts like: models, images, plots and more.  cnvrg makes it really easy for data scientists and developers to explore an experiment's artifacts, and have them versioned, stored and accessible via the job's artifacts section.  * **Artifacts are synced in one of the following ways:** - on manual sync - autosync - when experiment finishes  To view experiment's artifacts, scroll down below the log, and you'll see the following section:    As you can see, in this case cnvrg periodically syncs checkpoints from the experiment and adds them to the experiment page with different commits.  This feature allows you to manage all your files easily as they are all associated with a specific experiment. The experiments code is also versioned and so is the dataset. This means that you can easily reproduce the dataset and code that produced the artifacts. Allowing you to always keep track of your work and mange your models effectively.  ::: tip You can merge experiment artifact to the master branch by clicking **Merge**. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " Understanding your experiments both at-a-glance and in-depth is essential in any data science workflow. cnvrg has features that help you get insights into your experiments quickly and easily.  From the **Experiments** tab of your project, you can:  - Perform quick operations on experiments. - Customize and sort the experiments table. - Search through your experiments. - Compare your experiments' cnvrg visualizations and metadata. - Compare experiments using TensorBoard.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Perform quick operations on experiments Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " From the **Experiments** tab you can perform quick operations on all your experiments. You can do this on a single experiment or on a group of experiments.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Operations on a single experiment Perform quick operations on experiments Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "   Each row of the experiment table has a **Menu** drop-down list on the right end of the entry.  From the drop-down list you can choose the following options: - (When running) **Stop**: Stops the experiment. - (When running) **Sync**: Syncs the current artifacts and status of the experiment with cnvrg. - (When running) **Stop & Sync**: Syncs the experiment then stops the experiment. - **Export**: Emails the experiment's metadata as a CSV. - **Rerun**: Pre-fills an experiment form with all the details from the chosen experiment. - **Tag**: Adds a key-value pair to the metadata of the experiment. - **Delete**: Deletes the experiment.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Operations on multiple experiments Perform quick operations on experiments Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "   To complete actions on multiple experiments at once: 1. Check the boxes on the left of the table for each experiment to include in the action.   ::: tip You can use the [search bar](../core_concepts/experiments.md#search-through-your-experiments) to filter your experiments and quickly find the experiments you want to select. :::  2. Click the **Actions** drop-down list at the top of the experiments table.  In the drop-down list you can choose the following options: - (When running) **Stop**: Stops the experiment(s). - (When running) **Sync**: Syncs the current artifacts and status of the experiment(s) with cnvrg. - **Tag**: Adds a key-value pair to the metadata of the experiment(s). - **Export**: Emails the experiments' metadata as a CSV. - **Delete**: Deletes the experiment(s).  ::: tip You can also use this menu when only one experiment is selected. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Customize and sort the experiment table Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " When you are in the **Experiments** tab of your project, there are a number of ways you can arrange your experiments table for your own convenience.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Display certain columns Customize and sort the experiment table Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "   You can add or remove columns from your experiment by clicking the **Table** drop-down menu.  Inside the menu, you can click on the available columns to either add them to the table (checked) or remove them (unchecked). The table will update immediately.  The list of available columns is populated by your experiment metadata. Any tag or parameter, as well as any of the tracked metadata (start time, commit, grid search id and so on) can be used as a column.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Sort by a column Customize and sort the experiment table Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " You can sort your experiments table according to any of the columns displayed.  Click the column title to sort by the values in the chosen column. Clicking once sorts in ascending order. Clicking twice sorts in descending order. CLicking three times will stop sorting by that column.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Change the number of rows per page Customize and sort the experiment table Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " You can change the number of viewable rows in the experiments table.  Click the drop-down list below the table. It shows the number of rows that are currently visible. In the drop-down list, you can select to view 10, 25, 50 or 100 experiments at once.  You can also view the number of experiments being shown, alongside the total number of experiments in the same place.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Move between pages of the experiment table Customize and sort the experiment table Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " On the bottom right of the table you can jump from page to page of the experiment table.  Either click the arrows to move one page in either direction or click the number of the specific page you are looking for.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Search through your experiments Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "   You can easily search through your experiments using the search bar at the top of the experiments table. Click it to start constructing your search filter.  A search filter is constructed from a category key, category relation, and value: - A category key can be any of your columns. - A category relation can be any of the operators: `=` (equals), `>` (greater than) or `<` (less than). - A value can be any string or integer.  You can also use a category connect to build more complex filters. A category connect can be either `AND` or `OR`.  Press Enter or click **Search** to submit your search criteria and load the matching experiments.  Click the Refresh button in the search bar to reset the experiment table and remove your filter.  For example: `status = Success AND Accuracy > 0.85` would return only experiments that have a status of 'success' and an accuracy greater than 0.85.  ::: tip cnvrg auto-suggests filter terms to help you construct your filter. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Compare your experiments' cnvrg visualizations and metadata Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "   cnvrg provides a solution to compare and analyze all experiments and models within a project. Harnessing the cnvrg Research Assistant and all the experiment visualization features of experiments (tags and SDK tracking), cnvrg can automatically generate comparisons for all your experiments and models.  To compare experiments: 1. Navigate to the **Experiments** table of the desired project. 2. Check the boxes on the left hand side of each experiment you wish to include in the comparison. 3. Click **Compare** at the top of the experiments table.  A new page opens. The page displays all of your experiments metadata and charts alongside each other. Any graphs with matching keys from different experiments are merged into a single graph for easy comparison.  You can dynamically add additional charts using your metadata to the comparison view by clicking **Add Chart**.  All the comparison metadata can also be exported by clicking **Download CSV**.  You can remove experiments from the comparison along the top of the page. Click the X next to the experiment you wish to remove from the comparison. The page automatically updates, reflecting the change.  ::: tip NOTE Confusion matrices, scatter maps, and bar graphs are not currently included in this comparison. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Compare using TensorBoard Comparing and Organizing Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " ![TensorBoard- drop-down](../images/tensor-dropdown.png \"The  drop-down menu\")  You can also compare multiple experiments using TensorBoard. You can use this feature with any finished or currently running experiments. On the **Experiments** tab, use the **TensorBoard** drop-down menu to access currently running TensorBoard comparisons, stop them, or create new ones.  To create a new TensorBoard comparison, click **+ Start New TensorBoard session**. In the popup, choose your experiments, compute, and refresh frequency. Refresh frequency will determine the frequency to pull new logs from running experiments. If the experiments are not in an ongoing state cnvrg will fetch their end commit. ::: tip You can also mix and match - compare ongoing and completed experiments on the same TensorBoard dashboard. ::: Finally click **Start Session** and cnvrg starts running the TensorBoard comparison.  ![TensorBoard-create](../images/tensor-create.png \"Create a new TensorBoard comparison\")  ::: tip You can also preselect the experiments you want to compare in the **Experiments** table and they will automatically populate the experiments field when creating the comparison. :::  When your TensorBoard comparison is running, you can use the menu in the top bar to: - Stop the TensorBoard. - Check which experiments are being compared. - Share the comparison. - Display TensorBoard in full-screen mode.  ![TensorBoard-menu](../images/tensor-menu.png \"The TensorBoard menu\")  ::: tip NOTE The TensorBoard comparison feature is currently only supported when running on Kubernetes. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Experiment Error Codes Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " cnvrg will help you run your experiments quickly and easily, however, as with all code, your experiment might fail due to one of many possible errors. If an error is encountered, you can use the [debug mode](#experiment-debugger) to quickly fix issues and restart an experiment. Alternatively, you can fix your code however you desire, sync the updates to cnvrg or [push them to your git](../core_concepts/projects.md#git-integration) and then rerun the experiment.  Whenever an experiment fails, there should be an error code that is returned by the command that was run. This can provide important information to debug your code. Here is a breakdown of many of the typical error codes you may experience:  |Error Code|Explanation| |:-:|:-| |1| General errors in your code | |2| Misused shell builtin | |126| A command was invoked that could not run | |127| A command was invoked that could not be found | |128| An invalid argument was called to exit | |137| Compute ran out of memory | |139| Invalid memory was called |     "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Experiment Debugger Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " ![Debug Experiment](../images/debug-notification.png \"Experiment Debugging\")  Sometimes things go wrong and experiments fail due to errors in the code, errors in the environment, or just because the configuration is incorrect. cnvrg helps you resolve these situations quickly without needing to rerun the experiment from scratch (saving time and resources).  Once an experiment experiences an error, cnvrg will send you notification via Slack or email that the experiment has failed and notify you that it has entered `Debug` mode. The experiment remains live for debugging purposes.  When you first access the experiment's page, a notification will appear and you will be presented with the option to **Add 15 minutes** or to not add time by clicking **That's ok, I'm done**.  By default, the experiment will remain running for 30 minutes, however, you can configure this default value in the [Organization settings](../core_concepts/team.md#organization-settings). The countdown will display the time remaining. When the duration expires, the experiment will be stopped. You can add 15 minutes to the timer by clicking **Add 15 minutes** button.   The experiment, compute and environment can be accessed via a terminal session on the experiment page. Use the terminal to debug your experiment and fix the error.  When you have finished using the terminal to rectify issues in your code and the environment, you can click the **Rerun** button to start the experiment from the beginning without restarting the compute. When clicking rerun you can also enable the following: * **Sync my experiment before**: Sync changes to the code back to cnvrg before rerunning. * **Rerun with prerun script**: Re-execute the `prerun.sh` script before running the command. * **Rerun with requirements file**: Reinstall the packages from the `requirements.txt` file before running the command. Click **Yes, Rerun** to confirm your choices and restart the experiment.   ::: tip If Slack integration is enabled, you will be notified in real-time when your experiment enters debug mode. Information of how to set this up can be found [here](../core_concepts/projects.md#slack-integration).  ![Debug Experiment](../images/exp-slack-debug.png \"Experiment Debugging\")  :::    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is TensorBoard and Terminal Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "In all live running experiments, cnvrg allows you to access and interact with the experiment using a fully secured terminal or track live metrics and debug your models using TensorBoard.  - **TensorBoard** TensorBoard is an open-source application that makes it easier to understand, debug, and optimize TensorFlow programs.  To access the TensorBoard of an Experiment, click **Menu** at the top right of the Experiments page and select **Open TensorBoard**. A new page with the TensorBoard opens. To stop the TensorBoard from running, click **Menu** at the top right of the Experiments page and select **Stop TensorBoard** from the dropdown menu. If you have stopped the TensorBoard, you can start it again from **Menu** > **Start TensorBoard**.  ::: tip In the Project's settings you can change the default behavior for whether or not the TensorBoard runs for each experiments. If it is set to off, you can still start it from the Experiment's menu while it runs. :::  - **Terminal** To access the Terminal of the machine/instance/pod that the Experiment is running on, click **Menu** at the top right of the Experiments page and select **Open Terminal**. A new page with the Terminals opens.  ![TensorBoard / Terminal](../images/tensor-term.png \"TensorBoard / Terminal\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is The Files in an Experiment Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " Similar to the execution of any other machine learning workload in cnvrg, when an experiment is run, it constructs its environment as follows:  1. Pull and execute the chosen container. 2. Clone the chosen git branch and commit (if project connected to git) into `/cnvrg`. 3. Clone the latest version of the files from your projects **Files** tab (or the chosen cnvrg.io commit) into `/cnvrg`. 4. Clone or attach the chosen datasets into `/data`. 5. Install packages from the `requirements.txt` file (if it exists). 6. Execute the `prerun.sh` script (if it exists).  When these steps have completed, the environment will be fully constructed and the command will be executed.  For more information see [Environment](../core_concepts/environments.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Rerun Experiments Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": " Reproducible code and environments are key elements of cnvrg.  To quickly and easily rerun an experiment using all the same settings (command, compute, datasets, docker image and so on), select an experiment, click **Menu** and then select **Rerun** from the dropdown menu.  You will be taken to the run page and all of the details will be pre-selected. You can then check and change anything before finally running this new instance of the experiment.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is More Info Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Export your experiments table More Info Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "In order to export an experiment table, you must first navigate over to the **Experiments** tab.  From there you have three options:  1. **Export all** from the **Actions**  drop-down menu.    2. Select a few experiments and from the **Actions**  drop-down menu, you can export only those. 3. To export a single Experiment, click **Menu** on the right-hand side of its row and click **Export**     "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use View experiments using the CLI More Info Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "You can also use the CLI to interact with your experiments, including viewing all your experiments and deep-diving into one of them.  To view all experiments, in your project directory run: bash cnvrg experiments   To view a specific experiment and check its status and metadata, run: bash cnvrg experiments --id ID_OF_EXPERIMENT # e.g Mja3xxhDMVi7AMVEexNs    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Experiment status More Info Cnvrg sample printing value"
      },
      {
        "role": "assistant",
        "content": "An experiment can have one of the following states - Pending - Initializing - Running - Success - Aborted - Error - Debug   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " cnvrg supports running distributed jobs, allowing you to run a single job using more than one Kubernetes node. This enables you to achieve higher utilization of your resources and perform the best compute methodology for each job.  cnvrg supports two forms of distributed jobs: - Open MPI - PyTorch Distributed - Spark on Kubernetes - Remote Spark Clusters  The topics in this page: [[TOC]]   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " Spark is a great tool for running distributed jobs and processing data efficiently. cnvrg supports two different ways of using Spark: - [Spark on Kubernetes](#spark-on-kubernetes) - [Remote Spark clusters](#remote-spark-clusters)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Spark on Kubernetes Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " There is no setup required to use Spark on Kubernetes. As soon as you [add a new Kuberenetes cluster](../core_concepts/compute.md#add-a-kubernetes-cluster), cnvrg automatically creates Spark templates. When you run a job on one of these templates with a compatible Spark container and Spark compatible code, cnvrg will spin up the Spark nodes on Kubernetes for you.  When the Spark session concludes, cnvrg will spin down the Spark nodes.  ::: warning To use Spark, ensure you pick both a Spark compute and Spark container. cnvrg comes pre-configured with a default cnvrg Spark container you can use. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Spark on Kubernetes compute templates Spark on Kubernetes Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " A Spark on Kubernetes compute template represents a master node and a certain amount of executors. The template sets the resources for the master nodes and executors separately.  You can [create your own custom Spark compute templates](../core_concepts/compute.md#add-a-compute-template).  For example, a template called `spark-medium` with resources `4 CPUs 8 GB + 4 Workers: 4 CPUs 8.0 GB 0 GPUs`, indicates that the Spark master node will have 4 CPUs and 8 GB of memory. It also means that when a Spark Session is opened, 4 new executor pods will be spun up with 4 CPUs and 8 GB of memory each.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Spark on Kubernetes master nodes and executors Spark on Kubernetes Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " When you spin up a job using a Spark compute template and compatible Spark container, you are initially only spinning up a master node. This is true for both workspaces and experiments.  When you open a SparkSession within the job, the executor pods are spun up. As the resources need to be allocated and the pods spun up, this process is not immediate. The request may even trigger a scale up of your Kubernetes cluster and more nodes may be added. You can track this process from the SparkUI. Once all the executors are live, the Spark job will run.  When the SparkSession concludes, the executors will be spun down, but the master node will remain live until the workspace is closed or the experiment ends.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remote Spark clusters Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " If you have created a persistent remote Spark cluster, you can easily connect with and leverage it within cnvrg. There are some key differences when compared to Spark on Kubernetes: 1. [You must first add the remote Spark cluster as a compute resource](../core_concepts/compute.md#add-a-remote-spark-cluster). 2. [Then you need to define templates for the remote Spark cluster](../core_concepts/compute.md#add-a-compute-template).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remote Spark compute templates Remote Spark clusters Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " A remote Spark compute template represents a set of regular compute templates on a Kubernetes cluster or machine and a certain amount of executors in the remote Spark cluster.  To get started using the remote Spark cluster you must first [create one or more templates](../core_concepts/compute.md#add-a-compute-template). In this template, you define the compute templates that cnvrg will spin up as a driver and the specifications for workers inside the remote Spark cluster.  For example, a template called `remoteSparkSmall`  could have its driver set as `small` and have 2 workers each with 2 CPUs and 4 GB of memory.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remote Spark driver and executors Remote Spark clusters Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " When you spin up a job using a remote Spark compute template and compatible Spark container, you are only spinning up a driver node on a Kubernetes cluster or machine (as defined in the compute template). This is true for both workspaces and experiments.  When you open a SparkSession within the job, instead of spinning up new nodes on Kubernetes, cnvrg will connect the driver to the remote Spark cluster using the configuration you supplied when setting up the Spark cluster in cnvrg. It will then use the amount of workers and their specifications (as defined in the compute template) and start the Spark processing on the remote cluster. cnvrg will not directly manage the remote Spark cluster to spin up or spin down nodes.  When the SparkSession concludes, the driver node will remain live until the workspace is closed or the experiment ends.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use SparkUI Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " Whenever you create a SparkSession, wether in an experiment or a workspace, you will gain access to the SparkUI.  ::: tip You can only view the Spark UI while the Spark context is live. Before and after the Spark context, you will be unable to view the Spark UI. :::  **In a workspace**  You can access the SparkUI by clicking **SparkUI** on the workspaces' sidebar.  **In a experiment**  You can access the SparkUI in an experiment from the menu on the experiments' page.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using data with Spark Spark in cnvrg Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " When using Spark, a Spark compute template and a compatible Spark container, the data that you will be processing using Spark needs to be made available to all the Spark executors.  Therefore, you will need to use the remote link to the data you want to train on and not simply train on a mounted dataset. Instead of running your spark session using data from `/data` use the link to the actual file.  For example: python spark = SparkSession.builder.getOrCreate() df = spark.read.csv(\"s3a://link-to-file\")   If you are using cnvrg datasets, you can find the correct link by navigating to the file viewer for the dataset, finding the file and then copying the link.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Open MPI Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " Open MPI is a technology that allows th running of distributed jobs over multiple nodes on your Kubernetes. cnvrg fully supports this use case and will simplify the DevOps, allowing you to spin up Open MPI jobs with little additional effort.  To run an Open MPI job, you must use a compatible Open MPI container, Open MPI compatible code and an Open MPI compute template.  ::: warning To use Open MPI, ensure you pick both an Open MPI compute and Open MPI container. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Open MPI compute templates Open MPI Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " An Open MPI compute template represents a master node and a certain amount of executors. The template sets the resources for the master nodes and executors separately.  You can [create your own custom Open MPI compute templates](../core_concepts/compute.md#add-a-compute-template).  For example, a template called `Open-MPI-medium` with resources `2 CPUs 4 GB + 2 Workers: 4 CPUs 16.0 GB 1 GPUs`, indicates that the Open MPI master node will have 2 CPUs and 4 GB of memory. It also means that when the `mpirun` command is called 2 new executor pods will be spun up with 4 CPUs and 16 GB of memory and 1 GPU each.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Master nodes and executors (Open MPI) Open MPI Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " When you spin up a job using an Open MPI compute template and compatible Open MPI container, both the master node and the workers nodes (executors) are spun up.  The code (git repo and **Files**) as well as chosen datasets are cloned to the master node and the workers nodes, so you can access them as you would in a regular cnvrg job.  When the job concludes, all the resources will be spun down.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use More information Open MPI Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " To learn how to leverage Open MPI within your code, consult the [Open MPI documentation](https://www.open-mpi.org/doc/current/).   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is PyTorch Distributed Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " PyTorch has a fully native module `torch.distributed` that allows data scientists to easily parallelize their computations across multiple nodes. To do so, it leverages messaging passing semantics allowing each process to communicate data to any of the other processes. cnvrg has full support for using PyTorch in this fashion without needing to perform any of the DevOps or MLOps work for yourself.  To run an PyTorch Distributed job, you must use a compatible PyTorch container, and an PyTorch Distributed compute template.  ::: warning To use PyTorch Distributed, ensure you pick both a PyTorch Distributed compute and PyTorch container. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use PyTorch Distributed compute templates PyTorch Distributed Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " A PyTorch Distributed compute template represents a certain amount of workers nodes (executors). The template sets the resources for the executors.  You can [create your own custom PyTorch Distributed compute templates](../core_concepts/compute.md#add-a-compute-template).  For example, a template called `PyTorch-Dist-medium` with resources `4 Workers: 4 CPUs 16.0 GB 1 GPUs`, indicates that the workers nodes will have 4 CPUs and 16 GB of memory and 1 GPU each.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Workers nodes (PyTorch Distributed) PyTorch Distributed Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " When you spin up a job using an PyTorch Distributed compute template and compatible PyTorch container, the defined workers nodes (executors) are spun up.  The code (git repo and **Files**) as well as chosen datasets are cloned to the workers nodes, so you can access them as you would in a regular cnvrg job.  When the job concludes, all the resources will be spun down.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use PyTorch Distributed commands PyTorch Distributed Cnvrg Distributed Jobs"
      },
      {
        "role": "assistant",
        "content": " Once you have selected a compatible PyTorch Distributed template, you can run your code with a regular python command. For example, `python my_script.py`. cnvrg will automatically add the required flags to the rest of your command to ensure it runs correctly.  ::: warning NOTE Normally, you would need this full line to run your code: `python -m torch.distributed.launch --nproc_per_node=1 --nnodes=2 --node_rank=0 --master_addr=\"localhost\" --master_port=3000\" my_script.py`.  **However, cnvrg automatically injects the extra part into your command, so you only need to enter `python my_script.py`.** :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " Publishing and deploying your models has never been this easy. With one click you're able to deploy models on Kubernetes clusters quickly and easily.  cnvrg supports three types of endpoints: web services, kafka streams and batch predictions.  For web services, cnvrg will automatically encase your code and models in a lightweight REST API and expose it to the web. It will generate an authentication token to protect the use of the endpoint and automatically build comprehensive model tracking and monitoring tools.  For kafka streams, cnvrg supports integrating model predictions with existing Kafka streams. This allows you to ingest Kafka streams and perform realtime predictions with complex model monitoring features.  For batch predictions, cnvrg will create a model endpoint that will be remain inactive with 0 pods until a prediction is made. The endpoint will then scale up as needed and scale back down after the prediction is completed.  The topics in this page: [[TOC]]    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Requirements for a cnvrg Service Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " Creating services in cnrvg is a simple process. There are, however, a few requirements that your code must meet for everything to work. Before deploying an endpoint, make sure your code adheres to the following requirements:  * You must create a function that handles the querying of the supplied model and returns the output. * The above function must return a Simple Object or a type that [flasks jsonify function can handle](https://flask.palletsprojects.com/en/1.1.x/api/#flask.json.jsonify). * You can not return an already jsonified object as cnvrg will perform that function for you. * The input from the query will be sent to your code exactly as entered, so in the predict function, it should be referenced similarly to this: `def predict(*input):`. * The name of the file containing the function cannot have a dash (`-`) in it. * When **Function accepts file as input** is enabled: The service will expect a Base64 encoded file. cnvrg will then decode the Base64 and pass the decoded file to your predict function.  ::: tip Because the service is constructed using your code, you can execute any code from your git and project files from within the predict function. This allows you to process inputs and trigger other logic in addition to querying your model. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Examples of predict functions Requirements for a cnvrg Service Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " * Example 1 - Receiving a sentence for sentiment analysis and processing it before using the model: python def predict(sentence): encoded = encode_sentence(sentence) pred = np.array([encoded]) pred = vectorize_sequences(pred) a = model.predict(pred) return str(a[0][0])   * Example 2 - Receiving an array and parsing it before using the model: python def predict(*data): data = np.asarray(data) a=model.predict(data) return round(a[0][0],0)   * Example 3 - Receiving a file and processing it before using the model: python def predict(file_path): img = load_img(file_path, grayscale=True, target_size=(28, 28)) img = img_to_array(img) img = img.reshape(1, 28, 28, 1) img = img.astype('float32') img = img / 255.0 digit = model.predict_classes(img) return str(digit[0])   * Example 4 - Receiving multiple parameters: python def predict(a, b, c): prediction = model.predict(a, b) result = prediction[0] - c return str(result)    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Preprocess Function Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " All endpoints can optionally include a preprocessing function. Similarly to how the prediction function works, all inputs will be received as an input for the preprocess function, whereupon they will be processed by the function. Afterwards, the output of the preprocess function will be used as the input for the predict function.  This makes it easy to apply any processing on the inputs that may be required before the prediction can be made.  The same [requirements that apply to a prediction function](#requirements-for-a-cnvrg-service) also apply to the preprocessing function. However, you must verify that the output of your preprocessing function is compatible as the input of the prediction function.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Web Services Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " cnvrg can help you set up a real time web service. cnvrg will take your code and model and encase it in a lightweight REST API service, enabling it to be queried easily through the web.  All that is required is for you to provide a compatible [predict function](#requirements-for-a-cnvrg-service) and cnvrg will do the rest. Additionally, you can optionally use a [preprocessing function](#preprocess-function), that will process each input before the prediction is made.  cnvrg will set up all the network requirements and deploy the service to Kubernetes, allowing you to leverage auto-scaling and ensure you can accommodate all incoming traffic. It will add an authentication token to secure access. Furthermore, it will add an entire suite of monitoring tools, simplifying the process of managing your web service and its performance.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Publishing a new web service endpoint Web Services Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " You can create a new web service endpoint in cnvrg in two ways: 1. Publishing a new model from the **Serving** tab. 2. Using a **Deploy Task** in a flow.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Serving tab\"   To create a new service in cnvrg from the **Serving** tab: 1. Go to the **Serving** tab for the project. 2. (If you already have endpoints deployed) Click **+ Add Endpoint**. A menu will appear. 3. Click **Web Service**. 4. On the form that appears fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute that the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * **cnvrg.io commit**: Which commit of your project files to include in the service. If blank it defaults to `HEAD`. This is often used to deploy a specific model affiliated with a specific experiment commit. Ensure all the files needed for your service (predict function, model, etc.) are in the chosen commit. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. * **Flask Config**: [Transfer custom parameters to the Flask environment](#flask-config). * **Gunicorn Config**: [Add or update Gunicorn config variables](#gunicorn-config). * **Function accepts file as input**: Enable or disable the ability for the model to accept files as an input. 5. Click **Deploy Endpoint**.  cnvrg will automatically allocate the resources and build the endpoint for you. ::: ::: tab \"Deploy Task\"  To create a new service in cnvrg from a **Deploy Task**: 1. Go to the **Flows** tab for the project. 2. Open an existing flow or create a new one by clicking **New Flow**. 3. Click **New Task** > **Deploy Task**. 4. On the card that appears click **Select Endpoint** > **+ Add New** (this is at the bottom of the list). 5. At the top of the form, click **Web Service**. 6. In the form, fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute that the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. * **Flask Config**: [Transfer custom parameters to the Flask environment](#flask-config). * **Gunicorn Config**: [Add or update Gunicorn config variables](#gunicorn-config). * **Function accepts file as input**: Enable or disable the ability for the model to accept files as an input. 7. Click **Deploy Endpoint**.  When the flow is run and the task is reached, cnvrg will automatically allocate the resources and build the endpoint for you. ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Query a web service Web Services Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " There are 2 main methods that can be used to query a cnvrg service: 1. Using API calls 2. Using the Python SDK  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"API Calls\"  All cnvrg endpoints are configured as REST APIs, so you can query them similar to any other API call.  When you create a service in cnvrg, 2 preformatted snippets will be provided for you as examples for how to query the model: 1. curl snippet 2. Python snippet  You can use either of them to start querying your model. You can also implement the API call with any technology stack you want.  You can also submit an array with multiple parameters by simply setting the `\"your_input_params\"` to an array: `[param1, param2, param3]\"`. ::: ::: tab \"Python SDK\"  **Single predictions**  To query a cnvrg endpoint with the Python SDK, you first need to load the endpoint using `Endpoint(\"endpoint_id\")` and then use the `predict()` method on the loaded endpoint.  python from cnvrg import Endpoint e = Endpoint(\"endpoint_id\") result = e.predict(input)   **Batch predictions**  You can use the Python SDK to batch predict. First, load the endpoint using `Endpoint(\"endpoint_id\")`, then use the `batch_predict()` method on the loaded endpoint.  python from cnvrg import Endpoint e = Endpoint(\"endpoint_id\") results = e.batch_predict([input1, input2,...,inputn], pool_size=amount_of_request_threads)  ::: :::: <!--  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use # Logging predictions when streaming predictions Query a web service Web Services Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " When streaming predictions, you may want to log a prediction. Using the `log_request` method will instruct the cnvrg endpoint to log a prediction without querying the Rest API.  python from cnvrg import Endpoint e = Endpoint(\"endpoint_id\") e.log_request(input, output, start time (in ms))  The endpoint will add the prediction to its logs and metrics just as it would when being queried in normal use. The input and output each must be a String (or any printable object/type) and default to `None`. Elapsed time is recorded in milliseconds, must be an Integer and defaults to `0`.  -->  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Batch Predictions Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " cnvrg can help you set up all the required infrastructure to easily query your model with batch predictions. cnvrg will take your code and model and encase it in a lightweight REST API service, enabling it to be queried easily through the web. However, when not in use, the service will be scaled down to 0 pods - ensuring you are not using compute resources while not making predictions.  You will also be able to track each batch prediction that is made through the service. A batch predict endpoint comes with the same features for monitoring and tracking that web services and kafka streams have.  All that is required is for you to provide a compatible [predict function](#requirements-for-a-cnvrg-service). Additionally, you can optionally use a [preprocessing function](#preprocess-function), that will process each input before the prediction is made.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Predictions Tab Batch Predictions Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " cnvrg will track all the batch predictions that are made to the endpoint. You can access them from the **Predictions** tab.  There you can see all the batch predictions that ran using the specific endpoint. You can click on the name to go to the experiment page for the specific prediction. Clicking the **Compare All** button will take you to an experiment comparison of all of the batch prediction experiments.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Publishing a new batch predict endpoint Batch Predictions Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " You can create a new batch prediction endpoint in cnvrg in two ways: 1. Publishing a new model from the **Serving** tab. 2. Using a **Deploy Task** in a flow.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Serving tab\"   To create a new service in cnvrg from the **Serving** tab: 1. Go to the **Serving** tab for the project. 2. (If you already have endpoints deployed) Click **+ Add Endpoint**. A menu will appear. 3. Click **Batch**. 4. On the form that appears fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute tha the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * **cnvrg.io commit**: Which commit of your project files to include in the service. If blank it defaults to `HEAD`. This is often used to deploy a specific model affiliated with a specific experiment commit. Ensure all the files needed for your service (predict function, model, etc.) are in the chosen commit. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. * **Flask Config**: [Transfer custom parameters to the Flask environment](#flask-config). * **Gunicorn Config**: [Add or update Gunicorn config variables](#gunicorn-config). * **Function accepts file as input**: Enable or disable the ability for the model to accept files as an input. 1. Click **Deploy Endpoint**.  cnvrg will automatically allocate the resources and build the endpoint for you. ::: ::: tab \"Deploy Task\"  To create a new service in cnvrg from a **Deploy Task**: 1. Go to the **Flows** tab for the project. 2. Open an existing flow or create a new one by clicking **New Flow**. 3. Click **New Task** > **Deploy Task**. 4. On the card that appears click **Select Endpoint** > **+ Add New** (this is at the bottom of the list). 5. At the top of the form, click **Batch**. 6. In the form, fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute tha the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. * **Flask Config**: [Transfer custom parameters to the Flask environment](#flask-config). * **Gunicorn Config**: [Add or update Gunicorn config variables](#gunicorn-config). * **Function accepts file as input**: Enable or disable the ability for the model to accept files as an input. 1. Click **Deploy Endpoint**.  When the flow is run and the task is reached, cnvrg will automatically allocate the resources and build the endpoint for you. ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Make a batch prediction Batch Predictions Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " You can conduct a batch prediction using the Batch Predict AI Library in a flow or with the SDK.  When the library is run, the chosen batch predict endpoint will be scaled up. A batch prediction will then be made using the CSV input file. The output predictions will be saved in a new output CSV file and then the output CSV will sync with the chosen dataset.  The AI Library has four parameters: * `endpoint_id`: The name of the batch predict endpoint you are using. The endpoint must already be deployed. * `input_file`: The path of a CSV file with the data for the batch prediction. * `output_file`: The path of the CSV output file. It must not start with a `/`. For example, `output/predictions.csv`. * `dataset`: The name of an existing dataset that the output CSV will be uploaded to.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Flow\"  To make a batch prediction using a flow: 1. Go to the **Flows** tab for the project. 2. Open an existing flow or create a new one by clicking **New Flow**. 3. Click **New Task** > **Batch Predict**. 4. Fill in the required parameters as explained above. 5. Click **Save Changes** 6. Add further tasks to the fow if required. 7. Click **Run** to begin the batch prediction and run the flow. The flow will run and the batch prediction will be made. ::: ::: tab \"SDK\" To make a batch prediction using the SDK, use the following code snippet. Update the parameters with the correct information: py from cnvrg import Library library = Library('cnvrg/batch_predict') experiment = library.run( endpoint_id=\"ENDPOINT_ID\", input_file=\"INPUT_FILE\", output_file=\"OUTPUT_FILE\", dataset=\"DATASET\" )   You can learn more about running AI Libraries using the [here](../core_concepts/python_sdk.md#ai-library-operations). ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Kafka Streams Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " cnvrg supports integrating model predictions with existing Kafka streams. This allows you to ingest Kafka streams and perform realtime predictions with complex model monitoring features.  [Kafka is an open source library](https://kafka.apache.org/24/documentation/streams/developer-guide/) that allows for low-latency streaming of data. This is done with 0 batching. With these key benefits in mind, streaming can be useful for moving and processing data as soon as it is ingested, avoiding complex triggering and scheduling as data comes in. With the integration to cnvrg, you can perform model predictions on a Kafka stream - unlocking the ability to predict in realtime on all incoming data. Both Kafka and cnvrg leverage clusters and scaling technology, ensuring that your service will be capable of dealing with any incoming demand.  You will need to provide: - a compatible [predict function](#requirements-for-a-cnvrg-service). The input will be in the format of `bytes` literal. - A running Kafka service including: - a Kafka broker - Input topics - an Output topic  Additionally, you can optionally use a [preprocessing function](#preprocess-function), that will process each input before the prediction is made.  cnvrg will stream the data from the input topics to the model via the predict function and stream the output back to the output topic.  Using Kafka streams with cnvrg allows you to make realtime predictions while also leveraging all the other cnvrg model tracking features (logs, a/b testing, canary deployment, integration with flows, continual learning etc).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Streaming behavior Kafka Streams Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " When you start a new Kafka stream endpoint, the model will make predictions on messages at the latest point on the input stream. That means, that predictions will only be made on new entries to the input stream received once the endpoint has been deployed.  When rolling over a new model into production for an existing endpoint, the old model will be used, up until the new model finishes deploying. Then, the new model will continue making predictions from the same point on the input stream that the previous model finished at. This ensures zero downtime and complete data continuity.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Autoscaling with Kafka Kafka Streams Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " As with web service endpoints, cnvrg supports autoscaling for Kafka streams. As Kafka streams are backed by Kubernetes, cnvrg will automatically replicate the service to accommodate for incoming demand, allowing you to have a powerful and stable service.  You can control the lower and upper bounds for the autoscaling feature by setting the **Number of Pods** to indicate the minimum amount of pods for the stream and the maximum. The maximum number of pods is bounded by the number of partitions of the input topics.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Publishing a new Kafka stream Kafka Streams Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " You can create a new Kafka stream in cnvrg in two ways: 1. Publishing a new model from the **Serving** tab. 2. Using a **Deploy Task** in a flow.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Serving tab\"   To create a new service in cnvrg from the **Serving** tab: 1. Go to the **Serving** tab for the project. 2. (If you already have endpoints deployed) Click **+ Add Endpoint**. A menu will appear. 3. Click **Stream**. 4. On the form that appears fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute that the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * **Kafka Brokers**: The Kafka broker responsible for the streaming capabilities. * **Input Topics**: The Kafka topic(s) that will be expected as input. * **Output Topic**: The Kafka topic that predictions will be streamed under. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * **cnvrg.io commit**: Which commit of your project files to include in the service. If blank it defaults to `HEAD`. This is often used to deploy a specific model affiliated with a specific experiment commit. Ensure all the files needed for your service (predict function, model, etc.) are in the chosen commit. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. 5. Click **Deploy Endpoint**.  cnvrg will automatically allocate the resources and build the endpoint for you.  :::  ::: tab \"Deploy Task\" To create a new service in cnvrg from a **Deploy Task**: 1. Go to the **Flows** tab for the project. 2. Open an existing flow or create a new one by clicking **New Flow**. 3. Click **New Task** > **Deploy Task**. 4. On the card that appears click **Select Endpoint** > **+ Add New** (this is at the bottom of the list). 5. In the form that appears fill in the following details: * **Endpoint Title**: The name of the service. This is also used as part of the url for the REST API and as such can only contain alphanumeric characters and hyphens. * **Compute**: The compute tha the service will run on. * **Image**: The Docker container that will serve as the virtual environment for the endpoint. * **Number of Pods**: Set the lower and upper bounds for auto-scaling of the service due to demand. Set them according to the predicted traffic to the endpoint. * **Kafka Brokers**: The Kafka broker responsible for the streaming capabilities. * **Input Topics**: The Kafka topic(s) that will be expected as input. * **Output Topic**: The Kafka topic that predictions will be streamed under. * Predict: * **File**: The file containing your predict function. * **Function**: The function name of your predict function. * Preprocess: * **File**: The file containing your preprocess function. * **Function**: The function name of your preprocess function. * **Language**: Which language your service is in. * (If connected to git) **Git Branch** and **Git Commit**: Which branch and commit of your git repository to clone. 6. Click **Deploy Endpoint**.  When the flow is run and the task is reached, cnvrg will automatically allocate the resources and build the endpoint for you. ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Charts Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " To make tracking your service as easy as possible, cnvrg supports automatic and custom tracking on all endpoints. These can be found in the **Charts** tab for your service.  cnvrg will automatically create live charts for the **Requests per Minute** (traffic) and the **Endpoint Latency** (response time).  You can create new line graphs using the Python SDK. [Use the `log_metric()` method](../core_concepts/python_sdk.md#endpoint-tracking-and-visualizing) to track new metrics like accuracy and drift.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Logs and Endpoint Data Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "  You can find all the logs for each prediction in the **Logs** tab.  Every prediction, input and output of the Serving endpoint is recorded and logged. All data is tracked and you can quickly see how your models work in production environment. You can also **Export** the data as a CSV and analyze it.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Feedback Loops Logs and Endpoint Data Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " With cnvrg feedback loops you can export endpoint data to a cnvrg dataset. Queries, predictions and endpoint logs are important pieces of data. Training on real predictions can help improve model performance, which is wh feedback loops can be incredibly useful.  A feedback loop will export the endpoint data (queries, predictions, metadata etc.) either immediately, or according to the schedule that you set.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a feedback loop Feedback Loops Logs and Endpoint Data Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " To create a feedback loop: 1. Go to the endpoint of your choice. 2. Go to the **Logs** tab. 3. Click **Configure Feedback Loop**. A new form will appear. 4. Click the **Dataset** selector to choose the dataset to sync the data to. 5. For **Scheduling**, Choose wether to sync the data **Now** or **Recurring**. 6. (If you choose recurring) Choose the schedule information by setting: * **Save every**: What frequency to run the feedback loop. * **On the**: The details of when exactly the repeated feedback loop should occur. 7. Click **Save**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use End a feedback loop Feedback Loops Logs and Endpoint Data Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " To end a recurring feedback loop: 1. Go to the endpoint of your choice. 2. Go to the **Logs** tab. 3. Click **Stop** next to **Configure Feedback Loop**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Monitoring Systems Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " cnvrg's endpoints are backed by Kubernetes and cnvrg automatically installs advanced monitoring tools for production-grade readiness. cnvrg will install Grafana for dashboarding and Kibana for log visualizations, and more.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Grafana Monitoring Systems Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "  Grafana is platform for analytics and monitoring. Grafana is used for monitoring a Kubernetes cluster.  You can see the Grafana dashboard directly from UI by going to the running endpoint and selecting the **Grafana** tab.  cnvrg preconfigures a dashboard for monitoring the health of your pods including: - Memory usage: The memory usage of pod - CPU usage: The CPU usage of pod - Network I/O: The input and output of traffic of pod   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Kibana Monitoring Systems Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " Kibana allows you to visualize the Elasticsearch data. Kibana tool show all the prints in code, and visualizes them by turning them into graphs.  You can access Kibana in the **Kibana** tab in your endpoint.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Update the Model Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " For endpoints that are in the `Running` state, you can update models easily. Go to the **Config** tab and click **Update Model**. Then you will be prompted with the new model form, where you can specify file, function and/or a different commit version.  When clicking **Update**, cnvrg will gradually roll-out updates to the Endpoint using Canary Deployment mechanism (see below).  You can also update the model using a [flow](#updating-endpoints-with-flows)   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Canary Release Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "  Canary release is a technique to reduce the risk of introducing a new software version in production. This allows you to slowly roll out the change to a small percentage of the traffic, before rolling it out to the entire infrastructure and making it available to everybody. This allows you to check your model during its gradual roll out, and if any issues are revealed, you can undo the change before it reaches too many users.  When rolling out a new model to an existing service, you can choose a **Canary Rollout**. This will indicate how much of incoming traffic is served by the new model. You can subsequently increase that ratio as desired.  You also have the ability to rollback the model if it is not fulfilling your needs. In this case, the previous model will be served to all traffic.  Using flows, you can create a fully automated canary release with gradual rollout according to custom validation and the ability to rollback automatically if needed.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Rollout a new model with Canary Release Canary Release Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "You can roll out a new model to a chosen ratio of incoming traffic in two ways: 1. On the Endpoint's **Config** tab. 2. Using a **Deploy Task** in a flow.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Config Tab\"  To introduce a new model with a specific **Update Ratio** from the **Config tab**: 1. Navigate to the endpoint of your choice. 2. Click the **Config** tab. 3. Click **New Version**. 4. Fill in the **File**, **Function**, **cnvrg.io Commit** and other configuration details for the new model. 5. Enable **Canary Rollout** by clicking the toggle. Set the **Traffic Ratio** to the desired percent. 6. Click **Update**. The new model will begin deploying, and will be served to the chosen percentage of users. ::: ::: tab \"Flow\"  To introduce a new model with a specific **Update Ratio** from a flow: 1. Go to the **Flows** tab of your project. 2. Open an existing flow or create a new one. 3. Click the **New Task** menu. 4. Choose **Deploy Task** from the menu. 5. In the **Select Endpoint** menu, click the name of the existing endpoint you would like to update. 6. Enable **Canary Rollout** by clicking the toggle. Set the **Traffic Ratio** to the desired percent. 7. Click **Save Changes**. When the task is run as part of the flow, the end commit of the task that is connected to the newly created deploy task will begin deploying. The model will be served to the chosen percentage of users. ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Rollback a model Canary Release Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "You can rollback a new model using the rollback AI Library with the SDK or within a flow.  When the library is run, the chosen endpoint will have its latest model rolled back. The previous model will then be used.  The AI Library has one parameter: * `endpoint_id`: The name of the endpoint you are rolling back.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Flow\"  To make a batch prediction using a flow: 1. Go to the **Flows** tab for the project. 2. Open an existing flow or create a new one by clicking **New Flow**. 3. Click **New Task** > **Rollback**. 4. Fill in the required parameter as explained above. 5. Click **Save Changes** 6. Add further tasks to the fow if required. 7. Click **Run** to begin the batch prediction and run the flow. The flow will run and the model will be rolled back. ::: ::: tab \"SDK\" To roll back a model using the SDK, use the following code snippet. Update the parameters with the correct information: py from cnvrg import Library library = Library('cnvrg/rollback') experiment = library.run( endpoint_id=\"ENDPOINT_ID\" )   You can learn more about running AI Libraries using the [here](../core_concepts/python_sdk.md#ai-library-operations).  You can also use the [`.rollback()` Python SDK method](../core_concepts/python_sdk.md#rollback-to-previous-model). ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Continual Learning (Triggers) Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "![Trigger](../images/continual-learning-new.png \"Create a new Trigger\") With cnvrg you can ensure your endpoint is performing accurately and not experiencing decay by leveraging triggers within the platform. A trigger allows you to run an action based on the metrics being tracked in your endpoint. These actions allow you to simply and easily manage the endpoint and automate the upkeep of your service. You can send emails to your team or even run an end-to-end flow to retrain your model and update your endpoint automatically, with zero downtime!  The triggers are based on the metrics you log within your endpoint using the cnvrg SDK. To do so, first import the package: `from cnvrg import Endpoint`, then initialize an endpoint object: `e = Endpoint()` and finally log a metric: `e.log_metric(\"key\",value)`. Now that you are logging a metric, you can use that metric as the tag inside your new trigger.  ::: tip To see more info on `e.log_metric()` click [here](../core_concepts/python_sdk.md#endpoint-operations). :::  To create a new trigger, click the **Continual Learning** tab in your endpoint. Click **New Alert** then fill in the necessary details in the panel that appears.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use **Info:** Continual Learning (Triggers) Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "- **Title**: The name for the trigger. - **Severity**: An indication of the importance of this alert (Info, Warning or Critical).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use **If Condition:** Continual Learning (Triggers) Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "- **Tag**: The cnvrg SDK metric used for the trigger. (Only tags with numeric values are currently supported.) - **Comparision Type**: the type of comparison used for comparing with your set value (greater than or less than). - **Value**: The value you are comparing against. - **Run Condition Every**: How often to poll your endpoint to test for the trigger. - **Minimum events**: Number of times the condition needs to be fulfilled before the alert is triggered.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use **Action:** Continual Learning (Triggers) Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "- **Trigger**: What type of action will occur when the alert is triggered - **Email (*if applicable*)**: The email address/es that will receive an email when the alert is triggered. - **Flow (*if applicable*)**: The flow that will run when the alert is triggered.  Finally, click **Add** and you will have successfully created a new trigger! Whenever the criteria you set in the trigger are fulfilled, the action you have set will automatically run.  ::: tip NOTE Make sure the tag you choose for the trigger matches the metric you are logging in the endpoint exactly. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Accepting files as an Input Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " Web services and batch prediction endpoints in cnvrg can be set to accept files. Enable this functionality when launching a service or batch predict by enabling **Function accepts file as input**.  To send a file to the endpoint, you must encode it in Base64 and then send the encoded string as the input to the model.  cnvrg will handle the decoding of the file for you and pass the decoded file to your predict function. That means your predict function can simply expect a file as the input, and no further decoding is needed.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Flask Config Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " [Flask is a lightweight web framework](https://flask.palletsprojects.com/en/1.1.x/) that is used by cnvrg to create an API for [Batch](#batch-predictions) and [Web Service](#web-services) endpoints.  You can alter the configuration for Flask in your endpoint by adding KEY-VALUE pairs in the **Flask Config** section of the endpoint form.  Each KEY-VALUE pair will be added to the Flask configuration file as follows: py app.config['KEY'] = 'VALUE\"   These KEY-VALUE pairs will then be exported as environment variables that your deployment can access.  Information on Flask configuration and values can be found in the [Flask documentation](https://flask.palletsprojects.com/en/1.1.x/config/).  For example, to set the `FLASK_ENV` as `development`, fill in the following: * KEY: `FLASK_ENV` * VALUE: `development` The value will be exported in the config file and set in Flask.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Gunicorn Config Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": "[Gunicorn is a simple and scalable framework](https://gunicorn.org/) that is used by cnvrg to run the server for [Batch](#batch-predictions) and [Web Service](#web-services) endpoints.  You can change the Gunicorn settings in your endpoint by adding KEY-VALUE pairs in the **Gunicorn Config** section of the endpoint form.  There are two requirements: * You cannot alter the `bind` setting. * You can only change settings that work with a KEY-VALUE pair and not settings that are just a flag or KEY. For example, you cannot use `reload` as that does not have a key. Otherwise, you can use any of the config settings from the [Gunicorn documentation](https://docs.gunicorn.org/en/stable/settings.html).  There are two default Gunicorn config settings that cnvrg sets: * `workers` - This will be set according to the cpu of the compute template you select. * `timeout` - This defaults to `1800`. These default values can be overridden by submitting alternative values in the **Gunicorn Config** section.  For example, to change the amount of threads on each worker for handling requests to 4, fill in the following: * KEY: `threads` * VALUE: `4` When the service is initialized, Gunicorn will be run with `--threads 4`.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Updating Endpoints with Flows Cnvrg Serving"
      },
      {
        "role": "assistant",
        "content": " You can roll over a endpoint to a new model within a flow. To do so, add a **Deploy task** to your flow and set it to update an existing endpoint of your choice: 1. Go to the **Flows** tab of your project. 2. Open an existing flow or create a new one. 3. Click the **New Task** menu. 4. Choose **Deploy Task** from the menu. 5. In the **Select Endpoint** menu, click the name of the existing endpoint you would like to update. 6. Click **Save Changes**.  When the flow is run successfully, the endpoint will roll over to the end commit of the task that is connected to the newly created deploy task, with zero downtime.  Learn more about flows on the [flows docs](../core_concepts/flows.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " A cnvrg workspace is an interactive environment for developing and running code.  You can run any kind of interactive development environment, Python scripts and much more. The environment is pre-configured (meaning all your dependencies are preinstalled). All the files and data in your workspace will be preserved for you, across restarts. Your workspace has automatic version control and scalable compute available, so that you can use unlimited compute resources to do your data science research.  cnvrg.io has built-in support for JupyterLab, JupterLab on Spark, R Studio and Visual Studio Code to run on remote computes.  ![workspaces](../images/empty-workspace.png \"Create a workspace\")  <!-- Aaron: update this image to show some active sessions at the bottom. -->  The topics in this page: [[TOC]]   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " There are a variety of supported workspace types that are supported in cnvrg: * JupyterLab * JupyterLab on Spark * R Studio * Visual Studio Code  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use JupyterLab Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " JupyterLab is a next-generation web-based user interface for Project Jupyter. JupyterLab enables you to work with documents and activities such as Jupyter notebooks, text editors, terminals, and custom components in a flexible, integrated, and extensible manner.  [Learn more about JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Night Mode in JupyterLab JupyterLab Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " To switch your JupyterLab notebook to dark mode, click **Settings** inside the workspace > **JupyterLab Theme** > **JupyterLab Dark**.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use JupyterLab on Spark Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " JupyterLab can also be run on Spark in cnvrg. Choose this option with a compatible Spark **Compute** template to get started with JupyterLab backed by Spark.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use R Studio Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management  [Learn more about R Studio](https://rstudio.com/).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Visual Studio Code Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " Visual Studio Code is a lightweight but powerful source code editor which runs on your desktop and is available for Windows, macOS and Linux. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages (such as C++, C#, Java, Python, PHP, Go) and runtimes (such as .NET and Unity).  [Learn more about Visual Studio Code](https://code.visualstudio.com/docs).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Visual Studio Code settings Visual Studio Code Supported Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " You can add a [Visual Studio Code settings file](https://code.visualstudio.com/docs/getstarted/settings) to your [user account](../core_concepts/team.md#change-account-settings). This will be used to configure any Visual Studio Code workspaces that you start.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Start a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " <!-- update -->  To start a new workspace: 1. Open a project then click the **Workspaces** tab. 2. Click **Start a Workspace**. 3. Choose the notebook type by clicking **Change type**: JupyterLab, JupyterLab on Spark, R Studio or VSCode. 4. Set the **Title** for the workspace. 5. Choose one or more **Compute** templates for your workspace. 6. (Optional) Choose **Datasets** to add to your workspace. 7. Choose a Docker **Image** to use for your workspace. 8. [(Optional) Choose an existing **Volume** or create a new one](#workspace-volumes). 9. Click **Start workspace**.  ![Workspace Starting](../images/workspace-starting.png \"Your workspace is starting\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Stop a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " A cnvrg workspace will stay open until closed or until the [**Max Workspace Duration**](../core_concepts/team.md#organization-settings) is reached.  There are two ways to stop a running workspace: 1. From inside the workspace. 2. From the **Workspaces** tab.  To stop a workspace that is loading or running: 1. Go to the **Workspaces** tab. 2. Either: - In the table of workspaces, click the menu at the right end of the workspace you want to stop, then click **Stop**. - Open the workspace you want to stop by clicking its name, then click the **Stop** button that appears at the top of the pane, next to the workspace name. 3. Confirm the stop action.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Rerun a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " There are two ways to rerun or re-open a stopped workspace: 1. From inside the workspace. 2. From the **Workspaces** tab.  To rerun a workspace that has stopped: 1. Go to the **Workspaces** tab. 2. Either: - In the table of workspaces, click the menu at the right end of the workspace you want to resume, then click **Start**. - Open the workspace you want to stop by clicking its name, then click the **Start** button that appears at the top of the pane, next to the workspace name. 3. Confirm the run action.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Delete a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "To delete a workspace: 1. Go to the **Workspaces** tab. 2. In the table of workspaces, click the menu at the right end of the workspace to resume, then click **Delete**. 3. Confirm the delete action.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Compute Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " Select the compute for your workspace [when starting the workspace](../core_concepts/compute.md#when-starting-a-workspace-or-experiment-using-the-web-ui).  Choose one or more compute templates you would like to use for your workspace. If the first compute is unavailable, jobs attempt to run on the next compute you have selected. If you only select one compute template, the job waits until it is available to run or until the [wait time reaches the max duration](../core_concepts/team.md#organization-settings).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Datasets Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " When starting a workspace you have the option of including one or more datasets. Choose the datasets you want to use when starting the workspace You can also choose a specific query or commit of the dataset at this point.  When you choose to clone or attache a dataset, it will be mounted in the remote compute and accessible from the absolute path: `/data/name_of_dataset/`.  For example, if you include your dataset `hotdogs`, when running an experiment, the dataset can be found at `/data/hotdogs/` and all of the dataset files will be found in that directory.  [Datasets can also be added to a live workspace](#attach-datasets-to-a-live-workspace).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Images Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " You choose the Docker image to serve as the basis for virtual environment of the workspace.  cnvrg's default Docker images support most standard use cases and are updated regularly. Learn more about using your own custom Docker image to support your specific use case [here](../core_concepts/environments.md#add-a-custom-docker-image).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Workspace Volumes (Kubernetes Only) Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " Workspace volumes allow you to create a persistent file system for your workspace. This enables you to persist the exact same files and datasets, even when shutting down workspaces and restarting them.  When a workspace is started without a volume, a fresh environment is created, and configuration will have to be repeated by the user. With a volume, the exact setup will be loaded as you left it. This allows you to work with a workspace as if it was your own laptop, restarting a workspace to find it the same as when you shut it down.  Volumes are specific to projects and can only be used by the project they were created in. A workspace has a title and a size (in GB). A volume can only be used by one workspace at a time.  When a volume is created, [the environment will be created according to the regular process](#the-files-in-a-workspace). When a volume is reused, the volume will simply be re-attached and no cnvrg cloning, data cloning or git cloning will take place at start up.  Workspaces volumes are supported natively in cloud Kubernetes clusters. Extra configuration is required to enable this functionality with on-premise clusters, reach out to cnvrg support to get started. This feature is not supported with on-premise machines.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use The files in a volume Workspace Volumes (Kubernetes Only) Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " A volume is attached to `/cnvrg` (the working directory) and `/data`. This means that only files in these two locations will be persisted in the volume.  If you are working with a [cached dataset commit](../core_concepts/datasets.md#caching-dataset-commits-nfs-integration), the commit will need to be reattached and will not be persisted in the volume.  Python packages and environment setup will not be persisted either.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Create a volume Workspace Volumes (Kubernetes Only) Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "  You can create a workspace volume from the workspace creation page:  1. On a project's dashboard, or from the **Workspaces** tab, click **Start a Workspace**. 2. In the pop up that appears, fill in the regular workspace form: **Title**, **Computes**, **Datasets** and **Image**. 3. Next to **Volume**, click **+ Create New**. The **Volume** field will update. 4. Enter a **Volume Title** and **Size (GB)** for the new volume. 5. Click **Start Workspace**. The workspace environment will start being constructed and the volume will be created and attached.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Use an existing volume Workspace Volumes (Kubernetes Only) Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " When restarting a closed workspace that was previously run with a volume, cnvrg wil automatically reattach the volume. Ensure that the volume is not currently in use before restarting the workspace.  You can also create a new workspace with an existing volume: 1. On a project's dashboard, or from the **Workspaces** tab, click **Start a Workspace**. 2. In the pop up that appears, fill in the regular workspace form: **Title**, **Computes**, and **Image**. You can skip datasets as using a volume will override the **Dataset** selector. 3. Choose the volume you wish to use from the **Volume** selector. Only volumes not currently in use can be selected. 5. Click **Start Workspace**. The workspace environment will start being constructed and the volume will be attached.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use How to save and reload your VScode extensions automatically Workspace Volumes (Kubernetes Only) Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " When using VScode, many times you would like to use your favorite extensions and save them so that every time you start your workspace it will load automatically. You can do so by doing the following:  1. Start a new VScode workspace and make sure to create or attach a volume to it. The volume can be of any size that fits your needs.    2. Once the workspace is up and running, install your favorite extensions through the Extensions tab:    3. Continue working with your VScode workspace.  4. Once you finish with your workspace, you can safely click on the stop buttom (or wait for cnvrg to stop it after idle time).  5. Next time you want to use a VScode workspace you can either start the same workspace or create a new one and attach the volume you created in step 1.  6. Once your worksapce is up and running your VScode extensions will load automatically!  See below an example of a new workspace (Workspace 3) attaching the volume:    and the extensions automatically installed onto it:     "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Build an Image from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "  cnvrg uses Docker containers to ensure reproducibility throughout your ML pipeline and you can create a Docker image from within a workspace that will contain the exact environment of the workspace.  When you use this feature, new image will be built and any changes to the environment will be captured in the new Docker image. The Docker image will then be pushed to the chosen registry and repository with the specified tag.  The image can be built immediately (**Build Now**) or when the workspace closes (**Build On Stop**). When the image is built, it will be built inside the compute that the workspace is using.  This is useful in many instances. For example, after launching a workspace, you may `pip install` a python package, update a framework's version or `apt-get install` a ubuntu package. In this case, you have deviated from the image that you originally started the workspace with, and can no longer safely rely on the image working with your updated code (if you were to launch a new workspace or a remote experiment). This feature, allows you to build a new image with the update environment with one click. You can then use that image when running new workspaces, experiments, services or any ML workload.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Requirements Build an Image from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " To use this feature, [you must have added a private Docker registry to your organization](../core_concepts/environments.md#add-a-registry-to-cnvrg).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use The contents of the image Build an Image from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " When you use this feature, all changes to the environment and related files will be captured inside the image, including: - PyPI packages and version (`pip`) - Ubuntu packages and versions (`apt-get`) - Environment variables and so on.  The image will not include the files in `/cnvrg` and `/data`. If you would like to persist these files, see workspace [volumes](#workspace-volumes-kubernetes-only).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Link to workspace Build an Image from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "  When building and image from a workspace, you can optionally enable **Link to workspace**. If enabled, the workspaces **Image** metadata will be updated to the new image.  This is useful for at a glance insights into workspace environments and for restarting the workspace once it closes, with the correct image.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Build an image Build an Image from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Build Now\"  To immediately build a new image from a live workspace's environment: 1. Go to the workspace of your choice. 2. Click **Build Image** in the top navigation bar of thr workspace. 3. Click **Build Now**. 4. Choose the **Registry**, **Repository** and **Tag** for the image to be built. 5. (Optional) [Enable/disable **Link to workspace**](#link-to-workspace). 6. Click **Build**.  The new image will begin to be built inside the workspace. When the build is completed, the image will be pushed to the chosen registry and repository with the specified tag. ::: ::: tab \"Build On Stop\"  To schedule a new image to be built from a live workspace's environment when the workspace stops: 1. Go to the workspace of your choice. 2. Click **Build Image** in the top navigation bar of thr workspace. 3. Click **Build Now**. 4. Choose the **Registry**, **Repository** and **Tag** for the image to be built. 5. (Optional) [Enable/disable **Link to workspace**](#link-to-workspace). 6. Click **Save**.  The icon for **Build Image** along the top navigation bar will update to reflect the scheduled build. When the workspace stops, the image will be built and pushed to the chosen registry and repository with the specified tag.    You can update the **Build Image** details by accessing the menu and clicking **Save**.  You can stop a scheduled build from occurring, by opening the **Build Image** menu and clicking **Disable Build on Stop**  The new image will begin to be built inside the workspace. When the build is completed, the image will be pushed to the chosen registry and repository with the specified tag.  ::: tip There are many reasons a workspace might stop (max duration, stopped by user, restart etc.). In all cases, if a workspace stops, the build job will occur. ::: ::::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is The Files in a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " Similar to the execution of any other machine learning workload in cnvrg, when a workspace is created without an existing volume, it constructs its environment as follows:  1. Pull and execute the chosen container. 2. Clone the chosen git branch and commit (if project connected to git) into `/cnvrg`. 3. Clone the latest version of the files from your projects **Files** tab (or the chosen cnvrg.io commit) into `/cnvrg`. 4. Clone or attach the chosen datasets into `/data`. 5. Install packages from the `requirements.txt` file (if it exists). 6. Execute the `prerun.sh` script (if it exists).  When these steps have completed, the environment will be fully constructed and the workspace will load.  For more information see [Environment](../core_concepts/environments.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Remote SSH Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " You can use SSH to connect with a cnvrg workspace and code locally from your own machine and IDE. Most major IDEs support this remote SSH feature including Visual Studio Code and PyCharm (excluding community edition).  To open a remote SSH session use the `cnvrg ssh start` command on your local workstation. This will begin an SSH session with the workspace of your choice. Once you start the `cnvrg ssh start` command, it will connect to the existing remote workspace and the SSH session will be live until you actively interrupt the command. The command will also tell you the `host`, `port`, `username` and `password` required to add the workstation as an SSH host in your IDE.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Requirements Remote SSH Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " - You must have [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) installed on your local machine. - You must have the `kubeconfig` of the cluster that your workspace is running in on your local machine. - The [`kubeconfig` path, `port`, `username` and `password` can be configured in the `cnvrg ssh start` command](../cli/install.md#run-a-remote-ssh-session) but the `user` chosen must exist inside the workspace's Docker image. - `ssh-server` does not need to be installed in the Docker image as cnvrg will configure this automatically.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remote SSH guide Remote SSH Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " 1. Go to your project's **Workspaces** tab and launch any workspace type inside cnvrg. Wait for the setup to complete. 2. On your local machine, run the command `cnvrg ssh start workspace_id` in a terminal session. [You can also configure this command as required](../cli/install.md#run-a-remote-ssh-session). 3. Wait for `ssh to start`. When it has started, the command will tell you the `host`, `port`, `username` and `password` for the SSH session. 4. Add the SSH details as a host within the IDE of your choice. The default host is: `ssh root@localhost -p 2222`. Ensure you include the port. 5. Connect to the newly added SSH host from your IDE. You will be prompted for the `password`.  You will now have connected to the workspace remotely and can code on your local machine while leveraging the remote compute that your workspace is running in. You can access all the files and everything from the remote container. When you are finished working, you should remember to stop the session by ending the `cnvrg ssh start` command.  ::: tip NOTE To disable host key checking for ssh by default add the following lines in your ssh config file (usually located at `~/.ssh/config`):   Host localhost StrictHostKeyChecking no   If you would like to disable it for all hosts, change `localhost` to `*`, such that:  Host * StrictHostKeyChecking no  :::  ::: tip Check our tutorials for step-by-step guides for [Visual Studio Code](../tutorials/vscode_ssh.md) and [PyCharm](../tutorials/pycharm_ssh.md). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Controlling a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " <!-- ![Workspace opening](../images/workspace_opening.png \"Workspace opening\")-->  When you are inside a workspace you can see the workspace environment in the centre. There you can access all the functionality that JupyterLab, R Studio and Visual Studio Code provide.  However, you also have access to other controls designed to make interfacing with cnvrg from a workspace as seamless as possible.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Workspace Controls Controlling a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "The following controls are provided above the workspace: - **Workspace Name**: The workspace title appears here. Click it to edit it. - **Stop**: Stops the workspace from running and release the compute resources. - **Sync**: Syncs the working directory of the workspace with cnvrg. The workspace will also periodically sync according to the **Sync time** set in the project **Settings** > **Environnement**. - **More**: Click here to access the **Upload (force)** control. It will run the command `cnvrg upload --force` inside the workspace.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Workspace Sidebar Controlling a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "Through the workspace sidebar you can add datasets, monitor running experiments, use AI libraries, see information and logs and use tools like SparkUI and TensorBoard.  <img src='../images/workspace-sidebar.png' width='100' />  The following icons are shown in the sidebar: - **Datasets**: [View the datasets](#using-datasets-in-workspaces) that are attached to the workspace and add others. - **Libraries**: View and interact with the [AI Library](/core_concepts/ailibrary.md#components). - **Experiments**: [View experiments running from the workspace](#view-experiments-running-from-the-workspace). - **Apps**: [Publish an app or dashboard](#publish-apps-and-dashboards-from-a-workspace). - **Info**: [View details of the workspace session](#workspace-info). - **TensorBoard, SparkUI and others**: Click to view the TensorBoard or SparkUI of your workspace.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Syncing Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " Because the workspace is running on a remote compute, in order to sync back file changes to cnvrg you must sync the workspace. If you have auto-sync enabled in your project settings, the workspace will auto-sync after the interval has passed.  You can always sync on demand by clicking the **Sync** button that appears above the workspace.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Attach Datasets to a Live Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " From the Datasets tab in the right sidebar, you can control the datasets that are attached to your workspaces or attach new ones.  The tab contains a list of the datasets currently attached. For each dataset, you can see the name, size, and file count.  You can also choose a specific query or commit of the datasets.  When you choose to include a dataset within a workspace (whether at start-up or on-the-fly, using the sidebar), the dataset will be mounted in the remote compute and will be accessible from the absolute path: `/data/<name_of_dataset>/`.  For example, if you include your dataset `hotdogs` when working in the workspace, the dataset can be found at `/data/hotdogs/` and all of the datasets files will be found in that directory.  If the dataset is still cloning, the cloning symbol appears next to the dataset name.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Attach new datasets to the workspace Attach Datasets to a Live Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " 1. Click **Select Datasets To Attach**. 2. For each dataset you want to add to the workspace, choose the commit or query and the portion of the dataset to clone. 3. Click the dataset to add it to the list of datasets for the workspace. You can remove a dataset from the list by clicking the X next to its name. 4. Click **Attach**.  The selected datasets begin cloning to the workspace. You can track their statuses from the datasets panel where you attached them.  ::: tip Any datasets added on-the-fly will are located at the absolute path: `/data/name_of_dataset/`. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Sync a dataset (create a new commit) Attach Datasets to a Live Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " To sync a dataset that is connected to the workspace, click the **Sync** button next to the dataset's name in the datasets tab.  You can optionally include a commit message. Clicking **Sync** uploads any changes made to the dataset in the workspace to the remote dataset as a new commit.  <img src='../images/workspace-datasets.png' width='36' />  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Use AI Library Components in a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " You can use all of your available AI Library components from within a workspace. To use a component: 1. Go to the **Workspaces** tab. 2. In the right sidebar, click **Libraries**. 3. Choose the library you want to use. 4. Copy the code. 5. Paste it in your workspace and run it.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is View Experiments Running from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "To view the experiments that are running from the workspace: 1. Go to the **Workspaces** tab. 2. In the right sidebar, click **Experiments**.  Experiments that are running from the workspace are displayed here. You can see their status and click through to their pages.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Track your Workspaces' Experiments Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " A workspace is a great place to run experiments and start training models on the fly. You can go ahead and run your scripts inside your workspace but still get access to all the cnvrg experiment [tracking and visualization features](../core_concepts/experiments.md#tracking-and-visualizing).  To run an experiment locally (in the remote workspace) with cnvrg tracking through the SDK, run the experiment using `Experiment.run()`. The experiment will be recorded in the **Experiments** workspace sidebar. Track its progress either in the workspace or from the experiments page inside cnvrg.  Use the `Experiment.run()` method as follows:  python from cnvrg import Experiment e=Experiment.run(command_or_function, title=\"Local Workspace Experiment\")   For example, to run a Python 3 training script:  python from cnvrg import Experiment e=Experiment.run('python3 train.py')   Or to run a function: python from cnvrg import Experiment e=Experiment.run(train(input))   Learn more about using the Python SDK in the [SDK docs](../core_concepts/python_sdk.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Working with git Track your Workspaces' Experiments Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " With workspaces, you can quickly alter code and then run a new experiment to get quick results. While rapid experimentation is important, saving the code that resulted in the experiment is essential to trackable and repeatable experimentation. While you could push to git before each experiment, this can be avoided by using the `git_diff` parameter in your `Experiment.run()` command.  When you set `git_diff=True`, cnvrg will also sync the [git difference](https://git-scm.com/docs/git-diff), saving the changes relative to your git index along with the experiment. Then, after fiddling with your code and running experiments, you can simply [compare the experiments](../core_concepts/experiments.md#comparing-and-organizing), identify which was your most successful experiment, clone the cnvrg.io commit and the push back the changes to your git repository.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Examples: Working with git Track your Workspaces' Experiments Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "- Run an experiment on remote compute using a script: py from cnvrg import Experiment e=Experiment.run('python3 train,py', compute='medium', git_diff=True)   - Run an experiment directly in your workspace (cnvrg workspace) or local IDE (local Visual Studio Code/PyCharm): py from cnvrg import Experiment e=Experiment.run(train(), git_diff=True)   - Run an experiment with the CLI: sh cnvrg run --git_diff=True `python3 train.py`   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Publish Apps and Dashboards from a Workspace Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "1. Go to the **Workspaces** tab. 2. In the right sidebar, click **Apps**. 3. Click **Publish Apps**. 3. Follow the instructions [here](../core_concepts/apps.md#how-to-use-apps-with-cnvrg).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Workspace Info Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": " You can see all the details of a workspace from the workspace info page. You can access the page from the workspace sidebar by selecting **Info**. Accessing a closed workspace will show the workspace info automatically.  Along the top of the page are summary details of the workspace session: - Start time - End time - Duration - Start commit - Compute - Image - Volume  Below that are logs of the workspace and underneath the logs are the list of associated commits for the workspace.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Idle Workspaces Cnvrg Workspaces"
      },
      {
        "role": "assistant",
        "content": "When we work with workspaces we often leave them online for a long time even though we don't use them, for example during the night. For that reason, we added the option to declare a workspace an \"Idle\" automatically, and start a shutdown process. An idle workspace will be defined by two conditions: * No changes in the file system under the folders: /cnvrg and /data * Cpu usage, Memory usage and GPU usage ( if exist) are lower than 20% For more than X minutes, cnvrg will automatically start a shut down process.  :::tip NOTE In order for a workspace to enter idle state, those two conditions must be met. :::  The amount of minutes cnvrg checks before declaring a workspace to be idle is defined in the organization setting, and by default is set to 60 minutes. To enable idle workspace, an admin should turn on the idle flag in the organization settings, and will set the amount of minutes to check the idle time. If a user wants to change the amount of minutes to wait for idle time, the user can change it under the project settings, in the environment tab.  :::tip NOTE A user can only decrease the value that is set under the organization settings' value. If users need to set to a higher value, an admin can set it for them in the project settings. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "As a data scientist, you need to tap large amounts of compute power for extended periods of time, reliably and efficiently.  cnvrg provides powerful features for managing compute, whether in a [Kubernetes cluster](#kubernetes) or [on-premise machine](#on-premise-machines).  cnvrg provides several default compute templates (predefined sets of computer resources). You can [modify these](#edit-an-existing-template) and [add new compute templates](#add-a-compute-template) with no special effort.  In most instances, you configure the computes you'll need once, in the form of [compute templates](#compute-templates), at system setup. These become available across your entire organization.  Then you [select one or more computes](#using-compute-in-jobs) during the creation of your [experiment](#when-starting-a-workspace-or-experiment-using-the-web-ui), [workspace](#when-starting-a-workspace-or-experiment-using-the-web-ui), [flow](flows.html#overview), [apps](apps.md#how-to-use-apps-with-cnvrg) and [serving](endpoints.md#create-an-endpoint).  You can do this [through the cnvrg web UI](#when-starting-a-workspace-or-experiment-using-the-web-ui), or by using a [cnvrg CLI command](#using-the-cli) or [cnvrg SDK call](#using-the-sdk).  In running the job, cnvrg [attempts to use the compute](#using-compute-in-jobs) in the order in which you attach them, based on available resources. If the first compute is unavailable, cnvrg attempts to use the second compute and so on.  The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Compute Templates Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  A compute template is a predefined set of computer resources. It consists of information to define CPUs, GPUs, memory and other metadata. A template exists for a specific compute resource (Kubernetes cluster or on-premise machine).  Technically, a compute template describes either one or more Kubernetes pod, or an on-premise machine. Each template you add is a different set of resources to use as a compute engine when running a job - either as a pod on a Kubernetes cluster or as a specific on-premise machine.  Your templates are available for selection whenever you encounter a **Compute** drop-down list. When you select one of your templates, cnvrg checks if the required resources are available in your cluster or the machine is available and attempts to allocate the resources of the requested size. For more information, see [Using Compute in Jobs](#using-compute-in-jobs).  For each resource you are connected to, cnvrg automatically creates a set of default compute templates. You can customize existing templates, add templates or remove templates as desired.  The templates for a remote Spark cluster must be configured before use and are not generated automatically.  There are five types of compute templates: | Type of Template | Explanation | |:-:|-| |Regular| A regular template is a set of resources defining a single pod that will be launched on a single node (ie. non-distributed). A machine's template is a regular template as well. | | [Open MPI](../core_concepts/distributed.md#open-mpi) | This type of template is used for multi-node distributed jobs. It allows you to run any Open MPI compatible workload or job as a distributed workload over more than one node. The details of the master node and workers nodes can be defined separately. | | [PyTorch Distributed](../core_concepts/distributed.md#pytorch-distributed) | A PyTorch Distributed template is used for running code that uses the `torch.distributed` framework. The template defines the configuration for thr worker nodes.| | [Spark on Kubernetes](../core_concepts/distributed.md#spark-on-kubernetes) | A Spark on Kubernetes template is used for running distributed processing jobs using Spark on Kubernetes. The details of the master node and workers nodes can be defined separately. | | [Remote Spark](../core_concepts/distributed.md#remote-spark-clusters) | A Remote Spark template is used for running distributed processing jobs using a remote Spark cluster. You choose an existing regular template as the Spark driver and then define the configuration of the desired worker nodes. |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a compute template Compute Templates Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  You can add compute templates to a Kubernetes cluster and Spark cluster.  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab \"Regular\"  1. Click **Compute** > **Templates**. 2. Click **Add Compute Template**. 3. In the list that appears, select the Kubernetes cluster you want to add the compute template to. 4. Set the **Title** for the template. 5. Select **Regular**. 6. Fill in the rest of the relevant **Specifications**: - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 7. Click **Save**.  cnvrg adds the new template to the selected Kubernetes cluster. ::: ::: tab \"Open MPI\"  1. Click **Compute** > **Templates**. 2. Click **Add Compute Template**. 3. In the list that appears, select the Kubernetes cluster you want to add the compute template to. 4. Set the **Title** for the template. 5. Select **Open MPI**. 6. Fill in the rest of the relevant **Specifications**: - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 7. Fill in the **Workers Specifications** of the worker nodes: - **Workers Count**: The amount of worker nodes to use with this template. - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 8. Click **Save**.  cnvrg adds the new template to the selected Kubernetes cluster.  ::: ::: tab \"PyTorch Distributed\"  1. Click **Compute** > **Templates**. 2. Click **Add Compute Template**. 3. In the list that appears, select the Kubernetes cluster you want to add the compute template to. 4. Set the **Title** for the template. 5. Select **PyTorch Distributed**. 6. Fill in the rest of the relevant **Wroker Specifications**: - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 7. Click **Save**.  cnvrg adds the new template to the selected Kubernetes cluster.  ::: ::: tab \"Spark on Kubernetes\"  1. Click **Compute** > **Templates**. 2. Click **Add Compute Template**. 3. In the list that appears, select the Kubernetes cluster you want to add the compute template to. 4. Set the **Title** for the template. 5. Select **Spark**. 6. Fill in the rest of the relevant **Specifications**: - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 7. Fill in the **Workers Specifications** of the worker nodes: - **Workers Count**: The amount of worker nodes to use with this template. - Number of **CPU**s - Amount of **Memory** - Number of **GPU**s - The **Labels** or selector for the node pools the template should use. For example, `gputype=v100`. Ensure it matches the template. To specify several, separate them with commas. 8. Click **Save**.  cnvrg adds the new template to the selected Kubernetes cluster.  ::: ::: tab \"Remote Spark Cluster\"  1. Go to **Compute** > **Templates**. 2. Click **Add Compute Template**. 3. In the list that appears, select the Spark cluster you want to add the compute template to. 4. Set the **Title** for the template. 5. In the **Spark Driver** section, use the compute selector to choose which regular compute templates should be used. 6. Fill in the **Workers Specifications** of the worker nodes: - **Workers Count**: The amount of worker nodes to use with this template. - Number of **CPU**s - Amount of **Memory** 7. Click **Save**.  cnvrg adds the new template to the selected Spark cluster. ::: :::: "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a compute template Compute Templates Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " To delete a compute template:  1. Click **Compute** > **Templates**. 2. Click the **Delete** icon at the extreme right end of the compute template that you want to delete. 3. Confirm the deletion.  cnvrg deletes the template from your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Edit an existing template Compute Templates Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " To edit a compute template:  1. Go to **Compute** > **Templates**. 2. Click the template you wish to edit. A similar page to the [new template page](#add-a-compute-template) is presented. 3. Edit the fields as desired. 4. Click **Save**.  cnvrg updates the details of the template.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  In cnvrg, Kubernetes clusters and on-premise machines are referred to as compute resources.  cnvrg seamlessly integrates with your Kubernetes clusters and allows you to start leveraging your nodes quickly and easily. Your organization can connect to many Kubernetes clusters.  You can also connect to your on-premise machines and add them as resources as well.  Additionally, you can add remote Spark clusters as compute resources.  You can see all your connected compute resources by going to **Compute** > **Resources**.  Here, you can also add, edit and delete Kubernetes clusters, machines and Spark clusters from your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Kubernetes Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a Kubernetes cluster Kubernetes Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  1. Go to **Compute** > **Resources**. 2. Click on **+ Add Resource** and then click **Kubernetes** from the list. 3. Click the type of cluster you are adding: On-premise, Google GKE, Amazon EKS or Azure AKS. 4. Type in the **Title** of the cluster (for use within cnvrg). 5. Type in the **Domain** for the cluster. <!-- can this be an ip --> 6. Paste the **Kube Config** for the cluster. 7. Choose the provider for the cluster (GKE - Google, EKS - Amazon, AKS - Microsoft or On-Premise). 8. (When type is not On-Premise) Check **Use Persistent Volumes** if relevant. 9. (When type is not On-Premise) Check **Spots Enabled** if relevant. 10. Click **Create**. cnvrg adds the cluster to your organization and creates default templates for the cluster, displaying them in the panel that appears. 11. Click **Save** to complete the creation of the Kubernetes cluster. A set of default templates will be automatically generated as well.  If you would like to edit the cluster's templates, remove templates or add additional templates, you can do so from the [**Compute** > **Templates** page](#add-a-compute-template).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Kubernetes cluster information Kubernetes Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  Each cluster that you have added as a resource to cnvrg is accompanied with a dashboard. You can use the cluster's page to update information about your cluster.  You can access this page by clicking on the name of the cluster in **Compute** > **Resources**.  At the top is a summary of the cluster's details including the cluster's name, who created the cluster, the status of the cluster and the date of the last health check.  The page has the following tabs with deeper information:  |Tab | Contents | |:-:|-| |Logs | The logs of health checks can be found here. | | [Kibana](#kibana-kubernetes-only) | The Kibana dashboard for the cluster can be accessed from this tab. Use it to gain deep insights into the logs of your cluster. | [Grafana](#grafana-kubernetes-only) | The Grafana dashboard for the cluster can be accessed from this tab. Grafana allows you to monitor the compute usage for jobs running on the cluster. | Config | This tab holds the configuration details for the cluster. You can edit all of the cluster's details here as well. | | [System Dashboard](#system-dashboard-on-premise-and-kubernetes) | This tab holds a dashboard for getting at a glance in-depth insights into the health and utilization of the custer. |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Edit a Kubernetes cluster Kubernetes Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "To edit an existing Kubernetes cluster: 1. Go to **Compute** > **Resources**. 2. Click on the cluster you wish to edit. 3. Click on the **Config** tab. 4. Click **Edit**. 4. Edit the fields as desired. 5. Click **Save**.  cnvrg updates the details of the cluster.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a Kubernetes cluster Kubernetes Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can delete an on-premise machine from your organization:  1. Go to **Compute** > **Resources**. 2. Click on the cluster you wish to delete. 3. Click on the **Config** tab. 4. Click **Delete**. 5. Confirm you want to delete the machine by clicking **Delete** in the pop-up.  cnvrg deletes the cluster from your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use On-Premise machines Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add an on-premise machine On-Premise machines Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " Before you can add your on-premise machine you must verify the following dependencies are installed on the machine:  :::: tabs :options={ useUrlFragment: false } ::: tab CPU Machine - [docker compose](https://docs.docker.com/compose/install/) - [docker](https://docs.docker.com/install/) ::: ::: tab \"GPU Machine\" - [docker compose](https://docs.docker.com/compose/install/) - [docker](https://docs.docker.com/install/) - [NVIDIA docker](https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)) Note: Installing docker compose on a GPU machine can be complicated. [Use our guide to get started quickly](#installing-docker-compose-on-a-gpu-machine). ::: ::::   1. Go to **Compute** > **Resources** 2. Click on **+ Add Resource** and then click **Machine** from the list. 3. Type in the **Title** of your machine (for use within cnvrg). 4. Type in all the SSH details for the machine: - **Username** - **Host** - **Port** 5. Choose an SSH authentication method and add the relevant authentication: - **SSH Password** or - **SSH Key** 6. If it is a GPU machine, enable the **GPU Machine** toggle. 7. Fill out the advanced settings (optional): - Set **CPU Cores**. - Set **Memory** in GB. - Set **GPU Count** (if relevant). - Set **GPU Memory** (if relevant). - Set the **GPU Type** (if relevant). 8.  Click **Add**.  cnvrg saves the details and adds the machine to your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use On-Premise machine information On-Premise machines Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " Each machine that you have added as a resource to cnvrg is accompanied with a dashboard. You can use the machine's page to update information about your machine.  You can access this page by clicking on the name of the machine in **Compute** > **Resources**.  At the top is a summary of the machine's details including, the machine's name, who created the machine, the status of the machine and the date of the last [health check]().  The page has the following tabs with deeper information:  |Tab | Contents | |:-:|-| |Logs | The logs for health checks can be found in this tab. | | Config | This tab holds the configuration details for the machine. You can edit all of the machine's details here as well. | | [System Dashboard](#system-dashboard-on-premise-and-kubernetes) | This tab holds a dashboard for getting at a glance in-depth insights into the health and utilization of the machine. |  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Edit an on-premise machine On-Premise machines Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can edit settings for an on-premise machine in your organization: 1. Go to **Compute** > **Resources**. 2. Click on the machine you wish to edit. 3. Click on the **Config** tab. 4. Click **Edit**. 4. Edit the fields as desired. 5. Click **Save**.  cnvrg updates the details of the machine.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete an on-premise machine On-Premise machines Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can delete an on-premise machine from your organization:  1. Go to **Compute** > **Resources**. 2. Click on the machine you wish to delete. 3. Click on the **Config** tab. 4. Click **Delete**. 5. Confirm you want to delete the machine by clicking **Delete** in the pop-up.  cnvrg deletes the machine from your organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Spark clusters Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " While cnvrg natively support running [Spark on Kubernetes](../core_concepts/distributed.md#spark-on-kubernetes) without any setup, you can additionally add an existing remote Spark cluster for use in cnvrg. To get started: 1. Add the Spark cluster as a compute resource. 2. [Create the desired Spark compute templates for that cluster](#add-a-compute-template).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a remote Spark cluster Spark clusters Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  1. Go to **Compute** > **Resources** 2. Click on **+ Add Resource** and then click **Spark** from the list. 3. Set the **Title** of the Spark cluster (for use in cnvrg). 4. Set the  **Spark Configuration**. These key-value pairs will be used in the construction of the `spark-defaults.conf`. Enter all of the settings that you need for your cluster. For example, `spark.master` and `spark://your_host:your_port`. [A full list of options can be found here](http://spark.apache.org/docs/latest/configuration.html#spark-configuration). 5. Add any desired **Environment Variables**. These key-value pairs will be exposed as environment variables in the Spark driver. These will be exposed in addition to any that might exist in the chosen Docker image or those added in the [project settings](../core_concepts/projects.md#environment). For example, `SPARK_HOME` and `/spark`. 6. Upload **Files** that are relevant to your Spark configuration. Click **Browse Files** or drag-and-drop the files you wish to upload. Then add the exact file path and name for where the file should be copied to in the Spark driver and what it should be called. For example, `yarn-conf.xml` with **Target Path** `/spark/yarn-conf.xml`. 7. Click **Save**.  The Spark cluster will be added as a compute resource. Now you will need to [define compute templates]() for use with the cluster. These define which regular compute templates to use as a Spark driver and how many Spark worker nodes should be used. This allows you to run Spark jobs with different amounts of executors.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remote Spark cluster information Spark clusters Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can review the settings of your remote Spark cluster including which user added it and when it was created. 1. Go to **Compute** > **Resources**. 2. Click on the Spark cluster you would like to view.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Edit a remote Spark cluster Spark clusters Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can edit settings for a a remote Spark cluster in your organization: 1. Go to **Compute** > **Resources**. 2. Click on the Spark cluster you would like to edit. 3. Edit the fields as desired. 4. Click **Save**.  cnvrg updates the details of the Spark cluster.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Delete a remote Spark cluster Spark clusters Compute Resources Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can delete a Spark cluster from your organization: 1. Go to **Compute** > **Resources**. 2. Click on the Spark cluster you would like to remove. 3. Click **Delete**. 4. Confirm the deletion by clicking **Yes** in the popup.  cnvrg will delete the Spark cluster and remove it as a compute resource.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Compute Dashboards Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " One of the key goals of cnvrg is to simplify DevOps and provide tools to easily manage all of your compute resources. To make this possible, cnvrg builds in support for many different compute dashboards: - [System Dashboard](#system-dashboard-machines-and-kubernetes) - [Kibana](#kibana-kubernetes-only) - [Grafana](#grafana-kubernetes-only)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use System Dashboard (machines and Kubernetes) Compute Dashboards Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "   The system dashboard provides you with at a glance insights into the health and utilization of all of your resources. This allows you to monitor your GPUs and CPUs easier than ever before.  The system dashboard can be found in the **System Dashboard** tab on the information page of each [cluster](#kubernetes-cluster-information) and [machine](#on-premise-machine-information).  Inside the tab, dynamic and live charts for every relevant metric of your resource is displayed. You can get at a glance insights into: - GPU charts: - GPU Utilization (%) - Memory (%) - Temperature  - Power (W) - CPU charts: - CPU Utilization (%) - Memory (Mib) - Disk IO - Network Traffic  At the top you can determine the time horizon for the charts that are displayed: - Live - 1 Hour - 24 Hours - 30 Days - 60 Days   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Kibana (Kubernetes only) Compute Dashboards Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "  Kibana lets you visualize your Elasticsearch data and navigate the Elastic Stack so you can do anything from tracking query load to understanding the way requests flow through your apps.  Kibana is natively integrated with cnvrg and you can use it to dynamically visualize the logs of your Kubernetes cluster.  You can access the Kibana dashboard for your cluster from the [cluster's information page](#kubernetes-cluster-information). Additionally, any endpoints you create will be accompanied by a specific log dashboard using Kibana, which can be accessed in the **Kibana** tab of the service.  You can learn more about using Kibana [in the Kibana docs](https://www.elastic.co/guide/en/kibana/7.6/index.html).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Grafana (Kubernetes only) Compute Dashboards Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "   Grafana allows you to query, visualize, alert on and understand the metrics of your Kubernetes cluster. Create, explore, and share dashboards with your team with this simple and easy to use tool.  Its integration with cnvrg allows you to easily monitor the health of your cluster. You can check the resource usage of pods and create dynamic charts to keep an eye on your entire cluster.  You can access the Grafana for your cluster from the [cluster's information page](#kubernetes-cluster-information). Additionally, any endpoints you create will be accompanied by a specific resource dashboard using Grafana, which can be accessed in the **Grafana** tab of the service.  You can learn more about using Grafana [in the Grafana docs](https://grafana.com/docs/grafana/latest/).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Compute Health Checks Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " To help manage your compute effectively, cnvrg will regularly check the health of your connected machines and Kubernetes clusters.  cnvrg will query the resources every 5 minutes to see if they are reachable and useable in jobs. You can follow the logs for this process in the **Logs** tab on the information page of each [cluster](#kubernetes-cluster-information) and [machine](#on-premise-machine-information).  If the status is `Online`, the resource can be used. If the status is `Offline`, cnvrg could not connect to the resource. You will need to troubleshoot the resource for any issues and check that the configuration details for the resource are correct.  When the status of a compute resource changes, an email notification is sent to the administrators of the organization.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Using Compute in Jobs Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " Using the web UI, you can choose a compute when starting a workspace or experiment or when building a flow.  You can also set a compute for jobs when running them using the cnvrg CLI and cnvrg SDK.  In running the job, cnvrg attempts to use the computes in the order in which you set them. If the first compute is unavailable, cnvrg attempts to use the second compute and so on. If none of the selected computes are available, the experiment will enter into a queued state. When a compute becomes available, it will start running.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use When starting a workspace or experiment using the web UI Using Compute in Jobs Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "   When you start a workspace or experiment from the UI, you can choose one or more computes to attempt to run on, using the compute selector.  1. Click **Start Workspace** or **New Experiment** and fill in the relevant details in the pane that appears. To choose your compute(s), select the **Compute** drop-down list (for a workspace), or the **Compute** drop-down list under **Environment** (for an experiment). 2. Click each compute you want to attempt to use in the workspace or experiment. You can remove a compute from the list by clicking the X next to its name. The numbers next to their title when clicked indicate the order cnvrg will try to use them in. 3. Click **Start Workspace** or **Run**.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use When building a flow using the web UI Using Compute in Jobs Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": "   1. Open the flow for which you wish to choose the compute. 2. In the **Advanced** tab, select the **Compute** drop-down list. 3. Click each compute you want to attempt to use in the workspace or experiment. You can remove a compute from the list by clicking the X next to its name. The numbers next to their title when clicked indicate the order cnvrg will try to use them in. 4. Click **Save Changes**.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the CLI Using Compute in Jobs Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " To set a compute when running an experiment, use the `--machine` flag:  bash cnvrg run python3 train.py --machine=medium   You can include multiple computes in the array. See [the full cnvrg CLI documentation](../cli/install.md#experiments) for more information about running experiments using the CLI.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using the SDK Using Compute in Jobs Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " To set a compute when running an experiment using the Python SDK use the `compute` parameter:   python from cnvrg import Experiment e = Experiment.run('python3 train.py', compute= medium)   You can include multiple computes in the array. See [the full cnvrg SDK documentation](../core_concepts/python_sdk.md#experiment-operations) for more information about running experiments using the SDK.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Viewing Job History Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can view a history of the jobs that ran recently.  Click **Compute** > **Jobs**.  The Jobs pane is displayed, showing a summary of the recent jobs that have run. There are columns showing: - Title. Clicking the title brings you to the experiments page. - Project the job ran in. Clicking the project name brings you to the project page. - Status - Duration - User - Created at - Compute - Image  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Controlling which Jobs run on which Nodes Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " Kubernetes is designed to efficiently allocate and orchestrate your compute. By default, all nodes can be used by any job/compute template if the requested resources exist. However, this may mean that GPU nodes may be used for CPU jobs, meaning that a CPU job will use a GPU machine when it needs to be used for a GPU job. This is just one example of when you might want to limit this behavior.  You can use Kubernetes and cnvrg to control which jobs are run on which nodes. There are two ways to enforce this: 1. Adding a taint to the GPU node pool 2. Using node labels 3. Controlling using instance type  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a taint to the GPU node pool Controlling which Jobs run on which Nodes Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " If you wish to restrict GPU nodes to only GPU jobs, add the following node taint to the node: * key: `nvidia.com/gpu` * value: `present` * effect: `NoSchedule`  You can use the following kubectl command to set a specific node or nodes: bash kubectl taint nodes <node_name> key1=key:nvidia.com/gpu key2=value:present key3=effect:NoSchedule  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Using node labels Controlling which Jobs run on which Nodes Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can use node labels to attach specific compute jobs to specific nodes.  To label your nodes with a custom label use the following kubectl command: bash kubectl label nodes <node-name> <label-key>=<label-value>  Now add the label to the compute templates you want to run on the labelled node. Go to **Compute** > **Templates** and edit the template you want to use only on the labelled node. In **Labels**, add the same `<label-key>=<label-value>`.  Now any jobs run on the template will only run on nodes with the matching labels.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Controlling using instance type Controlling which Jobs run on which Nodes Cnvrg Compute"
      },
      {
        "role": "assistant",
        "content": " You can also add a selector to a job template that uses the instance type of the desired node group. This does not require adding a label or taint to the node group.  Go to **Compute** > **Templates** and edit the template you want to use only a specific instance type In **Labels**, add the following: `beta.kubernetes.io/instance-type: 'desired-instance-type'`  For example, to enforce the template to use an `m5.xlarge`, add `beta.kubernetes.io/instance-type: 'm5.xlarge'` to the **Selector**.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " A cnvrg project is the space that holds everything related to a specific machine learning problem or domain. You can work and collaborate on projects.  A project can include files, [workspaces](../core_concepts/workspaces.md),  [experiments](../core_concepts/experiments.md), [flows](../core_concepts/flows.md), [apps and dashboards](../core_concepts/apps.md), [serving](../core_concepts/endpoints.md), artifacts, models and even research papers.  The topics in this page: [[TOC]]  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Creating a project Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " ![create project](../images/create-new-project.png \"New Project Screen\")  You can create a project in cnvrg using the web UI, CLI, or SDK.  **Using the web UI**  1. Navigate to the **Projects** tab and click **Start Project**.  2. Type in a title for the project and click **Create**. The project is added and the project dashboard is displayed.  **Using the cnvrg CLI**  With cnvrg CLI commands, you can create an empty project or create a project linked to an existing folder.  - **Create an empty cnvrg project** bash cnvrg new <project-name>   When you run the `cnvrg new` CLI command, cnvrg creates a default project tree:   total 16 drwxr-xr-x  8  256B Jul 14 23:58 . drwxr-xr-x  8  256B Jul 14 23:58 .. drwxr-xr-x  4  128B Jul 14 23:58 .cnvrg -rw-r--r--  1  139B Jul 14 23:58 .cnvrgignore -rw-r--r--  1  404B Jul 14 23:58 README.md drwxr-xr-x  2   64B Jul 14 23:58 models drwxr-xr-x  2   64B Jul 14 23:58 notebooks drwxr-xr-x  5  160B Jul 14 23:58 src   The new project is now created in cnvrg and you can make changes in your local directory.  To sync changes between the online project and your local repository use the `cnvrg sync` command:  bash cnvrg sync   - **Create a cnvrg project and link it to an existing folder**  You can create a cnvrg project and link it to a folder, with a single command.  1. Navigate into the folder. 2. From there, run the `cnvrg link` command:  bash cnvrg link [--title='project_name'] --sync   For more information on the `cnvrg link` command, see the [cnvrg CLI documentation](../cli/install.md#projects).   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Project Dashboard Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " ![Project Dashboard](../images/project-dashboard.png \"Project Dashboard\")  The dashboard shows a summary of your project: the number of experiments run, active endpoints, active workspaces and active apps, as well as a feed of all activity in the project.  On the left, the dashboard presents tabs for easy access to project research, files and more.  From the dashboard, you can start or access a running workspace and link your project to a Git repo.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "cnvrg offers out-of-the-box version control for your project. With the simple drag-and-drop interface or the cnvrg CLI, you can have your project files (code, artifacts) automatically tracked and versioned.  cnvrg automatically creates new commits for experiments and workspaces syncs and tracks all your projects' files. When connected to git, only the designated `output` folder will be synced and managed by cnvrg.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Change commits Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " On the **Files** tab of a project, you can view a different commit by clicking the **Version** menu, and then choose a different commit. You can also change commits while viewing a specific file.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use File viewer Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " cnvrg has inline support for rendering a viewing the following file types: - images - csvs - scipts (python, R, txt, .sh, yaml etc.) - Static Jupyter notebooks  Simply navigate to the file inside the **Files** tab and click it to view it.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Compare different versions of a file Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "  As cnvrg is tracking multiple versions of your files, you can compare the difference between saved versions using the **Diff** button. This is beneficial for comparing scripts and Jupyter notebooks.  To compare the difference between two versions of the same file: 1. Navigate to the file you want to compare. 2. In the **Version** drop down list, choose the version you want to compare against. 3. Click **Diff** on the second version's page.  cnvrg compares the chosen version and the current version and highlights all the changes.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Diff for scripts and text files Compare different versions of a file Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " When comparing scripts, cnvrg places the scripts alongside each other and highlights the deletions and additions.   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Diff for static Jupyter notebooks Compare different versions of a file Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " When comparing Jupyter Notebooks, cnvrg aligns each cell alongside the corresponding previous version and highlights deletions and additions. Markdown and Code cells are designated as well.     "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Branches Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " When working on a workspace or from your local environment (PyCharm and others), all changes are pushed to the `master` branch via cnvrg version control.  Every experiment you run creates its own separate branch for the changes it makes. For example, if you run two experiments in parallel, with the same `start_commit`, they both create two different `end_commits`. This way, you can make sure that everything is tracked and that no conflicts or unnecessary merges are made.  ::: tip Use the `.cnvrgignore` file to ignore files that you don't want to be synced to the platform. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Syncing Files Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "To sync your project to cnvrg, run:  cnvrg sync   ::: tip Find more information for using the CLI with your project [here](../cli/install.md#projects). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Project Settings Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "For each project in cnvrg, you may configure many different settings. You can access the project settings via the **Settings** tab on your project's sidebar. Below, you can see descriptions for each section.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use General Settings Project Settings Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " - Name: Enter the name of the project (Note: you can't change the name after the project is created.) - Description: Enter the description of the project. - Privacy: Use the dropd-down arrow to set the project as private or public. - Delete Project: Click the Delete Project button to delete the project (Warning: you are not able to recover deleted projects.)  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Collaborators Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "Making collaboration simpler is a key goal in cnvrg's mission. As such, every project in cnvrg can have different members. Projects are private by default and only their collaborators can access them.  To view, add or remove collaborators from your project, go to the **Settings** tab of the project and click the **Collaborators** menu item.  ![alt](../images/collaborators.png \"Project Collaborators\")  ::: tip More details on how collaboration works in cnvrg can be found [here](../core_concepts/team.md). :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Add a collaborator Collaborators Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " To add a collaborator to the project: 1. Go to **Project** > **Settings** > **Collaborators**. 2. Click the **Add Collaborator** drop-down list. 3. Type the username or email of the person you wish to add, or choose the user from the list. 4. Click **Save**.  cnvrg adds the user as a collaborator on the project.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Remove a collaborator Collaborators Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " To remove a collaborator from the project: 1. Go to **Project** > **Settings** > **Collaborators**. 2. Click the **Remove** button next to the user you wish to remove.  cnvrg removes the user from the project.  :::tip NOTE Administrators in your organization have access to all projects, without being added as a collaborator. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "cnvrg has native integration with Git. Leveraging this feature allows you to use an external Git repository to track your code and files while using cnvrg to track your data science resources (models, experiments and more).  When integrating cnvrg project with Git, cnvrg automatically clones your Git project before starting your job. You can specify a branch and commit when starting a workspace, experiment, flow task or endpoint. Any artifacts and assets that are created during the job (models, datasets, plots, and so on) are stored using cnvrg's file system and are associated with the job for future reference.  ![Git Integration](../images/git-integration.png \"Git options when running a job\")  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Linking your Git repo with a cnvrg project Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " Go to your project **Settings** tab, and find the **Git Integration** tab. Here, set the **Git Repo** and the **Git Branch**. Specify whether the repo is private or not.  There are two ways to authenticate cnvrg with Git to use your private repositories: - SSH public and private key pair (done per project) - OAuth token (done per user)  ::: tip You cannot link an empty git repository. Ensure you have a branch before connecting. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use SSH public and private key pair Linking your Git repo with a cnvrg project Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " Generate an SSH public and private key pair. The public key is given to the Git repository and the private key is entered into cnvrg. Make sure you do not create a key that uses a password.  Navigate to the **Git Integration** tab of your project settings. After clicking **Private Repo** enter your SSH private key in the corresponding box.  Ensure the private key does not include a passphrase and it is entered with the following format:  -----BEGIN RSA PRIVATE KEY----- ... -----END RSA PRIVATE KEY-----  Click **Save**. Your project now clones your private Git repository when running jobs.  Here are several links to instructions from major Git services providing instructions to generate SSH keys:  :::: tabs :options=\"{ useUrlFragment: false }\" ::: tab GitHub [GitHub tutorial](https://help.github.com/en/articles/connecting-to-github-with-ssh) ::: ::: tab Bitbucket [Bitbucket tutorial](https://confluence.atlassian.com/bitbucket/set-up-an-ssh-key-728138079.html) ::: ::: tab GitLab [GitLab tutorial](https://docs.gitlab.com/ee/ssh/) ::: ::: tab \"AWS CodeCommit\" [AWS CodeCommit tutorial](https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-without-cli.html)  When using AWS CodeCommit, the SSH URL should be in the following format:  `ssh://SSH_KEY_ID@git-codecommit.ZONE.amazonaws.com/v1/repos/REPO_NAME`  Where `SSH_KEY_ID` is taken from the AWS IAM, `ZONE` is the AWS zone for your CodeCommit (for example, `us-west-2`), and `REPO_NAME` is the name of the repository you are linking to the project. ::: ::::  You will need to generate a new pair for every Git repository you are linking with cnvrg.  ::: warning When you enter the Git repo link in the project settings, use the SSH format. :::   "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use OAuth token Linking your Git repo with a cnvrg project Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " You can  authenticate your cnvrg account with your Git account using an OAuth token by adding it to your cnvrg account settings.  Navigate to your cnvrg account settings. Enter the OAuth token in the corresponding **Git Access Token** field. Click **Save**. Now your cnvrg account can access all the same Git repositories that your Git account has access to.  You still need to link the cnvrg project to the Git repository in its **Settings**. Navigate to the **Git Integration** tab in the project settings to do so.  Here are links from major Git services providing instructions to generate OAuth tokens:  - [GitHub](https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line) - [Bitbucket](https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html) - [GitLab](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html)  ::: tip This enables your cnvrg account access to all the private repos your Git account has access to. :::  ::: warning When you enter the Git repo link in the project settings, you need to use the `https://`. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Saving artifacts when using Git Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " To track a job's artifacts (for example, notebook checkpoints, experiment outputs and so on) you must indicate to cnvrg where to locate the artifacts your code produces. When running the job, indicate to cnvrg what directory your code is saving the files to. The default is `output` in the project's home directory.  For example, if your code saves outputs like this:  python model.save_weights('artifacts/model.weights')   Then ensure you select `artifacts` as your output folder.  ![Git Output](../images/git-output.png \"Make sure to set your output correctly\")  ::: warning Ensure the Output dir matches what is in your code, otherwise cnvrg cannot track your artifacts. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Environment Saving artifacts when using Git Git Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": " - Image: Add a default docker image to your project. - Compute: Set a default compute template or templates to run your jobs on. - Command To Execute: Set a default command for experiments in the project. - Working Directory: Set the default working directory for experiments. The command to be executed is called inside the chosen working directory. - Environment Variables: Set key value pairs to be exported as environment variables when a job is started. - Run Tensorboard automatically: If enabled, the TensorBoard will start running automatically when a job is started. - Restart when idle: Disable or enable restart cnvrg experiments that haven't printed new logs for more than predefined time (The default is 60 minutes). - Autosync: Turn on or off to perform periodic automatic sync. - Sync Time: Set the duration for each autosync. - On Spot Termination: If set to on, when you lose access to a spot, cnvrg will sync the experiment & restart it running on on-demand. - Use single deploy api key: Use one set of keys when publishing endpoints in the project. - Email notifications: Set the default settings for whether or not to send email notifications when an experiment finishes successfully or encounters an error.    "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Slack Integration Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "![Slack Success](../images/slack-success.png \"Successful notification\")  cnvrg has the ability to send experiment notifications to a Slack user or channel. This can help you keep up to date with the status of your running experiments.  [Enable Slack integration by following this guide](../tutorials/slack.md).  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Project Secrets Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "Secrets are encrypted environment variables that you create in your project and are attached to each job that you run in the project.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Creating a Secret Project Secrets Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "In your project **Settings** tab, navigate to the **Secrets** tab. Here, click **+ Add New** and add the Secret key and Secret value. Then click the **Submit** button.    The following rules apply to secret keys and values:  - Secret keys can only contain alphanumeric characters ([a-z], [A-Z], [0-9]) or underscores (_). Spaces are not allowed. - Secret keys must not start with a number. - Secret keys must be unique. - Secret value is limited too 253 characters.  "
      }
    ],
    [
      {
        "role": "user",
        "content": "How to use Accessing your secrets Project Secrets Cnvrg Projects"
      },
      {
        "role": "assistant",
        "content": "Secrets are available in every job that you run in the project using environment variables: - All jobs that are executed on a Kubernetes cluster, secrets are mounted as [Kubernetes Secrets](https://kubernetes.io/docs/concepts/configuration/secret/) - Jobs that are executed on a Machine, secrets will be mounted as docker environment variables  For example, in Python code you can access a secret key named \"AWS_ACCESS_KEY\" in the following way:  python import os os.environ.get(\"AWS_ACCESS_KEY\")  :::tip NOTE Updating environment variables and secrets doesn't affect running jobs, onlly new/restarted jobs. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg cnvrg SDK V1 (Deprecated)"
      },
      {
        "role": "assistant",
        "content": " The cnvrg SDK was developed in Python and is designed to help data scientists to interact with cnvrg from their code, experiments and models. Through the SDK, you can create experiments, manage models, automate your machine learning pipeline and more.   The topics in this page: [[TOC]]   "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Download and Install the cnvrg SDK Cnvrg cnvrg SDK V1 (Deprecated)"
      },
      {
        "role": "assistant",
        "content": "To install the cnvrg SDK simply use the following pip command.  bash pip install cnvrg   Or if you're using pip for Python 3, use the following: bash pip3 install cnvrg   ::: warning The cnvrg SDK requires Python 3.5 or later. :::  "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ],
    [
      {
        "role": "user",
        "content": "What is Authenticating the cnvrg SDK Cnvrg SDK Operations"
      },
      {
        "role": "assistant",
        "content": " "
      }
    ]
  ]
}